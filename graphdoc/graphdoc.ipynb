{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages \n",
    "import os\n",
    "import json\n",
    "\n",
    "# internal packages \n",
    "\n",
    "# external packages\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from graphql import build_schema, parse, build_ast_schema, validate_schema, print_ast\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "load_dotenv()\n",
    "open_ai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphQL Schema Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'document', 'definitions': [{'kind': 'enum_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'Network'}, 'directives': [], 'values': [{'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'ARBITRUM_ONE'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'ARWEAVE_MAINNET'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'AURORA'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'AVALANCHE'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'BOBA'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'BSC'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'CELO'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'COSMOS'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'CRONOS'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'MAINNET'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'FANTOM'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'FUSE'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'HARMONY'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'JUNO'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'MOONBEAM'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'MOONRIVER'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'NEAR_MAINNET'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'OPTIMISM'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'OSMOSIS'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'MATIC'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'XDAI'}, 'directives': []}]}, {'kind': 'enum_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'NftStandard'}, 'directives': [], 'values': [{'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'ERC721'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'ERC1155'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': None, 'name': {'kind': 'name', 'value': 'UNKNOWN'}, 'directives': []}]}, {'kind': 'enum_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'SaleStrategy'}, 'directives': [], 'values': [{'kind': 'enum_value_definition', 'description': {'kind': 'string_value', 'value': ' Strategy that executes an order at a fixed price that can be taken either by a bid or an ask. ', 'block': False}, 'name': {'kind': 'name', 'value': 'STANDARD_SALE'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': {'kind': 'string_value', 'value': ' Strategy that executes an order at a fixed price that can be matched by any tokenId for the collection. ', 'block': False}, 'name': {'kind': 'name', 'value': 'ANY_ITEM_FROM_COLLECTION'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': {'kind': 'string_value', 'value': ' Strategy that executes an order at a fixed price that can be matched by any tokenId in a set of tokenIds. ', 'block': False}, 'name': {'kind': 'name', 'value': 'ANY_ITEM_FROM_SET'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': {'kind': 'string_value', 'value': ' Strategy to launch a Dutch Auction for a token where the price decreases linearly until a specified timestamp and end price defined by the seller. ', 'block': False}, 'name': {'kind': 'name', 'value': 'DUTCH_AUCTION'}, 'directives': []}, {'kind': 'enum_value_definition', 'description': {'kind': 'string_value', 'value': ' Strategy to set up an order that can only be executed by a specific address. ', 'block': False}, 'name': {'kind': 'name', 'value': 'PRIVATE_SALE'}, 'directives': []}]}, {'kind': 'object_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'Marketplace'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'entity'}, 'arguments': []}, {'kind': 'directive', 'name': {'kind': 'name', 'value': 'regularPolling'}, 'arguments': []}], 'interfaces': [], 'fields': [{'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': \" Smart contract address of the protocol's main contract (Factory, Registry, etc) \", 'block': False}, 'name': {'kind': 'name', 'value': 'id'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'ID'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Name of the NFT marketplace, for example LooksRare ', 'block': False}, 'name': {'kind': 'name', 'value': 'name'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Slug of the NFT marketplace, for example looksrare ', 'block': False}, 'name': {'kind': 'name', 'value': 'slug'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' The blockchain network this subgraph is indexing on. ', 'block': False}, 'name': {'kind': 'name', 'value': 'network'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Network'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Version of the subgraph schema, in SemVer format (e.g. 1.0.0) ', 'block': False}, 'name': {'kind': 'name', 'value': 'schemaVersion'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Version of the subgraph implementation, in SemVer format (e.g. 1.0.0) ', 'block': False}, 'name': {'kind': 'name', 'value': 'subgraphVersion'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Version of the methodology used to compute metrics, loosely based on SemVer format (e.g. 1.0.0) ', 'block': False}, 'name': {'kind': 'name', 'value': 'methodologyVersion'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Number of collections listed on the marketplace. ', 'block': False}, 'name': {'kind': 'name', 'value': 'collectionCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Trade count of the all collections on the marketplace. ', 'block': False}, 'name': {'kind': 'name', 'value': 'tradeCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Cumulative trade volume (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'cumulativeTradeVolumeETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to the marketplace protocol, aka protocol fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'marketplaceRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to creator, aka royalty fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'creatorRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Sum of marketplaceRevenueETH and creatorRevenueETH. ', 'block': False}, 'name': {'kind': 'name', 'value': 'totalRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Cumulative unique traders ', 'block': False}, 'name': {'kind': 'name', 'value': 'cumulativeUniqueTraders'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}]}, {'kind': 'object_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'Collection'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'entity'}, 'arguments': []}, {'kind': 'directive', 'name': {'kind': 'name', 'value': 'regularPolling'}, 'arguments': []}], 'interfaces': [], 'fields': [{'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Contract address. ', 'block': False}, 'name': {'kind': 'name', 'value': 'id'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'ID'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Collection name, mirrored from the smart contract. Leave null if not available. ', 'block': False}, 'name': {'kind': 'name', 'value': 'name'}, 'directives': [], 'arguments': [], 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Collection symbol, mirrored from the smart contract. Leave null if not available. ', 'block': False}, 'name': {'kind': 'name', 'value': 'symbol'}, 'directives': [], 'arguments': [], 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Total supply of the collection, mirrored from the smart contract. ', 'block': False}, 'name': {'kind': 'name', 'value': 'totalSupply'}, 'directives': [], 'arguments': [], 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' NFT Standard the collection uses. ', 'block': False}, 'name': {'kind': 'name', 'value': 'nftStandard'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'NftStandard'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Royalty fee rate in percentage. E.g. 2.5% should be 2.5 ', 'block': False}, 'name': {'kind': 'name', 'value': 'royaltyFee'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Cumulative trade volume (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'cumulativeTradeVolumeETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to the marketplace protocol, aka protocol fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'marketplaceRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to creator, aka royalty fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'creatorRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Sum of marketplaceRevenue and creatorRevenue. ', 'block': False}, 'name': {'kind': 'name', 'value': 'totalRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Trade count of the collection on the marketplace. ', 'block': False}, 'name': {'kind': 'name', 'value': 'tradeCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Buyer count. ', 'block': False}, 'name': {'kind': 'name', 'value': 'buyerCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Seller count. ', 'block': False}, 'name': {'kind': 'name', 'value': 'sellerCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Trades of the collection. ', 'block': False}, 'name': {'kind': 'name', 'value': 'trades'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'derivedFrom'}, 'arguments': [{'kind': 'argument', 'name': {'kind': 'name', 'value': 'field'}, 'value': {'kind': 'string_value', 'value': 'collection', 'block': False}}]}], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'list_type', 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Trade'}}}}}}]}, {'kind': 'object_type_definition', 'description': {'kind': 'string_value', 'value': ' Trades exist such as a combination of taker/order and bid/ask. ', 'block': False}, 'name': {'kind': 'name', 'value': 'Trade'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'entity'}, 'arguments': []}, {'kind': 'directive', 'name': {'kind': 'name', 'value': 'transaction'}, 'arguments': []}], 'interfaces': [], 'fields': [{'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' { Transaction hash }-{ Log index }-{ (optional) ID within bundle } ', 'block': False}, 'name': {'kind': 'name', 'value': 'id'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'ID'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Event transaction hash. ', 'block': False}, 'name': {'kind': 'name', 'value': 'transactionHash'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Event log index. ', 'block': False}, 'name': {'kind': 'name', 'value': 'logIndex'}, 'directives': [], 'arguments': [], 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Block timestamp where the trade is executed. ', 'block': False}, 'name': {'kind': 'name', 'value': 'timestamp'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Block number where the trade is executed. ', 'block': False}, 'name': {'kind': 'name', 'value': 'blockNumber'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Whether the trade is in a bundle. ', 'block': False}, 'name': {'kind': 'name', 'value': 'isBundle'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Boolean'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Collection involved ', 'block': False}, 'name': {'kind': 'name', 'value': 'collection'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Collection'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Token ID of the traded NFT. ', 'block': False}, 'name': {'kind': 'name', 'value': 'tokenId'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' The amount of token to transfer. It is set at 1 except for ERC1155 batch. ', 'block': False}, 'name': {'kind': 'name', 'value': 'amount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Price (in ETH). If only 1 tokenId is involved, then the price is determined by the token only. If the trade is incurred by a batch purchasing (available in x2y2), then the price is the average price in the batch. ', 'block': False}, 'name': {'kind': 'name', 'value': 'priceETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Stretegy that the trade is executed. ', 'block': False}, 'name': {'kind': 'name', 'value': 'strategy'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'SaleStrategy'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Buyer account address ', 'block': False}, 'name': {'kind': 'name', 'value': 'buyer'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Seller account address ', 'block': False}, 'name': {'kind': 'name', 'value': 'seller'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'String'}}}}]}, {'kind': 'object_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'MarketplaceDailySnapshot'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'entity'}, 'arguments': []}, {'kind': 'directive', 'name': {'kind': 'name', 'value': 'dailySnapshot'}, 'arguments': []}], 'interfaces': [], 'fields': [{'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' { Contract address }-{# of days since Unix epoch time} ', 'block': False}, 'name': {'kind': 'name', 'value': 'id'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'ID'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' The marketplace that this snapshot belongs to. ', 'block': False}, 'name': {'kind': 'name', 'value': 'marketplace'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Marketplace'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Block number where the snapshot is taken. ', 'block': False}, 'name': {'kind': 'name', 'value': 'blockNumber'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Block timestamp when the snapshot is taken. ', 'block': False}, 'name': {'kind': 'name', 'value': 'timestamp'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Number of collections listed on the marketplace. ', 'block': False}, 'name': {'kind': 'name', 'value': 'collectionCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Cumulative trade volume (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'cumulativeTradeVolumeETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to the marketplace protocol, aka protocol fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'marketplaceRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to creator, aka royalty fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'creatorRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Sum of marketplaceRevenueETH and creatorRevenueETH. ', 'block': False}, 'name': {'kind': 'name', 'value': 'totalRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Trade count of the all collections on the marketplace. ', 'block': False}, 'name': {'kind': 'name', 'value': 'tradeCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Cumulative unique traders ', 'block': False}, 'name': {'kind': 'name', 'value': 'cumulativeUniqueTraders'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Daily active traders ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyActiveTraders'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Number of traded collections of the day ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyTradedCollectionCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Number of traded items of the day ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyTradedItemCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}]}, {'kind': 'object_type_definition', 'description': None, 'name': {'kind': 'name', 'value': 'CollectionDailySnapshot'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'entity'}, 'arguments': []}, {'kind': 'directive', 'name': {'kind': 'name', 'value': 'dailySnapshot'}, 'arguments': []}], 'interfaces': [], 'fields': [{'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' { Contract address }-{# of days since epoch unix time } ', 'block': False}, 'name': {'kind': 'name', 'value': 'id'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'ID'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' The collection that this snapshot belongs to. ', 'block': False}, 'name': {'kind': 'name', 'value': 'collection'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Collection'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Block number where the snapshot is taken. ', 'block': False}, 'name': {'kind': 'name', 'value': 'blockNumber'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Block timestamp when the snapshot is taken. ', 'block': False}, 'name': {'kind': 'name', 'value': 'timestamp'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigInt'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Royalty fee rate in percentage. E.g. 2.5% should be 2.5 ', 'block': False}, 'name': {'kind': 'name', 'value': 'royaltyFee'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Minimum sale price of the day (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyMinSalePrice'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Maximum sale price of the day (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyMaxSalePrice'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Cumulative trade volume (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'cumulativeTradeVolumeETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Daily trade volume (in ETH) ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyTradeVolumeETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to the marketplace protocol, aka protocol fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'marketplaceRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Revenue that goes to creator, aka royalty fee. ', 'block': False}, 'name': {'kind': 'name', 'value': 'creatorRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Sum of marketplaceRevenue and creatorRevenue. ', 'block': False}, 'name': {'kind': 'name', 'value': 'totalRevenueETH'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'BigDecimal'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Trade count of the collection on the marketplace. ', 'block': False}, 'name': {'kind': 'name', 'value': 'tradeCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}, {'kind': 'field_definition', 'description': {'kind': 'string_value', 'value': ' Number of traded items of the day ', 'block': False}, 'name': {'kind': 'name', 'value': 'dailyTradedItemCount'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'Int'}}}}]}, {'kind': 'object_type_definition', 'description': {'kind': 'string_value', 'value': ' A helper utility entity that works as a set for deduplication purpose. ', 'block': False}, 'name': {'kind': 'name', 'value': '_Item'}, 'directives': [{'kind': 'directive', 'name': {'kind': 'name', 'value': 'entity'}, 'arguments': []}], 'interfaces': [], 'fields': [{'kind': 'field_definition', 'description': None, 'name': {'kind': 'name', 'value': 'id'}, 'directives': [], 'arguments': [], 'type': {'kind': 'non_null_type', 'type': {'kind': 'named_type', 'name': {'kind': 'name', 'value': 'ID'}}}}]}]}\n"
     ]
    }
   ],
   "source": [
    "with open('../assets/schemas/opensea/opensea_original_schema.graphql', 'r') as schema_file:\n",
    "    schema_str = schema_file.read()\n",
    "\n",
    "parsed = parse(schema_str)\n",
    "print(parsed.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write whole schema\n",
    "schema_string = print_ast(parsed)  \n",
    "\n",
    "with open('../assets/schemas/opensea/opensea_test_schema.graphql', 'w') as schema_file:\n",
    "    schema_file.write(schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'type Marketplace @entity @regularPolling {\\n  \" Smart contract address of the protocol\\'s main contract (Factory, Registry, etc) \"\\n  id: ID!\\n  \" Name of the NFT marketplace, for example LooksRare \"\\n  name: String!\\n  \" Slug of the NFT marketplace, for example looksrare \"\\n  slug: String!\\n  \" The blockchain network this subgraph is indexing on. \"\\n  network: Network!\\n  \" Version of the subgraph schema, in SemVer format (e.g. 1.0.0) \"\\n  schemaVersion: String!\\n  \" Version of the subgraph implementation, in SemVer format (e.g. 1.0.0) \"\\n  subgraphVersion: String!\\n  \" Version of the methodology used to compute metrics, loosely based on SemVer format (e.g. 1.0.0) \"\\n  methodologyVersion: String!\\n  \" Number of collections listed on the marketplace. \"\\n  collectionCount: Int!\\n  \" Trade count of the all collections on the marketplace. \"\\n  tradeCount: Int!\\n  \" Cumulative trade volume (in ETH) \"\\n  cumulativeTradeVolumeETH: BigDecimal!\\n  \" Revenue that goes to the marketplace protocol, aka protocol fee. \"\\n  marketplaceRevenueETH: BigDecimal!\\n  \" Revenue that goes to creator, aka royalty fee. \"\\n  creatorRevenueETH: BigDecimal!\\n  \" Sum of marketplaceRevenueETH and creatorRevenueETH. \"\\n  totalRevenueETH: BigDecimal!\\n  \" Cumulative unique traders \"\\n  cumulativeUniqueTraders: Int!\\n}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk by entity\n",
    "schema_string = print_ast(parsed.definitions[3]) \n",
    "\n",
    "# with open('../assets/schemas/opensea/opensea_test_schema.graphql', 'w') as schema_file:\n",
    "#     schema_file.write(schema_string) \n",
    "schema_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regularPolling'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.definitions[3].directives[1].name.value # directives are the decorators for the entity (@entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marketplace'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.definitions[3].name.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type Marketplace @entity @regularPolling {\n",
      "  \" Smart contract address of the protocol's main contract (Factory, Registry, etc) \"\n",
      "  id: ID!\n",
      "  \" Name of the NFT marketplace, for example LooksRare \"\n",
      "  name: String!\n",
      "  \" Slug of the NFT marketplace, for example looksrare \"\n",
      "  slug: String!\n",
      "  \" The blockchain network this subgraph is indexing on. \"\n",
      "  network: Network!\n",
      "  \" Version of the subgraph schema, in SemVer format (e.g. 1.0.0) \"\n",
      "  schemaVersion: String!\n",
      "  \" Version of the subgraph implementation, in SemVer format (e.g. 1.0.0) \"\n",
      "  subgraphVersion: String!\n",
      "  \" Version of the methodology used to compute metrics, loosely based on SemVer format (e.g. 1.0.0) \"\n",
      "  methodologyVersion: String!\n",
      "  \" Number of collections listed on the marketplace. \"\n",
      "  collectionCount: Int!\n",
      "  \" Trade count of the all collections on the marketplace. \"\n",
      "  tradeCount: Int!\n",
      "  \" Cumulative trade volume (in ETH) \"\n",
      "  cumulativeTradeVolumeETH: BigDecimal!\n",
      "  \" Revenue that goes to the marketplace protocol, aka protocol fee. \"\n",
      "  marketplaceRevenueETH: BigDecimal!\n",
      "  \" Revenue that goes to creator, aka royalty fee. \"\n",
      "  creatorRevenueETH: BigDecimal!\n",
      "  \" Sum of marketplaceRevenueETH and creatorRevenueETH. \"\n",
      "  totalRevenueETH: BigDecimal!\n",
      "  \" Cumulative unique traders \"\n",
      "  cumulativeUniqueTraders: Int!\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(print_ast(parsed.definitions[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Smart contract address of the protocol's main contract (Factory, Registry, etc) \"\n",
      "id: ID!\n"
     ]
    }
   ],
   "source": [
    "print(print_ast(parsed.definitions[3].fields[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network\n"
     ]
    }
   ],
   "source": [
    "# parsed.definitions[3].fields[3] == Marketplace.network: Network! - we want to find out how these are linked so that we can pull in the relevant entity\n",
    "# name is the column name for the field \n",
    "print(parsed.definitions[3].fields[3].name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The blockchain network this subgraph is indexing on. \n"
     ]
    }
   ],
   "source": [
    "# description is the documentation field \n",
    "print(parsed.definitions[3].fields[3].description.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "print(parsed.definitions[3].fields[3].directives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "print(parsed.definitions[3].fields[3].arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network\n"
     ]
    }
   ],
   "source": [
    "# so here, we find the value of the field that it is, there doesn't seem to be a clear way to say this is an entity that it references\n",
    "# NonNullTypeNode at 1436:1444 | NamedTypeNode at 1436:1443\n",
    "print(parsed.definitions[3].fields[3].type.type.name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigDecimal\n"
     ]
    }
   ],
   "source": [
    "print(parsed.definitions[3].fields[9].type.type.name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/l2x6pccx1qdbhd_r0px4crjm0000gp/T/ipykernel_54346/798662062.py:10: DeprecationWarning: open_text is deprecated. Use files() instead. Refer to https://importlib-resources.readthedocs.io/en/latest/using.html#migrating-from-legacy for migration advice.\n",
      "  with pkg_resources.open_text(package_name, resource_name) as file:\n",
      "Failed to update token costs. Using static costs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt-4': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4o': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'cache_read_input_token_cost': 1.25e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-audio-preview': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_audio_token': 0.0001, 'output_cost_per_token': 1e-05, 'output_cost_per_audio_token': 0.0002, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_audio_input': True, 'supports_audio_output': True}, 'gpt-4o-audio-preview-2024-10-01': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_audio_token': 0.0001, 'output_cost_per_token': 1e-05, 'output_cost_per_audio_token': 0.0002, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_audio_input': True, 'supports_audio_output': True}, 'gpt-4o-mini': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-mini-2024-07-18': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'o1-mini': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'o1-mini-2024-09-12': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'o1-preview': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'o1-preview-2024-09-12': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'chatgpt-4o-latest': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-2024-05-13': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'cache_read_input_token_cost': 1.25e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-turbo-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-0314': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-0613': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-32k': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-32k-0314': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-32k-0613': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-turbo': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-turbo-2024-04-09': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-1106-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-0125-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-vision-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-1106-vision-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo': {'max_tokens': 4097, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-0301': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-3.5-turbo-0613': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-1106': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-0125': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-16k': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-3.5-turbo-16k-0613': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'ft:gpt-3.5-turbo': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-3.5-turbo-0125': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-3.5-turbo-1106': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-3.5-turbo-0613': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-4-0613': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing'}, 'ft:gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 3.75e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'ft:gpt-4o-mini-2024-07-18': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'ft:davinci-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'ft:babbage-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 4e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'text-embedding-3-large': {'max_tokens': 8191, 'max_input_tokens': 8191, 'output_vector_size': 3072, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-embedding-3-small': {'max_tokens': 8191, 'max_input_tokens': 8191, 'output_vector_size': 1536, 'input_cost_per_token': 2e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-embedding-ada-002': {'max_tokens': 8191, 'max_input_tokens': 8191, 'output_vector_size': 1536, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-embedding-ada-002-v2': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-moderation-stable': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 0, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'moderations'}, 'text-moderation-007': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 0, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'moderations'}, 'text-moderation-latest': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 0, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'moderations'}, '256-x-256/dall-e-2': {'mode': 'image_generation', 'input_cost_per_pixel': 2.4414e-07, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, '512-x-512/dall-e-2': {'mode': 'image_generation', 'input_cost_per_pixel': 6.86e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, '1024-x-1024/dall-e-2': {'mode': 'image_generation', 'input_cost_per_pixel': 1.9e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'hd/1024-x-1792/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 6.539e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'hd/1792-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 6.539e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'hd/1024-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 7.629e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'standard/1024-x-1792/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 4.359e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'standard/1792-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 4.359e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'standard/1024-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 3.81469e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'whisper-1': {'mode': 'audio_transcription', 'input_cost_per_second': 0, 'output_cost_per_second': 0.0001, 'litellm_provider': 'openai'}, 'tts-1': {'mode': 'audio_speech', 'input_cost_per_character': 1.5e-05, 'litellm_provider': 'openai'}, 'tts-1-hd': {'mode': 'audio_speech', 'input_cost_per_character': 3e-05, 'litellm_provider': 'openai'}, 'azure/tts-1': {'mode': 'audio_speech', 'input_cost_per_character': 1.5e-05, 'litellm_provider': 'azure'}, 'azure/tts-1-hd': {'mode': 'audio_speech', 'input_cost_per_character': 3e-05, 'litellm_provider': 'azure'}, 'azure/whisper-1': {'mode': 'audio_transcription', 'input_cost_per_second': 0, 'output_cost_per_second': 0.0001, 'litellm_provider': 'azure'}, 'azure/o1-mini': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/o1-mini-2024-09-12': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/o1-preview': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/o1-preview-2024-09-12': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/gpt-4o': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'cache_read_input_token_cost': 1.25e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'azure/gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.75e-06, 'output_cost_per_token': 1.1e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'azure/gpt-4o-2024-05-13': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'azure/global-standard/gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'azure/global-standard/gpt-4o-mini': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'azure/gpt-4o-mini': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.65e-07, 'output_cost_per_token': 6.6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'azure/gpt-4-turbo-2024-04-09': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True}, 'azure/gpt-4-0125-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-4-1106-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-4-0613': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-4-32k-0613': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'azure', 'mode': 'chat'}, 'azure/gpt-4-32k': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'azure', 'mode': 'chat'}, 'azure/gpt-4': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-4-turbo': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-4-turbo-vision-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_vision': True}, 'azure/gpt-35-turbo-16k-0613': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-35-turbo-1106': {'max_tokens': 4096, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-0613': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-0301': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-0125': {'max_tokens': 4096, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-16k': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'azure', 'mode': 'chat'}, 'azure/gpt-35-turbo': {'max_tokens': 4096, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-3.5-turbo-instruct-0914': {'max_tokens': 4097, 'max_input_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'azure/gpt-35-turbo-instruct': {'max_tokens': 4097, 'max_input_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'azure/gpt-35-turbo-instruct-0914': {'max_tokens': 4097, 'max_input_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'azure/mistral-large-latest': {'max_tokens': 32000, 'max_input_tokens': 32000, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/mistral-large-2402': {'max_tokens': 32000, 'max_input_tokens': 32000, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/command-r-plus': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/ada': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/text-embedding-ada-002': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/text-embedding-3-large': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/text-embedding-3-small': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 2e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/standard/1024-x-1024/dall-e-3': {'input_cost_per_pixel': 3.81469e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/hd/1024-x-1024/dall-e-3': {'input_cost_per_pixel': 7.629e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/standard/1024-x-1792/dall-e-3': {'input_cost_per_pixel': 4.359e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/standard/1792-x-1024/dall-e-3': {'input_cost_per_pixel': 4.359e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/hd/1024-x-1792/dall-e-3': {'input_cost_per_pixel': 6.539e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/hd/1792-x-1024/dall-e-3': {'input_cost_per_pixel': 6.539e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/standard/1024-x-1024/dall-e-2': {'input_cost_per_pixel': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure_ai/jamba-instruct': {'max_tokens': 4096, 'max_input_tokens': 70000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat'}, 'azure_ai/mistral-large': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_function_calling': True}, 'azure_ai/mistral-small': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'mode': 'chat'}, 'azure_ai/Meta-Llama-3-70B-Instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.1e-06, 'output_cost_per_token': 3.7e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat'}, 'azure_ai/Meta-Llama-3.1-8B-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6.1e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice'}, 'azure_ai/Meta-Llama-3.1-70B-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.68e-06, 'output_cost_per_token': 3.54e-06, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice'}, 'azure_ai/Meta-Llama-3.1-405B-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 5.33e-06, 'output_cost_per_token': 1.6e-05, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice'}, 'azure_ai/cohere-rerank-v3-multilingual': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'rerank'}, 'azure_ai/cohere-rerank-v3-english': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'rerank'}, 'azure_ai/Cohere-embed-v3-english': {'max_tokens': 512, 'max_input_tokens': 512, 'output_vector_size': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'embedding', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice'}, 'azure_ai/Cohere-embed-v3-multilingual': {'max_tokens': 512, 'max_input_tokens': 512, 'output_vector_size': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'embedding', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice'}, 'babbage-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 4e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'davinci-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'gpt-3.5-turbo-instruct': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'gpt-3.5-turbo-instruct-0914': {'max_tokens': 4097, 'max_input_tokens': 8192, 'max_output_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'claude-instant-1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-06, 'output_cost_per_token': 5.51e-06, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'mistral/mistral-tiny': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-small': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'supports_function_calling': True, 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-small-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'supports_function_calling': True, 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-medium': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-06, 'output_cost_per_token': 8.1e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-medium-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-06, 'output_cost_per_token': 8.1e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-medium-2312': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-06, 'output_cost_per_token': 8.1e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-large-latest': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/mistral-large-2402': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/mistral-large-2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/pixtral-12b-2409': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True, 'supports_vision': True}, 'mistral/open-mistral-7b': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/open-mixtral-8x7b': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/open-mixtral-8x22b': {'max_tokens': 8191, 'max_input_tokens': 64000, 'max_output_tokens': 8191, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/codestral-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/codestral-2405': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/open-mistral-nemo': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 3e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/open-mistral-nemo-2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 3e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/open-codestral-mamba': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/codestral-mamba-latest': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/mistral-embed': {'max_tokens': 8192, 'max_input_tokens': 8192, 'input_cost_per_token': 1e-07, 'litellm_provider': 'mistral', 'mode': 'embedding'}, 'deepseek-chat': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.4e-07, 'input_cost_per_token_cache_hit': 1.4e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'deepseek', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True, 'supports_tool_choice': True, 'supports_prompt_caching': True}, 'codestral/codestral-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'codestral', 'mode': 'chat', 'source': 'https://docs.mistral.ai/capabilities/code_generation/', 'supports_assistant_prefill': True}, 'codestral/codestral-2405': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'codestral', 'mode': 'chat', 'source': 'https://docs.mistral.ai/capabilities/code_generation/', 'supports_assistant_prefill': True}, 'text-completion-codestral/codestral-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'text-completion-codestral', 'mode': 'completion', 'source': 'https://docs.mistral.ai/capabilities/code_generation/'}, 'text-completion-codestral/codestral-2405': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'text-completion-codestral', 'mode': 'completion', 'source': 'https://docs.mistral.ai/capabilities/code_generation/'}, 'deepseek-coder': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.4e-07, 'input_cost_per_token_cache_hit': 1.4e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'deepseek', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True, 'supports_tool_choice': True, 'supports_prompt_caching': True}, 'groq/llama2-70b-4096': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 8e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-8b-8192': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 8e-08, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-70b-8192': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama-3.1-8b-instant': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 8e-08, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama-3.1-70b-versatile': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama-3.1-405b-reasoning': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/mixtral-8x7b-32768': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 2.4e-07, 'output_cost_per_token': 2.4e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/gemma-7b-it': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 7e-08, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/gemma2-9b-it': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-groq-70b-8192-tool-use-preview': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 8.9e-07, 'output_cost_per_token': 8.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-groq-8b-8192-tool-use-preview': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.9e-07, 'output_cost_per_token': 1.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'cerebras/llama3.1-8b': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'cerebras', 'mode': 'chat', 'supports_function_calling': True}, 'cerebras/llama3.1-70b': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cerebras', 'mode': 'chat', 'supports_function_calling': True}, 'friendliai/mixtral-8x7b-instruct-v0-1': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 4e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'friendliai', 'mode': 'chat', 'supports_function_calling': True}, 'friendliai/meta-llama-3-8b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'friendliai', 'mode': 'chat', 'supports_function_calling': True}, 'friendliai/meta-llama-3-70b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 8e-07, 'output_cost_per_token': 8e-07, 'litellm_provider': 'friendliai', 'mode': 'chat', 'supports_function_calling': True}, 'claude-instant-1.2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-07, 'output_cost_per_token': 5.51e-07, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'claude-2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'claude-2.1': {'max_tokens': 8191, 'max_input_tokens': 200000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'claude-3-haiku-20240307': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'cache_creation_input_token_cost': 3e-07, 'cache_read_input_token_cost': 3e-08, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 264, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-haiku-latest': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'cache_creation_input_token_cost': 3e-07, 'cache_read_input_token_cost': 3e-08, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 264, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-opus-20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'cache_creation_input_token_cost': 1.875e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 395, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-opus-latest': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'cache_creation_input_token_cost': 1.875e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 395, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-sonnet-20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-5-sonnet-20240620': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-5-sonnet-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-5-sonnet-latest': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'text-bison': {'max_tokens': 2048, 'max_input_tokens': 8192, 'max_output_tokens': 2048, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison@001': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison@002': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison32k': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison32k@002': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-unicorn': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 2.8e-05, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-unicorn@001': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 2.8e-05, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison@001': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison@002': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison-32k': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison-32k@002': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison@001': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison@002': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison32k': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison-32k@002': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko@001': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko@002': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko-latest': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison@latest': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison@001': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison@002': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison-32k': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison-32k@002': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-pro': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'gemini-1.0-pro': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models'}, 'gemini-1.0-pro-001': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-ultra': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 2048, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-ultra-001': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 2048, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-pro-002': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 1.25e-06, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 2.5e-06, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 5e-06, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 1e-05, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-002': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 1.25e-06, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 2.5e-06, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 5e-06, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 1e-05, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro'}, 'gemini-1.5-pro-001': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 1.25e-06, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 2.5e-06, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 5e-06, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 1e-05, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-preview-0514': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 7.8125e-08, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 1.5625e-07, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 3.125e-07, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 6.25e-07, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-preview-0215': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 7.8125e-08, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 1.5625e-07, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 3.125e-07, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 6.25e-07, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-preview-0409': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 7.8125e-08, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 1.5625e-07, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 3.125e-07, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 6.25e-07, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 3e-07, 'output_cost_per_character': 7.5e-08, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': 1.5e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 4.688e-09, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 4.6875e-09, 'output_cost_per_character': 1.875e-08, 'output_cost_per_token_above_128k_tokens': 9.375e-09, 'output_cost_per_character_above_128k_tokens': 3.75e-08, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash-002': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 3e-07, 'output_cost_per_character': 7.5e-08, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': 1.5e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash'}, 'gemini-1.5-flash-001': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 3e-07, 'output_cost_per_character': 7.5e-08, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': 1.5e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash-preview-0514': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 4.6875e-09, 'output_cost_per_character': 1.875e-08, 'output_cost_per_token_above_128k_tokens': 9.375e-09, 'output_cost_per_character_above_128k_tokens': 3.75e-08, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-pro-experimental': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_token': 0, 'output_cost_per_token': 0, 'input_cost_per_character': 0, 'output_cost_per_character': 0, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': False, 'supports_tool_choice': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental'}, 'gemini-flash-experimental': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_token': 0, 'output_cost_per_token': 0, 'input_cost_per_character': 0, 'output_cost_per_character': 0, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': False, 'supports_tool_choice': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental'}, 'gemini-pro-vision': {'max_tokens': 2048, 'max_input_tokens': 16384, 'max_output_tokens': 2048, 'max_images_per_prompt': 16, 'max_videos_per_prompt': 1, 'max_video_length': 2, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'vertex_ai-vision-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-pro-vision': {'max_tokens': 2048, 'max_input_tokens': 16384, 'max_output_tokens': 2048, 'max_images_per_prompt': 16, 'max_videos_per_prompt': 1, 'max_video_length': 2, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'vertex_ai-vision-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-pro-vision-001': {'max_tokens': 2048, 'max_input_tokens': 16384, 'max_output_tokens': 2048, 'max_images_per_prompt': 16, 'max_videos_per_prompt': 1, 'max_video_length': 2, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'vertex_ai-vision-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'medlm-medium': {'max_tokens': 8192, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_character': 5e-07, 'output_cost_per_character': 1e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'medlm-large': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_character': 5e-06, 'output_cost_per_character': 1.5e-05, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'vertex_ai/claude-3-sonnet@20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-5-sonnet@20240620': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-5-sonnet-v2@20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-haiku@20240307': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-opus@20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/meta/llama3-405b-instruct-maas': {'max_tokens': 32000, 'max_input_tokens': 32000, 'max_output_tokens': 32000, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'}, 'vertex_ai/meta/llama3-70b-instruct-maas': {'max_tokens': 32000, 'max_input_tokens': 32000, 'max_output_tokens': 32000, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'}, 'vertex_ai/meta/llama3-8b-instruct-maas': {'max_tokens': 32000, 'max_input_tokens': 32000, 'max_output_tokens': 32000, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'}, 'vertex_ai/meta/llama-3.2-90b-vision-instruct-maas': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'supports_system_messages': True, 'supports_vision': True, 'source': 'https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas'}, 'vertex_ai/mistral-large@latest': {'max_tokens': 8191, 'max_input_tokens': 128000, 'max_output_tokens': 8191, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/mistral-large@2407': {'max_tokens': 8191, 'max_input_tokens': 128000, 'max_output_tokens': 8191, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/mistral-nemo@latest': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/jamba-1.5-mini@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5-large@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5-mini': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5-large': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/mistral-nemo@2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/codestral@latest': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/codestral@2405': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/imagegeneration@006': {'cost_per_image': 0.02, 'litellm_provider': 'vertex_ai-image-models', 'mode': 'image_generation', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'vertex_ai/imagen-3.0-generate-001': {'cost_per_image': 0.04, 'litellm_provider': 'vertex_ai-image-models', 'mode': 'image_generation', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'vertex_ai/imagen-3.0-fast-generate-001': {'cost_per_image': 0.02, 'litellm_provider': 'vertex_ai-image-models', 'mode': 'image_generation', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'text-embedding-004': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models'}, 'text-multilingual-embedding-002': {'max_tokens': 2048, 'max_input_tokens': 2048, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models'}, 'textembedding-gecko': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko-multilingual': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko-multilingual@001': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko@001': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko@003': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-embedding-preview-0409': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'input_cost_per_token_batch_requests': 5e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'text-multilingual-embedding-preview-0409': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/chat-bison': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/chat-bison-001': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison-001': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison-safety-off': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison-safety-recitation-off': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-1.5-flash-002': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-001': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-latest': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-8b-exp-0924': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-8b-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-pro': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'input_cost_per_token_above_128k_tokens': 7e-07, 'output_cost_per_token': 1.05e-06, 'output_cost_per_token_above_128k_tokens': 2.1e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-1.5-pro': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-002': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-001': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-exp-0801': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-latest': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-06, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-pro-vision': {'max_tokens': 2048, 'max_input_tokens': 30720, 'max_output_tokens': 2048, 'input_cost_per_token': 3.5e-07, 'input_cost_per_token_above_128k_tokens': 7e-07, 'output_cost_per_token': 1.05e-06, 'output_cost_per_token_above_128k_tokens': 2.1e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-gemma-2-27b-it': {'max_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 1.05e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-gemma-2-9b-it': {'max_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 1.05e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'command-r': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-r-08-2024': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-light': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cohere_chat', 'mode': 'chat'}, 'command-r-plus': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-r-plus-08-2024': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-nightly': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'cohere', 'mode': 'completion'}, 'command': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'cohere', 'mode': 'completion'}, 'rerank-english-v3.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'rerank-multilingual-v3.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'rerank-english-v2.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'rerank-multilingual-v2.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'embed-english-v3.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'input_cost_per_image': 0.0001, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding', 'supports_image_input': True}, 'embed-english-light-v3.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-multilingual-v3.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-english-v2.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-english-light-v2.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-multilingual-v2.0': {'max_tokens': 768, 'max_input_tokens': 768, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'replicate/meta/llama-2-13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-13b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-7b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-7b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-70b': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-70b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-8b': {'max_tokens': 8086, 'max_input_tokens': 8086, 'max_output_tokens': 8086, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-8b-instruct': {'max_tokens': 8086, 'max_input_tokens': 8086, 'max_output_tokens': 8086, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/mistralai/mistral-7b-v0.1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/mistralai/mistral-7b-instruct-v0.2': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/mistralai/mixtral-8x7b-instruct-v0.1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 1e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'openrouter/deepseek/deepseek-coder': {'max_tokens': 4096, 'max_input_tokens': 32000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.4e-07, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/microsoft/wizardlm-2-8x22b:nitro': {'max_tokens': 65536, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/google/gemini-pro-1.5': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 7.5e-06, 'input_cost_per_image': 0.00265, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/mistralai/mixtral-8x22b-instruct': {'max_tokens': 65536, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 6.5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/cohere/command-r-plus': {'max_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/databricks/dbrx-instruct': {'max_tokens': 32768, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-3-haiku': {'max_tokens': 200000, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'input_cost_per_image': 0.0004, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/anthropic/claude-3-haiku-20240307': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 264}, 'anthropic/claude-3-5-sonnet-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'anthropic/claude-3-5-sonnet-latest': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'openrouter/anthropic/claude-3.5-sonnet': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True}, 'openrouter/anthropic/claude-3.5-sonnet:beta': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159}, 'openrouter/anthropic/claude-3-sonnet': {'max_tokens': 200000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'input_cost_per_image': 0.0048, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/mistralai/mistral-large': {'max_tokens': 32000, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/cognitivecomputations/dolphin-mixtral-8x7b': {'max_tokens': 32769, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/google/gemini-pro-vision': {'max_tokens': 45875, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 3.75e-07, 'input_cost_per_image': 0.0025, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/fireworks/firellava-13b': {'max_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-8b-instruct:free': {'max_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-8b-instruct:extended': {'max_tokens': 16384, 'input_cost_per_token': 2.25e-07, 'output_cost_per_token': 2.25e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-70b-instruct:nitro': {'max_tokens': 8192, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-70b-instruct': {'max_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/openai/o1-mini': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/o1-mini-2024-09-12': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/o1-preview': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/o1-preview-2024-09-12': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/gpt-4o': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True}, 'openrouter/openai/gpt-4o-2024-05-13': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True}, 'openrouter/openai/gpt-4-vision-preview': {'max_tokens': 130000, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'input_cost_per_image': 0.01445, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/openai/gpt-3.5-turbo': {'max_tokens': 4095, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/openai/gpt-3.5-turbo-16k': {'max_tokens': 16383, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/openai/gpt-4': {'max_tokens': 8192, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-instant-v1': {'max_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-06, 'output_cost_per_token': 5.51e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-2': {'max_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.102e-05, 'output_cost_per_token': 3.268e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-3-opus': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 395}, 'openrouter/google/palm-2-chat-bison': {'max_tokens': 25804, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/google/palm-2-codechat-bison': {'max_tokens': 20070, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-2-13b-chat': {'max_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-2-70b-chat': {'max_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/codellama-34b-instruct': {'max_tokens': 8192, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/nousresearch/nous-hermes-llama2-13b': {'max_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/mancer/weaver': {'max_tokens': 8000, 'input_cost_per_token': 5.625e-06, 'output_cost_per_token': 5.625e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/gryphe/mythomax-l2-13b': {'max_tokens': 8192, 'input_cost_per_token': 1.875e-06, 'output_cost_per_token': 1.875e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/jondurbin/airoboros-l2-70b-2.1': {'max_tokens': 4096, 'input_cost_per_token': 1.3875e-05, 'output_cost_per_token': 1.3875e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/undi95/remm-slerp-l2-13b': {'max_tokens': 6144, 'input_cost_per_token': 1.875e-06, 'output_cost_per_token': 1.875e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/pygmalionai/mythalion-13b': {'max_tokens': 4096, 'input_cost_per_token': 1.875e-06, 'output_cost_per_token': 1.875e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/mistralai/mistral-7b-instruct': {'max_tokens': 8192, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/mistralai/mistral-7b-instruct:free': {'max_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'j2-ultra': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'ai21', 'mode': 'completion'}, 'jamba-1.5-mini@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5-large@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5-mini': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5-large': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'j2-mid': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 1e-05, 'litellm_provider': 'ai21', 'mode': 'completion'}, 'j2-light': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'ai21', 'mode': 'completion'}, 'dolphin': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'nlp_cloud', 'mode': 'completion'}, 'chatdolphin': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'nlp_cloud', 'mode': 'chat'}, 'luminous-base': {'max_tokens': 2048, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 3.3e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'completion'}, 'luminous-base-control': {'max_tokens': 2048, 'input_cost_per_token': 3.75e-05, 'output_cost_per_token': 4.125e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'chat'}, 'luminous-extended': {'max_tokens': 2048, 'input_cost_per_token': 4.5e-05, 'output_cost_per_token': 4.95e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'completion'}, 'luminous-extended-control': {'max_tokens': 2048, 'input_cost_per_token': 5.625e-05, 'output_cost_per_token': 6.1875e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'chat'}, 'luminous-supreme': {'max_tokens': 2048, 'input_cost_per_token': 0.000175, 'output_cost_per_token': 0.0001925, 'litellm_provider': 'aleph_alpha', 'mode': 'completion'}, 'luminous-supreme-control': {'max_tokens': 2048, 'input_cost_per_token': 0.00021875, 'output_cost_per_token': 0.000240625, 'litellm_provider': 'aleph_alpha', 'mode': 'chat'}, 'ai21.j2-mid-v1': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 8191, 'input_cost_per_token': 1.25e-05, 'output_cost_per_token': 1.25e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'ai21.j2-ultra-v1': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 8191, 'input_cost_per_token': 1.88e-05, 'output_cost_per_token': 1.88e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'ai21.jamba-instruct-v1:0': {'max_tokens': 4096, 'max_input_tokens': 70000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_system_messages': True}, 'amazon.titan-text-lite-v1': {'max_tokens': 4000, 'max_input_tokens': 42000, 'max_output_tokens': 4000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'amazon.titan-text-express-v1': {'max_tokens': 8000, 'max_input_tokens': 42000, 'max_output_tokens': 8000, 'input_cost_per_token': 1.3e-06, 'output_cost_per_token': 1.7e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'amazon.titan-text-premier-v1:0': {'max_tokens': 32000, 'max_input_tokens': 42000, 'max_output_tokens': 32000, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'amazon.titan-embed-text-v1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'output_vector_size': 1536, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'amazon.titan-embed-text-v2:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'output_vector_size': 1024, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4.5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'mistral.mistral-large-2407-v1:0': {'max_tokens': 8191, 'max_input_tokens': 128000, 'max_output_tokens': 8191, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'mistral.mistral-small-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4.5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4.5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 9.1e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2.6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'bedrock/eu-west-3/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.04e-05, 'output_cost_per_token': 3.12e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'anthropic.claude-3-5-sonnet-latest-v2:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'us.anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'eu.anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0455, 'output_cost_per_second': 0.0455, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02527, 'output_cost_per_second': 0.02527, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0415, 'output_cost_per_second': 0.0415, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02305, 'output_cost_per_second': 0.02305, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0455, 'output_cost_per_second': 0.0455, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02527, 'output_cost_per_second': 0.02527, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0415, 'output_cost_per_second': 0.0415, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02305, 'output_cost_per_second': 0.02305, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0455, 'output_cost_per_second': 0.0455, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02527, 'output_cost_per_second': 0.02527, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0415, 'output_cost_per_second': 0.0415, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02305, 'output_cost_per_second': 0.02305, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-06, 'output_cost_per_token': 5.51e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-07, 'output_cost_per_token': 2.4e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.011, 'output_cost_per_second': 0.011, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00611, 'output_cost_per_second': 0.00611, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.011, 'output_cost_per_second': 0.011, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00611, 'output_cost_per_second': 0.00611, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-07, 'output_cost_per_token': 2.4e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.23e-06, 'output_cost_per_token': 7.55e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.01475, 'output_cost_per_second': 0.01475, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.008194, 'output_cost_per_second': 0.008194, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.48e-06, 'output_cost_per_token': 8.38e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.01635, 'output_cost_per_second': 0.01635, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.009083, 'output_cost_per_second': 0.009083, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/1-month-commitment/cohere.command-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.011, 'output_cost_per_second': 0.011, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/6-month-commitment/cohere.command-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.0066027, 'output_cost_per_second': 0.0066027, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-light-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/1-month-commitment/cohere.command-light-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.001902, 'output_cost_per_second': 0.001902, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/6-month-commitment/cohere.command-light-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.0011416, 'output_cost_per_second': 0.0011416, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-r-plus-v1:0': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-r-v1:0': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.embed-english-v3': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'cohere.embed-multilingual-v3': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'meta.llama2-13b-chat-v1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7.5e-07, 'output_cost_per_token': 1e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama2-70b-chat-v1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.95e-06, 'output_cost_per_token': 2.56e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.6e-07, 'output_cost_per_token': 7.2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 6.9e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.2e-07, 'output_cost_per_token': 6.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.9e-07, 'output_cost_per_token': 7.8e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.01e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.65e-06, 'output_cost_per_token': 3.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.65e-06, 'output_cost_per_token': 3.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.65e-06, 'output_cost_per_token': 3.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.18e-06, 'output_cost_per_token': 4.2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.05e-06, 'output_cost_per_token': 4.03e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.86e-06, 'output_cost_per_token': 3.78e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.45e-06, 'output_cost_per_token': 4.55e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 4.45e-06, 'output_cost_per_token': 5.88e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama3-1-8b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 2.2e-07, 'output_cost_per_token': 2.2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-1-70b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 9.9e-07, 'output_cost_per_token': 9.9e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-1-405b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5.32e-06, 'output_cost_per_token': 1.6e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'eu.meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'eu.meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.9e-07, 'output_cost_per_token': 1.9e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-11b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 3.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-11b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 3.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-90b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-90b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, '512-x-512/50-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.018, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, '512-x-512/max-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.036, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, 'max-x-max/50-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.036, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, 'max-x-max/max-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.072, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, '1024-x-1024/50-steps/stability.stable-diffusion-xl-v1': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.04, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, '1024-x-1024/max-steps/stability.stable-diffusion-xl-v1': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.08, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, 'sagemaker/meta-textgeneration-llama-2-7b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'completion'}, 'sagemaker/meta-textgeneration-llama-2-7b-f': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'chat'}, 'sagemaker/meta-textgeneration-llama-2-13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'completion'}, 'sagemaker/meta-textgeneration-llama-2-13b-f': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'chat'}, 'sagemaker/meta-textgeneration-llama-2-70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'completion'}, 'sagemaker/meta-textgeneration-llama-2-70b-b-f': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'chat'}, 'together-ai-up-to-4b': {'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-4.1b-8b': {'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-8.1b-21b': {'max_tokens': 1000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 3e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-21.1b-41b': {'input_cost_per_token': 8e-07, 'output_cost_per_token': 8e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-41.1b-80b': {'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-81.1b-110b': {'input_cost_per_token': 1.8e-06, 'output_cost_per_token': 1.8e-06, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-embedding-up-to-150m': {'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'together_ai', 'mode': 'embedding'}, 'together-ai-embedding-151m-to-350m': {'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'together_ai', 'mode': 'embedding'}, 'together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1': {'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'together_ai', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'mode': 'chat'}, 'together_ai/mistralai/Mistral-7B-Instruct-v0.1': {'litellm_provider': 'together_ai', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'mode': 'chat'}, 'together_ai/togethercomputer/CodeLlama-34b-Instruct': {'litellm_provider': 'together_ai', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'mode': 'chat'}, 'ollama/codegemma': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/codegeex4': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': False}, 'ollama/deepseek-coder-v2-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/deepseek-coder-v2-base': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion', 'supports_function_calling': True}, 'ollama/deepseek-coder-v2-lite-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/deepseek-coder-v2-lite-base': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion', 'supports_function_calling': True}, 'ollama/internlm2_5-20b-chat': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/llama2': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2:7b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2:13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2:70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2-uncensored': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/llama3': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama3:8b': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama3:70b': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama3.1': {'max_tokens': 32768, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/mistral-large-instruct-2407': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mistral': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/mistral-7B-Instruct-v0.1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mistral-7B-Instruct-v0.2': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mixtral-8x7B-Instruct-v0.1': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mixtral-8x22B-Instruct-v0.1': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 65536, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/codellama': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/orca-mini': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/vicuna': {'max_tokens': 2048, 'max_input_tokens': 2048, 'max_output_tokens': 2048, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'deepinfra/lizpreciatior/lzlv_70b_fp16_hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/Gryphe/MythoMax-L2-13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 2.2e-07, 'output_cost_per_token': 2.2e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/mistralai/Mistral-7B-Instruct-v0.1': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Llama-2-70b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-07, 'output_cost_per_token': 2.7e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/codellama/CodeLlama-34b-Instruct-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/deepinfra/mixtral': {'max_tokens': 4096, 'max_input_tokens': 32000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.7e-07, 'output_cost_per_token': 2.7e-07, 'litellm_provider': 'deepinfra', 'mode': 'completion'}, 'deepinfra/Phind/Phind-CodeLlama-34B-v2': {'max_tokens': 4096, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-07, 'output_cost_per_token': 2.7e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/deepinfra/airoboros-70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/01-ai/Yi-34B-Chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/01-ai/Yi-6B-200K': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'completion'}, 'deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Llama-2-13b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 2.2e-07, 'output_cost_per_token': 2.2e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/amazon/MistralLite': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Llama-2-7b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Meta-Llama-3-8B-Instruct': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 4096, 'input_cost_per_token': 8e-08, 'output_cost_per_token': 8e-08, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Meta-Llama-3-70B-Instruct': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 4096, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/01-ai/Yi-34B-200K': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'completion'}, 'deepinfra/openchat/openchat_3.5': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'perplexity/codellama-34b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 1.4e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/codellama-70b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 2.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-70b-instruct': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-8b-instruct': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-huge-128k-online': {'max_tokens': 127072, 'max_input_tokens': 127072, 'max_output_tokens': 127072, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-large-128k-online': {'max_tokens': 127072, 'max_input_tokens': 127072, 'max_output_tokens': 127072, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-large-128k-chat': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-small-128k-chat': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-small-128k-online': {'max_tokens': 127072, 'max_input_tokens': 127072, 'max_output_tokens': 127072, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-7b-chat': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 2.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-7b-online': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 2.8e-07, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-70b-online': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 2.8e-06, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-2-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 2.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/mistral-7b-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/mixtral-8x7b-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-small-chat': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-small-online': {'max_tokens': 12000, 'max_input_tokens': 12000, 'max_output_tokens': 12000, 'input_cost_per_token': 0, 'output_cost_per_token': 2.8e-07, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-medium-chat': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 1.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-medium-online': {'max_tokens': 12000, 'max_input_tokens': 12000, 'max_output_tokens': 12000, 'input_cost_per_token': 0, 'output_cost_per_token': 1.8e-06, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://fireworks.ai/pricing'}, 'accounts/fireworks/models/llama-v3p2-90b-vision-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/firefunction-v2': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 65536, 'input_cost_per_token': 1.2e-06, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/yi-large': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 8192, 'input_cost_per_token': 1.2e-06, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/nomic-ai/nomic-embed-text-v1.5': {'max_tokens': 8192, 'max_input_tokens': 8192, 'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/nomic-ai/nomic-embed-text-v1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/WhereIsAI/UAE-Large-V1': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/thenlper/gte-large': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/thenlper/gte-base': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks-ai-up-to-16b': {'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-16.1b-to-80b': {'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-moe-up-to-56b': {'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-56b-to-176b': {'input_cost_per_token': 1.2e-06, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-default': {'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-embedding-up-to-150m': {'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models'}, 'fireworks-ai-embedding-150m-to-350m': {'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models'}, 'anyscale/mistralai/Mistral-7B-Instruct-v0.1': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1'}, 'anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1'}, 'anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 65536, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1'}, 'anyscale/HuggingFaceH4/zephyr-7b-beta': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/google/gemma-7b-it': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it'}, 'anyscale/meta-llama/Llama-2-7b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/meta-llama/Llama-2-13b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/meta-llama/Llama-2-70b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/codellama/CodeLlama-34b-Instruct-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/codellama/CodeLlama-70b-Instruct-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf'}, 'anyscale/meta-llama/Meta-Llama-3-8B-Instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct'}, 'anyscale/meta-llama/Meta-Llama-3-70B-Instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct'}, 'cloudflare/@cf/meta/llama-2-7b-chat-fp16': {'max_tokens': 3072, 'max_input_tokens': 3072, 'max_output_tokens': 3072, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'cloudflare/@cf/meta/llama-2-7b-chat-int8': {'max_tokens': 2048, 'max_input_tokens': 2048, 'max_output_tokens': 2048, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'cloudflare/@cf/mistral/mistral-7b-instruct-v0.1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'cloudflare/@hf/thebloke/codellama-7b-instruct-awq': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'voyage/voyage-01': {'max_tokens': 4096, 'max_input_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-lite-01': {'max_tokens': 4096, 'max_input_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-large-2': {'max_tokens': 16000, 'max_input_tokens': 16000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-law-2': {'max_tokens': 16000, 'max_input_tokens': 16000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-code-2': {'max_tokens': 16000, 'max_input_tokens': 16000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-2': {'max_tokens': 4000, 'max_input_tokens': 4000, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-lite-02-instruct': {'max_tokens': 4000, 'max_input_tokens': 4000, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-finance-2': {'max_tokens': 4000, 'max_input_tokens': 4000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'databricks/databricks-meta-llama-3-1-405b-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 5e-06, 'input_dbu_cost_per_token': 7.1429e-05, 'output_cost_per_token': 1.500002e-05, 'output_db_cost_per_token': 0.000214286, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-meta-llama-3-1-70b-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1.00002e-06, 'input_dbu_cost_per_token': 1.4286e-05, 'output_cost_per_token': 2.99999e-06, 'output_dbu_cost_per_token': 4.2857e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-dbrx-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 7.4998e-07, 'input_dbu_cost_per_token': 1.0714e-05, 'output_cost_per_token': 2.24901e-06, 'output_dbu_cost_per_token': 3.2143e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-meta-llama-3-70b-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1.00002e-06, 'input_dbu_cost_per_token': 1.4286e-05, 'output_cost_per_token': 2.99999e-06, 'output_dbu_cost_per_token': 4.2857e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-llama-2-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5.0001e-07, 'input_dbu_cost_per_token': 7.143e-06, 'output_cost_per_token': 1.5e-06, 'output_dbu_cost_per_token': 2.1429e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-mixtral-8x7b-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5.0001e-07, 'input_dbu_cost_per_token': 7.143e-06, 'output_cost_per_token': 9.9902e-07, 'output_dbu_cost_per_token': 1.4286e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-mpt-30b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 9.9902e-07, 'input_dbu_cost_per_token': 1.4286e-05, 'output_cost_per_token': 9.9902e-07, 'output_dbu_cost_per_token': 1.4286e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-mpt-7b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.0001e-07, 'input_dbu_cost_per_token': 7.143e-06, 'output_cost_per_token': 0.0, 'output_dbu_cost_per_token': 0.0, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-bge-large-en': {'max_tokens': 512, 'max_input_tokens': 512, 'output_vector_size': 1024, 'input_cost_per_token': 1.0003e-07, 'input_dbu_cost_per_token': 1.429e-06, 'output_cost_per_token': 0.0, 'output_dbu_cost_per_token': 0.0, 'litellm_provider': 'databricks', 'mode': 'embedding', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-gte-large-en': {'max_tokens': 8192, 'max_input_tokens': 8192, 'output_vector_size': 1024, 'input_cost_per_token': 1.2999e-07, 'input_dbu_cost_per_token': 1.857e-06, 'output_cost_per_token': 0.0, 'output_dbu_cost_per_token': 0.0, 'litellm_provider': 'databricks', 'mode': 'embedding', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'azure/gpt-4o-mini-2024-07-18': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.65e-07, 'output_cost_per_token': 6.6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'amazon.titan-embed-image-v1': {'max_tokens': 128, 'max_input_tokens': 128, 'output_vector_size': 1024, 'input_cost_per_token': 8e-07, 'input_cost_per_image': 6e-05, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'supports_image_input': True, 'mode': 'embedding', 'source': 'https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1'}, 'azure_ai/mistral-large-2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview'}, 'azure_ai/ministral-3b': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 4e-08, 'output_cost_per_token': 4e-08, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview'}, 'azure_ai/Llama-3.2-11B-Vision-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 3.7e-07, 'output_cost_per_token': 3.7e-07, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'supports_vision': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview'}, 'azure_ai/Llama-3.2-90B-Vision-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 2.04e-06, 'output_cost_per_token': 2.04e-06, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'supports_vision': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview'}, 'azure_ai/Phi-3.5-mini-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3.5-vision-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': True, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3.5-MoE-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.6e-07, 'output_cost_per_token': 6.4e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-mini-4k-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-mini-128k-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-small-8k-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-small-128k-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-medium-4k-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.7e-07, 'output_cost_per_token': 6.8e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-medium-128k-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.7e-07, 'output_cost_per_token': 6.8e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'xai/grok-beta': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'xai', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'claude-3-5-haiku-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'cache_creation_input_token_cost': 1.25e-06, 'cache_read_input_token_cost': 1e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'tool_use_system_prompt_tokens': 264, 'supports_assistant_prefill': True, 'supports_prompt_caching': True, 'supports_pdf_input': True}, 'vertex_ai/claude-3-5-haiku@20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'openrouter/anthropic/claude-3-5-haiku': {'max_tokens': 200000, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True}, 'openrouter/anthropic/claude-3-5-haiku-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'tool_use_system_prompt_tokens': 264}, 'anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_assistant_prefill': True, 'supports_function_calling': True}, 'us.anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_assistant_prefill': True, 'supports_function_calling': True}, 'eu.anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'stability.sd3-large-v1:0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.08, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denver/Library/Caches/pypoetry/virtualenvs/graphdoc-x8ppHhEw-py3.11/lib/python3.11/site-packages/tokencost/constants.py:69: RuntimeWarning: coroutine 'update_token_costs' was never awaited\n",
      "  logger.error(\"Failed to update token costs. Using static costs.\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib.resources as pkg_resources\n",
    "\n",
    "# Replace 'tokencost' with the name of your package\n",
    "package_name = \"tokencost\"\n",
    "resource_name = \"model_prices.json\"\n",
    "\n",
    "try:\n",
    "    # Access the JSON file within the package\n",
    "    with pkg_resources.open_text(package_name, resource_name) as file:\n",
    "        data = json.load(file)\n",
    "    print(data)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{resource_name} not found in the package {package_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt-4': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4o': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'cache_read_input_token_cost': 1.25e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-audio-preview': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_audio_token': 0.0001, 'output_cost_per_token': 1e-05, 'output_cost_per_audio_token': 0.0002, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_audio_input': True, 'supports_audio_output': True}, 'gpt-4o-audio-preview-2024-10-01': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'input_cost_per_audio_token': 0.0001, 'output_cost_per_token': 1e-05, 'output_cost_per_audio_token': 0.0002, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_audio_input': True, 'supports_audio_output': True}, 'gpt-4o-mini': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-mini-2024-07-18': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'o1-mini': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'o1-mini-2024-09-12': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'o1-preview': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'o1-preview-2024-09-12': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'chatgpt-4o-latest': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-2024-05-13': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'cache_read_input_token_cost': 1.25e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-turbo-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-0314': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-0613': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-32k': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-32k-0314': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-32k-0613': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-4-turbo': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-turbo-2024-04-09': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-1106-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-0125-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-4-vision-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-4-1106-vision-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_vision': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo': {'max_tokens': 4097, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-0301': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-3.5-turbo-0613': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-1106': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-0125': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_prompt_caching': True}, 'gpt-3.5-turbo-16k': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'gpt-3.5-turbo-16k-0613': {'max_tokens': 16385, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_prompt_caching': True}, 'ft:gpt-3.5-turbo': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-3.5-turbo-0125': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-3.5-turbo-1106': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-3.5-turbo-0613': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'openai', 'mode': 'chat'}, 'ft:gpt-4-0613': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing'}, 'ft:gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 3.75e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'ft:gpt-4o-mini-2024-07-18': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'ft:davinci-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'ft:babbage-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 4e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'text-embedding-3-large': {'max_tokens': 8191, 'max_input_tokens': 8191, 'output_vector_size': 3072, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-embedding-3-small': {'max_tokens': 8191, 'max_input_tokens': 8191, 'output_vector_size': 1536, 'input_cost_per_token': 2e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-embedding-ada-002': {'max_tokens': 8191, 'max_input_tokens': 8191, 'output_vector_size': 1536, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-embedding-ada-002-v2': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'embedding'}, 'text-moderation-stable': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 0, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'moderations'}, 'text-moderation-007': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 0, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'moderations'}, 'text-moderation-latest': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 0, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openai', 'mode': 'moderations'}, '256-x-256/dall-e-2': {'mode': 'image_generation', 'input_cost_per_pixel': 2.4414e-07, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, '512-x-512/dall-e-2': {'mode': 'image_generation', 'input_cost_per_pixel': 6.86e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, '1024-x-1024/dall-e-2': {'mode': 'image_generation', 'input_cost_per_pixel': 1.9e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'hd/1024-x-1792/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 6.539e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'hd/1792-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 6.539e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'hd/1024-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 7.629e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'standard/1024-x-1792/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 4.359e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'standard/1792-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 4.359e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'standard/1024-x-1024/dall-e-3': {'mode': 'image_generation', 'input_cost_per_pixel': 3.81469e-08, 'output_cost_per_pixel': 0.0, 'litellm_provider': 'openai'}, 'whisper-1': {'mode': 'audio_transcription', 'input_cost_per_second': 0, 'output_cost_per_second': 0.0001, 'litellm_provider': 'openai'}, 'tts-1': {'mode': 'audio_speech', 'input_cost_per_character': 1.5e-05, 'litellm_provider': 'openai'}, 'tts-1-hd': {'mode': 'audio_speech', 'input_cost_per_character': 3e-05, 'litellm_provider': 'openai'}, 'azure/tts-1': {'mode': 'audio_speech', 'input_cost_per_character': 1.5e-05, 'litellm_provider': 'azure'}, 'azure/tts-1-hd': {'mode': 'audio_speech', 'input_cost_per_character': 3e-05, 'litellm_provider': 'azure'}, 'azure/whisper-1': {'mode': 'audio_transcription', 'input_cost_per_second': 0, 'output_cost_per_second': 0.0001, 'litellm_provider': 'azure'}, 'azure/o1-mini': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/o1-mini-2024-09-12': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/o1-preview': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/o1-preview-2024-09-12': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'cache_read_input_token_cost': 7.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False, 'supports_prompt_caching': True}, 'azure/gpt-4o': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'cache_read_input_token_cost': 1.25e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'azure/gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.75e-06, 'output_cost_per_token': 1.1e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'azure/gpt-4o-2024-05-13': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'azure/global-standard/gpt-4o-2024-08-06': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'azure/global-standard/gpt-4o-mini': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True}, 'azure/gpt-4o-mini': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.65e-07, 'output_cost_per_token': 6.6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'azure/gpt-4-turbo-2024-04-09': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True}, 'azure/gpt-4-0125-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-4-1106-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-4-0613': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-4-32k-0613': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'azure', 'mode': 'chat'}, 'azure/gpt-4-32k': {'max_tokens': 4096, 'max_input_tokens': 32768, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-05, 'output_cost_per_token': 0.00012, 'litellm_provider': 'azure', 'mode': 'chat'}, 'azure/gpt-4': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-4-turbo': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-4-turbo-vision-preview': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_vision': True}, 'azure/gpt-35-turbo-16k-0613': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-35-turbo-1106': {'max_tokens': 4096, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-0613': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-0301': {'max_tokens': 4097, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-0125': {'max_tokens': 4096, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True}, 'azure/gpt-35-turbo-16k': {'max_tokens': 4096, 'max_input_tokens': 16385, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'azure', 'mode': 'chat'}, 'azure/gpt-35-turbo': {'max_tokens': 4096, 'max_input_tokens': 4097, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/gpt-3.5-turbo-instruct-0914': {'max_tokens': 4097, 'max_input_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'azure/gpt-35-turbo-instruct': {'max_tokens': 4097, 'max_input_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'azure/gpt-35-turbo-instruct-0914': {'max_tokens': 4097, 'max_input_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'azure/mistral-large-latest': {'max_tokens': 32000, 'max_input_tokens': 32000, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/mistral-large-2402': {'max_tokens': 32000, 'max_input_tokens': 32000, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/command-r-plus': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True}, 'azure/ada': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/text-embedding-ada-002': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/text-embedding-3-large': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/text-embedding-3-small': {'max_tokens': 8191, 'max_input_tokens': 8191, 'input_cost_per_token': 2e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'embedding'}, 'azure/standard/1024-x-1024/dall-e-3': {'input_cost_per_pixel': 3.81469e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/hd/1024-x-1024/dall-e-3': {'input_cost_per_pixel': 7.629e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/standard/1024-x-1792/dall-e-3': {'input_cost_per_pixel': 4.359e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/standard/1792-x-1024/dall-e-3': {'input_cost_per_pixel': 4.359e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/hd/1024-x-1792/dall-e-3': {'input_cost_per_pixel': 6.539e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/hd/1792-x-1024/dall-e-3': {'input_cost_per_pixel': 6.539e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure/standard/1024-x-1024/dall-e-2': {'input_cost_per_pixel': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure', 'mode': 'image_generation'}, 'azure_ai/jamba-instruct': {'max_tokens': 4096, 'max_input_tokens': 70000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat'}, 'azure_ai/mistral-large': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_function_calling': True}, 'azure_ai/mistral-small': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'mode': 'chat'}, 'azure_ai/Meta-Llama-3-70B-Instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.1e-06, 'output_cost_per_token': 3.7e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat'}, 'azure_ai/Meta-Llama-3.1-8B-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6.1e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice'}, 'azure_ai/Meta-Llama-3.1-70B-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.68e-06, 'output_cost_per_token': 3.54e-06, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice'}, 'azure_ai/Meta-Llama-3.1-405B-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 5.33e-06, 'output_cost_per_token': 1.6e-05, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice'}, 'azure_ai/cohere-rerank-v3-multilingual': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'rerank'}, 'azure_ai/cohere-rerank-v3-english': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'rerank'}, 'azure_ai/Cohere-embed-v3-english': {'max_tokens': 512, 'max_input_tokens': 512, 'output_vector_size': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'embedding', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice'}, 'azure_ai/Cohere-embed-v3-multilingual': {'max_tokens': 512, 'max_input_tokens': 512, 'output_vector_size': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'azure_ai', 'mode': 'embedding', 'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice'}, 'babbage-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 4e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'davinci-002': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'gpt-3.5-turbo-instruct': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'gpt-3.5-turbo-instruct-0914': {'max_tokens': 4097, 'max_input_tokens': 8192, 'max_output_tokens': 4097, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'text-completion-openai', 'mode': 'completion'}, 'claude-instant-1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-06, 'output_cost_per_token': 5.51e-06, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'mistral/mistral-tiny': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-small': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'supports_function_calling': True, 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-small-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'supports_function_calling': True, 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-medium': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-06, 'output_cost_per_token': 8.1e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-medium-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-06, 'output_cost_per_token': 8.1e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-medium-2312': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-06, 'output_cost_per_token': 8.1e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/mistral-large-latest': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/mistral-large-2402': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/mistral-large-2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/pixtral-12b-2409': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True, 'supports_vision': True}, 'mistral/open-mistral-7b': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/open-mixtral-8x7b': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/open-mixtral-8x22b': {'max_tokens': 8191, 'max_input_tokens': 64000, 'max_output_tokens': 8191, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'mistral/codestral-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/codestral-2405': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'mistral', 'mode': 'chat', 'supports_assistant_prefill': True}, 'mistral/open-mistral-nemo': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 3e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/open-mistral-nemo-2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 3e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/open-codestral-mamba': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/codestral-mamba-latest': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'mistral', 'mode': 'chat', 'source': 'https://mistral.ai/technology/', 'supports_assistant_prefill': True}, 'mistral/mistral-embed': {'max_tokens': 8192, 'max_input_tokens': 8192, 'input_cost_per_token': 1e-07, 'litellm_provider': 'mistral', 'mode': 'embedding'}, 'deepseek-chat': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.4e-07, 'input_cost_per_token_cache_hit': 1.4e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'deepseek', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True, 'supports_tool_choice': True, 'supports_prompt_caching': True}, 'codestral/codestral-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'codestral', 'mode': 'chat', 'source': 'https://docs.mistral.ai/capabilities/code_generation/', 'supports_assistant_prefill': True}, 'codestral/codestral-2405': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'codestral', 'mode': 'chat', 'source': 'https://docs.mistral.ai/capabilities/code_generation/', 'supports_assistant_prefill': True}, 'text-completion-codestral/codestral-latest': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'text-completion-codestral', 'mode': 'completion', 'source': 'https://docs.mistral.ai/capabilities/code_generation/'}, 'text-completion-codestral/codestral-2405': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'text-completion-codestral', 'mode': 'completion', 'source': 'https://docs.mistral.ai/capabilities/code_generation/'}, 'deepseek-coder': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.4e-07, 'input_cost_per_token_cache_hit': 1.4e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'deepseek', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True, 'supports_tool_choice': True, 'supports_prompt_caching': True}, 'groq/llama2-70b-4096': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 8e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-8b-8192': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 8e-08, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-70b-8192': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama-3.1-8b-instant': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 8e-08, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama-3.1-70b-versatile': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama-3.1-405b-reasoning': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/mixtral-8x7b-32768': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 2.4e-07, 'output_cost_per_token': 2.4e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/gemma-7b-it': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 7e-08, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/gemma2-9b-it': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-groq-70b-8192-tool-use-preview': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 8.9e-07, 'output_cost_per_token': 8.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'groq/llama3-groq-8b-8192-tool-use-preview': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.9e-07, 'output_cost_per_token': 1.9e-07, 'litellm_provider': 'groq', 'mode': 'chat', 'supports_function_calling': True}, 'cerebras/llama3.1-8b': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'cerebras', 'mode': 'chat', 'supports_function_calling': True}, 'cerebras/llama3.1-70b': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cerebras', 'mode': 'chat', 'supports_function_calling': True}, 'friendliai/mixtral-8x7b-instruct-v0-1': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 4e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'friendliai', 'mode': 'chat', 'supports_function_calling': True}, 'friendliai/meta-llama-3-8b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'friendliai', 'mode': 'chat', 'supports_function_calling': True}, 'friendliai/meta-llama-3-70b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 8e-07, 'output_cost_per_token': 8e-07, 'litellm_provider': 'friendliai', 'mode': 'chat', 'supports_function_calling': True}, 'claude-instant-1.2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-07, 'output_cost_per_token': 5.51e-07, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'claude-2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'claude-2.1': {'max_tokens': 8191, 'max_input_tokens': 200000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'anthropic', 'mode': 'chat'}, 'claude-3-haiku-20240307': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'cache_creation_input_token_cost': 3e-07, 'cache_read_input_token_cost': 3e-08, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 264, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-haiku-latest': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'cache_creation_input_token_cost': 3e-07, 'cache_read_input_token_cost': 3e-08, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 264, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-opus-20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'cache_creation_input_token_cost': 1.875e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 395, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-opus-latest': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'cache_creation_input_token_cost': 1.875e-05, 'cache_read_input_token_cost': 1.5e-06, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 395, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-sonnet-20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-5-sonnet-20240620': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-5-sonnet-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'claude-3-5-sonnet-latest': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'text-bison': {'max_tokens': 2048, 'max_input_tokens': 8192, 'max_output_tokens': 2048, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison@001': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison@002': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison32k': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-bison32k@002': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-unicorn': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 2.8e-05, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-unicorn@001': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 2.8e-05, 'litellm_provider': 'vertex_ai-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison@001': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison@002': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison-32k': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'chat-bison-32k@002': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison@001': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison@002': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison32k': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-bison-32k@002': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko@001': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko@002': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'code-gecko-latest': {'max_tokens': 64, 'max_input_tokens': 2048, 'max_output_tokens': 64, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'vertex_ai-code-text-models', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison@latest': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison@001': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison@002': {'max_tokens': 1024, 'max_input_tokens': 6144, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison-32k': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'codechat-bison-32k@002': {'max_tokens': 8192, 'max_input_tokens': 32000, 'max_output_tokens': 8192, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'input_cost_per_character': 2.5e-07, 'output_cost_per_character': 5e-07, 'litellm_provider': 'vertex_ai-code-chat-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-pro': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'gemini-1.0-pro': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models'}, 'gemini-1.0-pro-001': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-ultra': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 2048, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-ultra-001': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 2048, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-pro-002': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_image': 0.0025, 'input_cost_per_video_per_second': 0.002, 'input_cost_per_token': 5e-07, 'input_cost_per_character': 1.25e-07, 'output_cost_per_token': 1.5e-06, 'output_cost_per_character': 3.75e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 1.25e-06, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 2.5e-06, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 5e-06, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 1e-05, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-002': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 1.25e-06, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 2.5e-06, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 5e-06, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 1e-05, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro'}, 'gemini-1.5-pro-001': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 1.25e-06, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 2.5e-06, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 5e-06, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 1e-05, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-preview-0514': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 7.8125e-08, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 1.5625e-07, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 3.125e-07, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 6.25e-07, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-preview-0215': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 7.8125e-08, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 1.5625e-07, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 3.125e-07, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 6.25e-07, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-pro-preview-0409': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_image': 0.00032875, 'input_cost_per_audio_per_second': 3.125e-05, 'input_cost_per_video_per_second': 0.00032875, 'input_cost_per_token': 7.8125e-08, 'input_cost_per_character': 3.125e-07, 'input_cost_per_image_above_128k_tokens': 0.0006575, 'input_cost_per_video_per_second_above_128k_tokens': 0.0006575, 'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05, 'input_cost_per_token_above_128k_tokens': 1.5625e-07, 'input_cost_per_character_above_128k_tokens': 6.25e-07, 'output_cost_per_token': 3.125e-07, 'output_cost_per_character': 1.25e-06, 'output_cost_per_token_above_128k_tokens': 6.25e-07, 'output_cost_per_character_above_128k_tokens': 2.5e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 3e-07, 'output_cost_per_character': 7.5e-08, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': 1.5e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 4.688e-09, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 4.6875e-09, 'output_cost_per_character': 1.875e-08, 'output_cost_per_token_above_128k_tokens': 9.375e-09, 'output_cost_per_character_above_128k_tokens': 3.75e-08, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash-002': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 3e-07, 'output_cost_per_character': 7.5e-08, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': 1.5e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash'}, 'gemini-1.5-flash-001': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 3e-07, 'output_cost_per_character': 7.5e-08, 'output_cost_per_token_above_128k_tokens': 6e-07, 'output_cost_per_character_above_128k_tokens': 1.5e-07, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.5-flash-preview-0514': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_image': 2e-05, 'input_cost_per_video_per_second': 2e-05, 'input_cost_per_audio_per_second': 2e-06, 'input_cost_per_token': 7.5e-08, 'input_cost_per_character': 1.875e-08, 'input_cost_per_token_above_128k_tokens': 1e-06, 'input_cost_per_character_above_128k_tokens': 2.5e-07, 'input_cost_per_image_above_128k_tokens': 4e-05, 'input_cost_per_video_per_second_above_128k_tokens': 4e-05, 'input_cost_per_audio_per_second_above_128k_tokens': 4e-06, 'output_cost_per_token': 4.6875e-09, 'output_cost_per_character': 1.875e-08, 'output_cost_per_token_above_128k_tokens': 9.375e-09, 'output_cost_per_character_above_128k_tokens': 3.75e-08, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-pro-experimental': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_token': 0, 'output_cost_per_token': 0, 'input_cost_per_character': 0, 'output_cost_per_character': 0, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': False, 'supports_tool_choice': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental'}, 'gemini-flash-experimental': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_token': 0, 'output_cost_per_token': 0, 'input_cost_per_character': 0, 'output_cost_per_character': 0, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'supports_function_calling': False, 'supports_tool_choice': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental'}, 'gemini-pro-vision': {'max_tokens': 2048, 'max_input_tokens': 16384, 'max_output_tokens': 2048, 'max_images_per_prompt': 16, 'max_videos_per_prompt': 1, 'max_video_length': 2, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'vertex_ai-vision-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-pro-vision': {'max_tokens': 2048, 'max_input_tokens': 16384, 'max_output_tokens': 2048, 'max_images_per_prompt': 16, 'max_videos_per_prompt': 1, 'max_video_length': 2, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'vertex_ai-vision-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini-1.0-pro-vision-001': {'max_tokens': 2048, 'max_input_tokens': 16384, 'max_output_tokens': 2048, 'max_images_per_prompt': 16, 'max_videos_per_prompt': 1, 'max_video_length': 2, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'vertex_ai-vision-models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'medlm-medium': {'max_tokens': 8192, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_character': 5e-07, 'output_cost_per_character': 1e-06, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'medlm-large': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_character': 5e-06, 'output_cost_per_character': 1.5e-05, 'litellm_provider': 'vertex_ai-language-models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'vertex_ai/claude-3-sonnet@20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-5-sonnet@20240620': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-5-sonnet-v2@20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-haiku@20240307': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/claude-3-opus@20240229': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'vertex_ai/meta/llama3-405b-instruct-maas': {'max_tokens': 32000, 'max_input_tokens': 32000, 'max_output_tokens': 32000, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'}, 'vertex_ai/meta/llama3-70b-instruct-maas': {'max_tokens': 32000, 'max_input_tokens': 32000, 'max_output_tokens': 32000, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'}, 'vertex_ai/meta/llama3-8b-instruct-maas': {'max_tokens': 32000, 'max_input_tokens': 32000, 'max_output_tokens': 32000, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'}, 'vertex_ai/meta/llama-3.2-90b-vision-instruct-maas': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'vertex_ai-llama_models', 'mode': 'chat', 'supports_system_messages': True, 'supports_vision': True, 'source': 'https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas'}, 'vertex_ai/mistral-large@latest': {'max_tokens': 8191, 'max_input_tokens': 128000, 'max_output_tokens': 8191, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/mistral-large@2407': {'max_tokens': 8191, 'max_input_tokens': 128000, 'max_output_tokens': 8191, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/mistral-nemo@latest': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/jamba-1.5-mini@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5-large@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5-mini': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/jamba-1.5-large': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'vertex_ai-ai21_models', 'mode': 'chat'}, 'vertex_ai/mistral-nemo@2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/codestral@latest': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/codestral@2405': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'vertex_ai-mistral_models', 'mode': 'chat', 'supports_function_calling': True}, 'vertex_ai/imagegeneration@006': {'cost_per_image': 0.02, 'litellm_provider': 'vertex_ai-image-models', 'mode': 'image_generation', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'vertex_ai/imagen-3.0-generate-001': {'cost_per_image': 0.04, 'litellm_provider': 'vertex_ai-image-models', 'mode': 'image_generation', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'vertex_ai/imagen-3.0-fast-generate-001': {'cost_per_image': 0.02, 'litellm_provider': 'vertex_ai-image-models', 'mode': 'image_generation', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'text-embedding-004': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models'}, 'text-multilingual-embedding-002': {'max_tokens': 2048, 'max_input_tokens': 2048, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models'}, 'textembedding-gecko': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko-multilingual': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko-multilingual@001': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko@001': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'textembedding-gecko@003': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'text-embedding-preview-0409': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'input_cost_per_token_batch_requests': 5e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'}, 'text-multilingual-embedding-preview-0409': {'max_tokens': 3072, 'max_input_tokens': 3072, 'output_vector_size': 768, 'input_cost_per_token': 6.25e-09, 'output_cost_per_token': 0, 'litellm_provider': 'vertex_ai-embedding-models', 'mode': 'embedding', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/chat-bison': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/chat-bison-001': {'max_tokens': 4096, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'chat', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison-001': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison-safety-off': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'palm/text-bison-safety-recitation-off': {'max_tokens': 1024, 'max_input_tokens': 8192, 'max_output_tokens': 1024, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 1.25e-07, 'litellm_provider': 'palm', 'mode': 'completion', 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-1.5-flash-002': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-001': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-latest': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 7.5e-08, 'input_cost_per_token_above_128k_tokens': 1.5e-07, 'output_cost_per_token': 3e-07, 'output_cost_per_token_above_128k_tokens': 6e-07, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-8b-exp-0924': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-flash-8b-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'max_images_per_prompt': 3000, 'max_videos_per_prompt': 10, 'max_video_length': 1, 'max_audio_length_hours': 8.4, 'max_audio_per_prompt': 1, 'max_pdf_size_mb': 30, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-pro': {'max_tokens': 8192, 'max_input_tokens': 32760, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'input_cost_per_token_above_128k_tokens': 7e-07, 'output_cost_per_token': 1.05e-06, 'output_cost_per_token_above_128k_tokens': 2.1e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-1.5-pro': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-002': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-001': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'supports_prompt_caching': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-exp-0801': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-05, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-exp-0827': {'max_tokens': 8192, 'max_input_tokens': 2097152, 'max_output_tokens': 8192, 'input_cost_per_token': 0, 'input_cost_per_token_above_128k_tokens': 0, 'output_cost_per_token': 0, 'output_cost_per_token_above_128k_tokens': 0, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-1.5-pro-latest': {'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'input_cost_per_token_above_128k_tokens': 7e-06, 'output_cost_per_token': 1.05e-06, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_function_calling': True, 'supports_vision': True, 'supports_tool_choice': True, 'supports_response_schema': True, 'source': 'https://ai.google.dev/pricing'}, 'gemini/gemini-pro-vision': {'max_tokens': 2048, 'max_input_tokens': 30720, 'max_output_tokens': 2048, 'input_cost_per_token': 3.5e-07, 'input_cost_per_token_above_128k_tokens': 7e-07, 'output_cost_per_token': 1.05e-06, 'output_cost_per_token_above_128k_tokens': 2.1e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-gemma-2-27b-it': {'max_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 1.05e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'gemini/gemini-gemma-2-9b-it': {'max_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 1.05e-06, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'}, 'command-r': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-r-08-2024': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-light': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'cohere_chat', 'mode': 'chat'}, 'command-r-plus': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-r-plus-08-2024': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 1e-05, 'litellm_provider': 'cohere_chat', 'mode': 'chat', 'supports_function_calling': True}, 'command-nightly': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'cohere', 'mode': 'completion'}, 'command': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'cohere', 'mode': 'completion'}, 'rerank-english-v3.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'rerank-multilingual-v3.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'rerank-english-v2.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'rerank-multilingual-v2.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'max_query_tokens': 2048, 'input_cost_per_token': 0.0, 'input_cost_per_query': 0.002, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'rerank'}, 'embed-english-v3.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'input_cost_per_image': 0.0001, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding', 'supports_image_input': True}, 'embed-english-light-v3.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-multilingual-v3.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-english-v2.0': {'max_tokens': 4096, 'max_input_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-english-light-v2.0': {'max_tokens': 1024, 'max_input_tokens': 1024, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'embed-multilingual-v2.0': {'max_tokens': 768, 'max_input_tokens': 768, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'cohere', 'mode': 'embedding'}, 'replicate/meta/llama-2-13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-13b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-7b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-2-7b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-70b': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-70b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 2.75e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-8b': {'max_tokens': 8086, 'max_input_tokens': 8086, 'max_output_tokens': 8086, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/meta/llama-3-8b-instruct': {'max_tokens': 8086, 'max_input_tokens': 8086, 'max_output_tokens': 8086, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/mistralai/mistral-7b-v0.1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/mistralai/mistral-7b-instruct-v0.2': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-08, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'replicate/mistralai/mixtral-8x7b-instruct-v0.1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 1e-06, 'litellm_provider': 'replicate', 'mode': 'chat'}, 'openrouter/deepseek/deepseek-coder': {'max_tokens': 4096, 'max_input_tokens': 32000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.4e-07, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/microsoft/wizardlm-2-8x22b:nitro': {'max_tokens': 65536, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/google/gemini-pro-1.5': {'max_tokens': 8192, 'max_input_tokens': 1000000, 'max_output_tokens': 8192, 'input_cost_per_token': 2.5e-06, 'output_cost_per_token': 7.5e-06, 'input_cost_per_image': 0.00265, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/mistralai/mixtral-8x22b-instruct': {'max_tokens': 65536, 'input_cost_per_token': 6.5e-07, 'output_cost_per_token': 6.5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/cohere/command-r-plus': {'max_tokens': 128000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/databricks/dbrx-instruct': {'max_tokens': 32768, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-3-haiku': {'max_tokens': 200000, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'input_cost_per_image': 0.0004, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/anthropic/claude-3-haiku-20240307': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 264}, 'anthropic/claude-3-5-sonnet-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'anthropic/claude-3-5-sonnet-latest': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'cache_creation_input_token_cost': 3.75e-06, 'cache_read_input_token_cost': 3e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True, 'supports_prompt_caching': True}, 'openrouter/anthropic/claude-3.5-sonnet': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159, 'supports_assistant_prefill': True}, 'openrouter/anthropic/claude-3.5-sonnet:beta': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 159}, 'openrouter/anthropic/claude-3-sonnet': {'max_tokens': 200000, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'input_cost_per_image': 0.0048, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/mistralai/mistral-large': {'max_tokens': 32000, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/cognitivecomputations/dolphin-mixtral-8x7b': {'max_tokens': 32769, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/google/gemini-pro-vision': {'max_tokens': 45875, 'input_cost_per_token': 1.25e-07, 'output_cost_per_token': 3.75e-07, 'input_cost_per_image': 0.0025, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/fireworks/firellava-13b': {'max_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-8b-instruct:free': {'max_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-8b-instruct:extended': {'max_tokens': 16384, 'input_cost_per_token': 2.25e-07, 'output_cost_per_token': 2.25e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-70b-instruct:nitro': {'max_tokens': 8192, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-3-70b-instruct': {'max_tokens': 8192, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/openai/o1-mini': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/o1-mini-2024-09-12': {'max_tokens': 65536, 'max_input_tokens': 128000, 'max_output_tokens': 65536, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.2e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/o1-preview': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/o1-preview-2024-09-12': {'max_tokens': 32768, 'max_input_tokens': 128000, 'max_output_tokens': 32768, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': False}, 'openrouter/openai/gpt-4o': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True}, 'openrouter/openai/gpt-4o-2024-05-13': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_vision': True}, 'openrouter/openai/gpt-4-vision-preview': {'max_tokens': 130000, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 3e-05, 'input_cost_per_image': 0.01445, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'openrouter/openai/gpt-3.5-turbo': {'max_tokens': 4095, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/openai/gpt-3.5-turbo-16k': {'max_tokens': 16383, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 4e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/openai/gpt-4': {'max_tokens': 8192, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 6e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-instant-v1': {'max_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-06, 'output_cost_per_token': 5.51e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-2': {'max_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.102e-05, 'output_cost_per_token': 3.268e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/anthropic/claude-3-opus': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'tool_use_system_prompt_tokens': 395}, 'openrouter/google/palm-2-chat-bison': {'max_tokens': 25804, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/google/palm-2-codechat-bison': {'max_tokens': 20070, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-2-13b-chat': {'max_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/llama-2-70b-chat': {'max_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/meta-llama/codellama-34b-instruct': {'max_tokens': 8192, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/nousresearch/nous-hermes-llama2-13b': {'max_tokens': 4096, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/mancer/weaver': {'max_tokens': 8000, 'input_cost_per_token': 5.625e-06, 'output_cost_per_token': 5.625e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/gryphe/mythomax-l2-13b': {'max_tokens': 8192, 'input_cost_per_token': 1.875e-06, 'output_cost_per_token': 1.875e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/jondurbin/airoboros-l2-70b-2.1': {'max_tokens': 4096, 'input_cost_per_token': 1.3875e-05, 'output_cost_per_token': 1.3875e-05, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/undi95/remm-slerp-l2-13b': {'max_tokens': 6144, 'input_cost_per_token': 1.875e-06, 'output_cost_per_token': 1.875e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/pygmalionai/mythalion-13b': {'max_tokens': 4096, 'input_cost_per_token': 1.875e-06, 'output_cost_per_token': 1.875e-06, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/mistralai/mistral-7b-instruct': {'max_tokens': 8192, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'openrouter/mistralai/mistral-7b-instruct:free': {'max_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'openrouter', 'mode': 'chat'}, 'j2-ultra': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'ai21', 'mode': 'completion'}, 'jamba-1.5-mini@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5-large@001': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5-mini': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'jamba-1.5-large': {'max_tokens': 256000, 'max_input_tokens': 256000, 'max_output_tokens': 256000, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 8e-06, 'litellm_provider': 'ai21', 'mode': 'chat'}, 'j2-mid': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-05, 'output_cost_per_token': 1e-05, 'litellm_provider': 'ai21', 'mode': 'completion'}, 'j2-light': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'ai21', 'mode': 'completion'}, 'dolphin': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'nlp_cloud', 'mode': 'completion'}, 'chatdolphin': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'nlp_cloud', 'mode': 'chat'}, 'luminous-base': {'max_tokens': 2048, 'input_cost_per_token': 3e-05, 'output_cost_per_token': 3.3e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'completion'}, 'luminous-base-control': {'max_tokens': 2048, 'input_cost_per_token': 3.75e-05, 'output_cost_per_token': 4.125e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'chat'}, 'luminous-extended': {'max_tokens': 2048, 'input_cost_per_token': 4.5e-05, 'output_cost_per_token': 4.95e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'completion'}, 'luminous-extended-control': {'max_tokens': 2048, 'input_cost_per_token': 5.625e-05, 'output_cost_per_token': 6.1875e-05, 'litellm_provider': 'aleph_alpha', 'mode': 'chat'}, 'luminous-supreme': {'max_tokens': 2048, 'input_cost_per_token': 0.000175, 'output_cost_per_token': 0.0001925, 'litellm_provider': 'aleph_alpha', 'mode': 'completion'}, 'luminous-supreme-control': {'max_tokens': 2048, 'input_cost_per_token': 0.00021875, 'output_cost_per_token': 0.000240625, 'litellm_provider': 'aleph_alpha', 'mode': 'chat'}, 'ai21.j2-mid-v1': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 8191, 'input_cost_per_token': 1.25e-05, 'output_cost_per_token': 1.25e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'ai21.j2-ultra-v1': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 8191, 'input_cost_per_token': 1.88e-05, 'output_cost_per_token': 1.88e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'ai21.jamba-instruct-v1:0': {'max_tokens': 4096, 'max_input_tokens': 70000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_system_messages': True}, 'amazon.titan-text-lite-v1': {'max_tokens': 4000, 'max_input_tokens': 42000, 'max_output_tokens': 4000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 4e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'amazon.titan-text-express-v1': {'max_tokens': 8000, 'max_input_tokens': 42000, 'max_output_tokens': 8000, 'input_cost_per_token': 1.3e-06, 'output_cost_per_token': 1.7e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'amazon.titan-text-premier-v1:0': {'max_tokens': 32000, 'max_input_tokens': 42000, 'max_output_tokens': 32000, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'amazon.titan-embed-text-v1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'output_vector_size': 1536, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'amazon.titan-embed-text-v2:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'output_vector_size': 1024, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4.5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'mistral.mistral-large-2407-v1:0': {'max_tokens': 8191, 'max_input_tokens': 128000, 'max_output_tokens': 8191, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 9e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'mistral.mistral-small-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4.5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 4.5e-07, 'output_cost_per_token': 7e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 9.1e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2.6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'bedrock/eu-west-3/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191, 'max_input_tokens': 32000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.04e-05, 'output_cost_per_token': 3.12e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'anthropic.claude-3-5-sonnet-latest-v2:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'us.anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'us.anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'supports_assistant_prefill': True}, 'eu.anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 1.25e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'eu.anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-05, 'output_cost_per_token': 7.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0455, 'output_cost_per_second': 0.0455, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02527, 'output_cost_per_second': 0.02527, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0415, 'output_cost_per_second': 0.0415, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02305, 'output_cost_per_second': 0.02305, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0455, 'output_cost_per_second': 0.0455, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02527, 'output_cost_per_second': 0.02527, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0415, 'output_cost_per_second': 0.0415, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02305, 'output_cost_per_second': 0.02305, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0455, 'output_cost_per_second': 0.0455, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02527, 'output_cost_per_second': 0.02527, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-06, 'output_cost_per_token': 2.4e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0415, 'output_cost_per_second': 0.0415, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.02305, 'output_cost_per_second': 0.02305, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.0175, 'output_cost_per_second': 0.0175, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00972, 'output_cost_per_second': 0.00972, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 1.63e-06, 'output_cost_per_token': 5.51e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-07, 'output_cost_per_token': 2.4e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.011, 'output_cost_per_second': 0.011, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00611, 'output_cost_per_second': 0.00611, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.011, 'output_cost_per_second': 0.011, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.00611, 'output_cost_per_second': 0.00611, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-2/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 8e-07, 'output_cost_per_token': 2.4e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.23e-06, 'output_cost_per_token': 7.55e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.01475, 'output_cost_per_second': 0.01475, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.008194, 'output_cost_per_second': 0.008194, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_token': 2.48e-06, 'output_cost_per_token': 8.38e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.01635, 'output_cost_per_second': 0.01635, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191, 'max_input_tokens': 100000, 'max_output_tokens': 8191, 'input_cost_per_second': 0.009083, 'output_cost_per_second': 0.009083, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/1-month-commitment/cohere.command-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.011, 'output_cost_per_second': 0.011, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/6-month-commitment/cohere.command-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.0066027, 'output_cost_per_second': 0.0066027, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-light-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/1-month-commitment/cohere.command-light-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.001902, 'output_cost_per_second': 0.001902, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/*/6-month-commitment/cohere.command-light-text-v14': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_second': 0.0011416, 'output_cost_per_second': 0.0011416, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-r-plus-v1:0': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.command-r-v1:0': {'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'cohere.embed-english-v3': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'cohere.embed-multilingual-v3': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'mode': 'embedding'}, 'meta.llama2-13b-chat-v1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7.5e-07, 'output_cost_per_token': 1e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama2-70b-chat-v1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.95e-06, 'output_cost_per_token': 2.56e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.6e-07, 'output_cost_per_token': 7.2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 6.9e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.2e-07, 'output_cost_per_token': 6.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.9e-07, 'output_cost_per_token': 7.8e-07, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5e-07, 'output_cost_per_token': 1.01e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.65e-06, 'output_cost_per_token': 3.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-east-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.65e-06, 'output_cost_per_token': 3.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/us-west-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.65e-06, 'output_cost_per_token': 3.5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.18e-06, 'output_cost_per_token': 4.2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.05e-06, 'output_cost_per_token': 4.03e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 2.86e-06, 'output_cost_per_token': 3.78e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 3.45e-06, 'output_cost_per_token': 4.55e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 4.45e-06, 'output_cost_per_token': 5.88e-06, 'litellm_provider': 'bedrock', 'mode': 'chat'}, 'meta.llama3-1-8b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 2.2e-07, 'output_cost_per_token': 2.2e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-1-70b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 9.9e-07, 'output_cost_per_token': 9.9e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-1-405b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5.32e-06, 'output_cost_per_token': 1.6e-05, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'eu.meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'eu.meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.9e-07, 'output_cost_per_token': 1.9e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-11b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 3.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-11b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 3.5e-07, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'meta.llama3-2-90b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, 'us.meta.llama3-2-90b-instruct-v1:0': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 2e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True, 'supports_tool_choice': False}, '512-x-512/50-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.018, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, '512-x-512/max-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.036, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, 'max-x-max/50-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.036, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, 'max-x-max/max-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.072, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, '1024-x-1024/50-steps/stability.stable-diffusion-xl-v1': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.04, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, '1024-x-1024/max-steps/stability.stable-diffusion-xl-v1': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.08, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}, 'sagemaker/meta-textgeneration-llama-2-7b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'completion'}, 'sagemaker/meta-textgeneration-llama-2-7b-f': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'chat'}, 'sagemaker/meta-textgeneration-llama-2-13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'completion'}, 'sagemaker/meta-textgeneration-llama-2-13b-f': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'chat'}, 'sagemaker/meta-textgeneration-llama-2-70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'completion'}, 'sagemaker/meta-textgeneration-llama-2-70b-b-f': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'sagemaker', 'mode': 'chat'}, 'together-ai-up-to-4b': {'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-4.1b-8b': {'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-8.1b-21b': {'max_tokens': 1000, 'input_cost_per_token': 3e-07, 'output_cost_per_token': 3e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-21.1b-41b': {'input_cost_per_token': 8e-07, 'output_cost_per_token': 8e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-41.1b-80b': {'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-81.1b-110b': {'input_cost_per_token': 1.8e-06, 'output_cost_per_token': 1.8e-06, 'litellm_provider': 'together_ai', 'mode': 'chat'}, 'together-ai-embedding-up-to-150m': {'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'together_ai', 'mode': 'embedding'}, 'together-ai-embedding-151m-to-350m': {'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'together_ai', 'mode': 'embedding'}, 'together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1': {'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'together_ai', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'mode': 'chat'}, 'together_ai/mistralai/Mistral-7B-Instruct-v0.1': {'litellm_provider': 'together_ai', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'mode': 'chat'}, 'together_ai/togethercomputer/CodeLlama-34b-Instruct': {'litellm_provider': 'together_ai', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'mode': 'chat'}, 'ollama/codegemma': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/codegeex4': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': False}, 'ollama/deepseek-coder-v2-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/deepseek-coder-v2-base': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion', 'supports_function_calling': True}, 'ollama/deepseek-coder-v2-lite-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/deepseek-coder-v2-lite-base': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion', 'supports_function_calling': True}, 'ollama/internlm2_5-20b-chat': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/llama2': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2:7b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2:13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2:70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama2-uncensored': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/llama3': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama3:8b': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama3:70b': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/llama3.1': {'max_tokens': 32768, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat', 'supports_function_calling': True}, 'ollama/mistral-large-instruct-2407': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mistral': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/mistral-7B-Instruct-v0.1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mistral-7B-Instruct-v0.2': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mixtral-8x7B-Instruct-v0.1': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/mixtral-8x22B-Instruct-v0.1': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 65536, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'chat'}, 'ollama/codellama': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/orca-mini': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'ollama/vicuna': {'max_tokens': 2048, 'max_input_tokens': 2048, 'max_output_tokens': 2048, 'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'ollama', 'mode': 'completion'}, 'deepinfra/lizpreciatior/lzlv_70b_fp16_hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/Gryphe/MythoMax-L2-13b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 2.2e-07, 'output_cost_per_token': 2.2e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/mistralai/Mistral-7B-Instruct-v0.1': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Llama-2-70b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-07, 'output_cost_per_token': 2.7e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/codellama/CodeLlama-34b-Instruct-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/deepinfra/mixtral': {'max_tokens': 4096, 'max_input_tokens': 32000, 'max_output_tokens': 4096, 'input_cost_per_token': 2.7e-07, 'output_cost_per_token': 2.7e-07, 'litellm_provider': 'deepinfra', 'mode': 'completion'}, 'deepinfra/Phind/Phind-CodeLlama-34B-v2': {'max_tokens': 4096, 'max_input_tokens': 16384, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 2.7e-07, 'output_cost_per_token': 2.7e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/deepinfra/airoboros-70b': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/01-ai/Yi-34B-Chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/01-ai/Yi-6B-200K': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'completion'}, 'deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Llama-2-13b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 2.2e-07, 'output_cost_per_token': 2.2e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/amazon/MistralLite': {'max_tokens': 8191, 'max_input_tokens': 32768, 'max_output_tokens': 8191, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Llama-2-7b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Meta-Llama-3-8B-Instruct': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 4096, 'input_cost_per_token': 8e-08, 'output_cost_per_token': 8e-08, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/meta-llama/Meta-Llama-3-70B-Instruct': {'max_tokens': 8191, 'max_input_tokens': 8191, 'max_output_tokens': 4096, 'input_cost_per_token': 5.9e-07, 'output_cost_per_token': 7.9e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'deepinfra/01-ai/Yi-34B-200K': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'deepinfra', 'mode': 'completion'}, 'deepinfra/openchat/openchat_3.5': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 1.3e-07, 'litellm_provider': 'deepinfra', 'mode': 'chat'}, 'perplexity/codellama-34b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 3.5e-07, 'output_cost_per_token': 1.4e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/codellama-70b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 2.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-70b-instruct': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-8b-instruct': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-huge-128k-online': {'max_tokens': 127072, 'max_input_tokens': 127072, 'max_output_tokens': 127072, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-large-128k-online': {'max_tokens': 127072, 'max_input_tokens': 127072, 'max_output_tokens': 127072, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-large-128k-chat': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-small-128k-chat': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-3.1-sonar-small-128k-online': {'max_tokens': 127072, 'max_input_tokens': 127072, 'max_output_tokens': 127072, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-7b-chat': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 2.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-7b-online': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 2.8e-07, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/pplx-70b-online': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 0.0, 'output_cost_per_token': 2.8e-06, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/llama-2-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-07, 'output_cost_per_token': 2.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/mistral-7b-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/mixtral-8x7b-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-small-chat': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 7e-08, 'output_cost_per_token': 2.8e-07, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-small-online': {'max_tokens': 12000, 'max_input_tokens': 12000, 'max_output_tokens': 12000, 'input_cost_per_token': 0, 'output_cost_per_token': 2.8e-07, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-medium-chat': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 6e-07, 'output_cost_per_token': 1.8e-06, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'perplexity/sonar-medium-online': {'max_tokens': 12000, 'max_input_tokens': 12000, 'max_output_tokens': 12000, 'input_cost_per_token': 0, 'output_cost_per_token': 1.8e-06, 'input_cost_per_request': 0.005, 'litellm_provider': 'perplexity', 'mode': 'chat'}, 'fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 1e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://fireworks.ai/pricing'}, 'accounts/fireworks/models/llama-v3p2-90b-vision-instruct': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/firefunction-v2': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 65536, 'input_cost_per_token': 1.2e-06, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/yi-large': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 3e-06, 'output_cost_per_token': 3e-06, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 8192, 'input_cost_per_token': 1.2e-06, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'fireworks_ai', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/nomic-ai/nomic-embed-text-v1.5': {'max_tokens': 8192, 'max_input_tokens': 8192, 'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/nomic-ai/nomic-embed-text-v1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/WhereIsAI/UAE-Large-V1': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/thenlper/gte-large': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks_ai/thenlper/gte-base': {'max_tokens': 512, 'max_input_tokens': 512, 'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models', 'mode': 'embedding', 'source': 'https://fireworks.ai/pricing'}, 'fireworks-ai-up-to-16b': {'input_cost_per_token': 2e-07, 'output_cost_per_token': 2e-07, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-16.1b-to-80b': {'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-moe-up-to-56b': {'input_cost_per_token': 5e-07, 'output_cost_per_token': 5e-07, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-56b-to-176b': {'input_cost_per_token': 1.2e-06, 'output_cost_per_token': 1.2e-06, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-default': {'input_cost_per_token': 0.0, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai'}, 'fireworks-ai-embedding-up-to-150m': {'input_cost_per_token': 8e-09, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models'}, 'fireworks-ai-embedding-150m-to-350m': {'input_cost_per_token': 1.6e-08, 'output_cost_per_token': 0.0, 'litellm_provider': 'fireworks_ai-embedding-models'}, 'anyscale/mistralai/Mistral-7B-Instruct-v0.1': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1'}, 'anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1'}, 'anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1': {'max_tokens': 65536, 'max_input_tokens': 65536, 'max_output_tokens': 65536, 'input_cost_per_token': 9e-07, 'output_cost_per_token': 9e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'supports_function_calling': True, 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1'}, 'anyscale/HuggingFaceH4/zephyr-7b-beta': {'max_tokens': 16384, 'max_input_tokens': 16384, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/google/gemma-7b-it': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it'}, 'anyscale/meta-llama/Llama-2-7b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/meta-llama/Llama-2-13b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 2.5e-07, 'output_cost_per_token': 2.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/meta-llama/Llama-2-70b-chat-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/codellama/CodeLlama-34b-Instruct-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat'}, 'anyscale/codellama/CodeLlama-70b-Instruct-hf': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf'}, 'anyscale/meta-llama/Meta-Llama-3-8B-Instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 1.5e-07, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct'}, 'anyscale/meta-llama/Meta-Llama-3-70B-Instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 1e-06, 'litellm_provider': 'anyscale', 'mode': 'chat', 'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct'}, 'cloudflare/@cf/meta/llama-2-7b-chat-fp16': {'max_tokens': 3072, 'max_input_tokens': 3072, 'max_output_tokens': 3072, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'cloudflare/@cf/meta/llama-2-7b-chat-int8': {'max_tokens': 2048, 'max_input_tokens': 2048, 'max_output_tokens': 2048, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'cloudflare/@cf/mistral/mistral-7b-instruct-v0.1': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'cloudflare/@hf/thebloke/codellama-7b-instruct-awq': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.923e-06, 'output_cost_per_token': 1.923e-06, 'litellm_provider': 'cloudflare', 'mode': 'chat'}, 'voyage/voyage-01': {'max_tokens': 4096, 'max_input_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-lite-01': {'max_tokens': 4096, 'max_input_tokens': 4096, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-large-2': {'max_tokens': 16000, 'max_input_tokens': 16000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-law-2': {'max_tokens': 16000, 'max_input_tokens': 16000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-code-2': {'max_tokens': 16000, 'max_input_tokens': 16000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-2': {'max_tokens': 4000, 'max_input_tokens': 4000, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-lite-02-instruct': {'max_tokens': 4000, 'max_input_tokens': 4000, 'input_cost_per_token': 1e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'voyage/voyage-finance-2': {'max_tokens': 4000, 'max_input_tokens': 4000, 'input_cost_per_token': 1.2e-07, 'output_cost_per_token': 0.0, 'litellm_provider': 'voyage', 'mode': 'embedding'}, 'databricks/databricks-meta-llama-3-1-405b-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 5e-06, 'input_dbu_cost_per_token': 7.1429e-05, 'output_cost_per_token': 1.500002e-05, 'output_db_cost_per_token': 0.000214286, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-meta-llama-3-1-70b-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1.00002e-06, 'input_dbu_cost_per_token': 1.4286e-05, 'output_cost_per_token': 2.99999e-06, 'output_dbu_cost_per_token': 4.2857e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-dbrx-instruct': {'max_tokens': 32768, 'max_input_tokens': 32768, 'max_output_tokens': 32768, 'input_cost_per_token': 7.4998e-07, 'input_dbu_cost_per_token': 1.0714e-05, 'output_cost_per_token': 2.24901e-06, 'output_dbu_cost_per_token': 3.2143e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-meta-llama-3-70b-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 128000, 'input_cost_per_token': 1.00002e-06, 'input_dbu_cost_per_token': 1.4286e-05, 'output_cost_per_token': 2.99999e-06, 'output_dbu_cost_per_token': 4.2857e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-llama-2-70b-chat': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5.0001e-07, 'input_dbu_cost_per_token': 7.143e-06, 'output_cost_per_token': 1.5e-06, 'output_dbu_cost_per_token': 2.1429e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-mixtral-8x7b-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 5.0001e-07, 'input_dbu_cost_per_token': 7.143e-06, 'output_cost_per_token': 9.9902e-07, 'output_dbu_cost_per_token': 1.4286e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-mpt-30b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 9.9902e-07, 'input_dbu_cost_per_token': 1.4286e-05, 'output_cost_per_token': 9.9902e-07, 'output_dbu_cost_per_token': 1.4286e-05, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-mpt-7b-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 8192, 'input_cost_per_token': 5.0001e-07, 'input_dbu_cost_per_token': 7.143e-06, 'output_cost_per_token': 0.0, 'output_dbu_cost_per_token': 0.0, 'litellm_provider': 'databricks', 'mode': 'chat', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-bge-large-en': {'max_tokens': 512, 'max_input_tokens': 512, 'output_vector_size': 1024, 'input_cost_per_token': 1.0003e-07, 'input_dbu_cost_per_token': 1.429e-06, 'output_cost_per_token': 0.0, 'output_dbu_cost_per_token': 0.0, 'litellm_provider': 'databricks', 'mode': 'embedding', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'databricks/databricks-gte-large-en': {'max_tokens': 8192, 'max_input_tokens': 8192, 'output_vector_size': 1024, 'input_cost_per_token': 1.2999e-07, 'input_dbu_cost_per_token': 1.857e-06, 'output_cost_per_token': 0.0, 'output_dbu_cost_per_token': 0.0, 'litellm_provider': 'databricks', 'mode': 'embedding', 'source': 'https://www.databricks.com/product/pricing/foundation-model-serving', 'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}}, 'azure/gpt-4o-mini-2024-07-18': {'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.65e-07, 'output_cost_per_token': 6.6e-07, 'cache_read_input_token_cost': 7.5e-08, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_function_calling': True, 'supports_parallel_function_calling': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_prompt_caching': True}, 'amazon.titan-embed-image-v1': {'max_tokens': 128, 'max_input_tokens': 128, 'output_vector_size': 1024, 'input_cost_per_token': 8e-07, 'input_cost_per_image': 6e-05, 'output_cost_per_token': 0.0, 'litellm_provider': 'bedrock', 'supports_image_input': True, 'mode': 'embedding', 'source': 'https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1'}, 'azure_ai/mistral-large-2407': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 2e-06, 'output_cost_per_token': 6e-06, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview'}, 'azure_ai/ministral-3b': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 4e-08, 'output_cost_per_token': 4e-08, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview'}, 'azure_ai/Llama-3.2-11B-Vision-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 3.7e-07, 'output_cost_per_token': 3.7e-07, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'supports_vision': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview'}, 'azure_ai/Llama-3.2-90B-Vision-Instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 2048, 'input_cost_per_token': 2.04e-06, 'output_cost_per_token': 2.04e-06, 'litellm_provider': 'azure_ai', 'supports_function_calling': True, 'supports_vision': True, 'mode': 'chat', 'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview'}, 'azure_ai/Phi-3.5-mini-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3.5-vision-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': True, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3.5-MoE-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.6e-07, 'output_cost_per_token': 6.4e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-mini-4k-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-mini-128k-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.3e-07, 'output_cost_per_token': 5.2e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-small-8k-instruct': {'max_tokens': 8192, 'max_input_tokens': 8192, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-small-128k-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.5e-07, 'output_cost_per_token': 6e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-medium-4k-instruct': {'max_tokens': 4096, 'max_input_tokens': 4096, 'max_output_tokens': 4096, 'input_cost_per_token': 1.7e-07, 'output_cost_per_token': 6.8e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'azure_ai/Phi-3-medium-128k-instruct': {'max_tokens': 128000, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 1.7e-07, 'output_cost_per_token': 6.8e-07, 'litellm_provider': 'azure_ai', 'mode': 'chat', 'supports_vision': False, 'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'}, 'xai/grok-beta': {'max_tokens': 131072, 'max_input_tokens': 131072, 'max_output_tokens': 131072, 'input_cost_per_token': 5e-06, 'output_cost_per_token': 1.5e-05, 'litellm_provider': 'xai', 'mode': 'chat', 'supports_function_calling': True, 'supports_vision': True}, 'claude-3-5-haiku-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'cache_creation_input_token_cost': 1.25e-06, 'cache_read_input_token_cost': 1e-07, 'litellm_provider': 'anthropic', 'mode': 'chat', 'supports_function_calling': True, 'tool_use_system_prompt_tokens': 264, 'supports_assistant_prefill': True, 'supports_prompt_caching': True, 'supports_pdf_input': True}, 'vertex_ai/claude-3-5-haiku@20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'vertex_ai-anthropic_models', 'mode': 'chat', 'supports_function_calling': True, 'supports_assistant_prefill': True}, 'openrouter/anthropic/claude-3-5-haiku': {'max_tokens': 200000, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True}, 'openrouter/anthropic/claude-3-5-haiku-20241022': {'max_tokens': 8192, 'max_input_tokens': 200000, 'max_output_tokens': 8192, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'openrouter', 'mode': 'chat', 'supports_function_calling': True, 'tool_use_system_prompt_tokens': 264}, 'anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_assistant_prefill': True, 'supports_function_calling': True}, 'us.anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_assistant_prefill': True, 'supports_function_calling': True}, 'eu.anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096, 'max_input_tokens': 200000, 'max_output_tokens': 4096, 'input_cost_per_token': 1e-06, 'output_cost_per_token': 5e-06, 'litellm_provider': 'bedrock', 'mode': 'chat', 'supports_function_calling': True}, 'stability.sd3-large-v1:0': {'max_tokens': 77, 'max_input_tokens': 77, 'output_cost_per_image': 0.08, 'litellm_provider': 'bedrock', 'mode': 'image_generation'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Access the JSON file within the package\n",
    "    with pkg_resources.files(package_name).joinpath(resource_name).open('r') as file:\n",
    "        data = json.load(file)\n",
    "    print(data)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{resource_name} not found in the package {package_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4o': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'cache_read_input_token_cost': 1.25e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4o-audio-preview': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'input_cost_per_audio_token': 0.0001,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'output_cost_per_audio_token': 0.0002,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_audio_input': True,\n",
       "  'supports_audio_output': True},\n",
       " 'gpt-4o-audio-preview-2024-10-01': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'input_cost_per_audio_token': 0.0001,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'output_cost_per_audio_token': 0.0002,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_audio_input': True,\n",
       "  'supports_audio_output': True},\n",
       " 'gpt-4o-mini': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'cache_read_input_token_cost': 7.5e-08,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4o-mini-2024-07-18': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'cache_read_input_token_cost': 7.5e-08,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'o1-mini': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'cache_read_input_token_cost': 1.5e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'o1-mini-2024-09-12': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'cache_read_input_token_cost': 1.5e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'o1-preview': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'cache_read_input_token_cost': 7.5e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'o1-preview-2024-09-12': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'cache_read_input_token_cost': 7.5e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'chatgpt-4o-latest': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4o-2024-05-13': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4o-2024-08-06': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'cache_read_input_token_cost': 1.25e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-turbo-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-0314': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-32k': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-05,\n",
       "  'output_cost_per_token': 0.00012,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-32k-0314': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-05,\n",
       "  'output_cost_per_token': 0.00012,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-32k-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-05,\n",
       "  'output_cost_per_token': 0.00012,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-turbo': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-turbo-2024-04-09': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-1106-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-0125-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-vision-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-4-1106-vision-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo-0301': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo-0613': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo-1106': {'max_tokens': 16385,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo-0125': {'max_tokens': 16385,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo-16k': {'max_tokens': 16385,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 4e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'gpt-3.5-turbo-16k-0613': {'max_tokens': 16385,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 4e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_prompt_caching': True},\n",
       " 'ft:gpt-3.5-turbo': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 6e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat'},\n",
       " 'ft:gpt-3.5-turbo-0125': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 6e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat'},\n",
       " 'ft:gpt-3.5-turbo-1106': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 6e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat'},\n",
       " 'ft:gpt-3.5-turbo-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 6e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat'},\n",
       " 'ft:gpt-4-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing'},\n",
       " 'ft:gpt-4o-2024-08-06': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 3.75e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True},\n",
       " 'ft:gpt-4o-mini-2024-07-18': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 1.2e-06,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True},\n",
       " 'ft:davinci-002': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'ft:babbage-002': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 4e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'text-embedding-3-large': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'output_vector_size': 3072,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'embedding'},\n",
       " 'text-embedding-3-small': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'output_vector_size': 1536,\n",
       "  'input_cost_per_token': 2e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'embedding'},\n",
       " 'text-embedding-ada-002': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'output_vector_size': 1536,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'embedding'},\n",
       " 'text-embedding-ada-002-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'embedding'},\n",
       " 'text-moderation-stable': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 0,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'moderations'},\n",
       " 'text-moderation-007': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 0,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'moderations'},\n",
       " 'text-moderation-latest': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 0,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openai',\n",
       "  'mode': 'moderations'},\n",
       " '256-x-256/dall-e-2': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 2.4414e-07,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " '512-x-512/dall-e-2': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 6.86e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " '1024-x-1024/dall-e-2': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 1.9e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'hd/1024-x-1792/dall-e-3': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 6.539e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'hd/1792-x-1024/dall-e-3': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 6.539e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'hd/1024-x-1024/dall-e-3': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 7.629e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'standard/1024-x-1792/dall-e-3': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 4.359e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'standard/1792-x-1024/dall-e-3': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 4.359e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'standard/1024-x-1024/dall-e-3': {'mode': 'image_generation',\n",
       "  'input_cost_per_pixel': 3.81469e-08,\n",
       "  'output_cost_per_pixel': 0.0,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'whisper-1': {'mode': 'audio_transcription',\n",
       "  'input_cost_per_second': 0,\n",
       "  'output_cost_per_second': 0.0001,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'tts-1': {'mode': 'audio_speech',\n",
       "  'input_cost_per_character': 1.5e-05,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'tts-1-hd': {'mode': 'audio_speech',\n",
       "  'input_cost_per_character': 3e-05,\n",
       "  'litellm_provider': 'openai'},\n",
       " 'azure/tts-1': {'mode': 'audio_speech',\n",
       "  'input_cost_per_character': 1.5e-05,\n",
       "  'litellm_provider': 'azure'},\n",
       " 'azure/tts-1-hd': {'mode': 'audio_speech',\n",
       "  'input_cost_per_character': 3e-05,\n",
       "  'litellm_provider': 'azure'},\n",
       " 'azure/whisper-1': {'mode': 'audio_transcription',\n",
       "  'input_cost_per_second': 0,\n",
       "  'output_cost_per_second': 0.0001,\n",
       "  'litellm_provider': 'azure'},\n",
       " 'azure/o1-mini': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'cache_read_input_token_cost': 1.5e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/o1-mini-2024-09-12': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'cache_read_input_token_cost': 1.5e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/o1-preview': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'cache_read_input_token_cost': 7.5e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/o1-preview-2024-09-12': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'cache_read_input_token_cost': 7.5e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/gpt-4o': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'cache_read_input_token_cost': 1.25e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/gpt-4o-2024-08-06': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2.75e-06,\n",
       "  'output_cost_per_token': 1.1e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True},\n",
       " 'azure/gpt-4o-2024-05-13': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/global-standard/gpt-4o-2024-08-06': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True},\n",
       " 'azure/global-standard/gpt-4o-mini': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True},\n",
       " 'azure/gpt-4o-mini': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.65e-07,\n",
       "  'output_cost_per_token': 6.6e-07,\n",
       "  'cache_read_input_token_cost': 7.5e-08,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'azure/gpt-4-turbo-2024-04-09': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'azure/gpt-4-0125-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-4-1106-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-4-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/gpt-4-32k-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-05,\n",
       "  'output_cost_per_token': 0.00012,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat'},\n",
       " 'azure/gpt-4-32k': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-05,\n",
       "  'output_cost_per_token': 0.00012,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat'},\n",
       " 'azure/gpt-4': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/gpt-4-turbo': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-4-turbo-vision-preview': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': True},\n",
       " 'azure/gpt-35-turbo-16k-0613': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 4e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/gpt-35-turbo-1106': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-35-turbo-0613': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-35-turbo-0301': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-35-turbo-0125': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True},\n",
       " 'azure/gpt-35-turbo-16k': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16385,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 4e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat'},\n",
       " 'azure/gpt-35-turbo': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4097,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/gpt-3.5-turbo-instruct-0914': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'azure/gpt-35-turbo-instruct': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'azure/gpt-35-turbo-instruct-0914': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 4097,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'azure/mistral-large-latest': {'max_tokens': 32000,\n",
       "  'max_input_tokens': 32000,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/mistral-large-2402': {'max_tokens': 32000,\n",
       "  'max_input_tokens': 32000,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/command-r-plus': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure/ada': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'embedding'},\n",
       " 'azure/text-embedding-ada-002': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'embedding'},\n",
       " 'azure/text-embedding-3-large': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'embedding'},\n",
       " 'azure/text-embedding-3-small': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'input_cost_per_token': 2e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'embedding'},\n",
       " 'azure/standard/1024-x-1024/dall-e-3': {'input_cost_per_pixel': 3.81469e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure/hd/1024-x-1024/dall-e-3': {'input_cost_per_pixel': 7.629e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure/standard/1024-x-1792/dall-e-3': {'input_cost_per_pixel': 4.359e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure/standard/1792-x-1024/dall-e-3': {'input_cost_per_pixel': 4.359e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure/hd/1024-x-1792/dall-e-3': {'input_cost_per_pixel': 6.539e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure/hd/1792-x-1024/dall-e-3': {'input_cost_per_pixel': 6.539e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure/standard/1024-x-1024/dall-e-2': {'input_cost_per_pixel': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'image_generation'},\n",
       " 'azure_ai/jamba-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 70000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 7e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat'},\n",
       " 'azure_ai/mistral-large': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 4e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'azure_ai/mistral-small': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'mode': 'chat'},\n",
       " 'azure_ai/Meta-Llama-3-70B-Instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.1e-06,\n",
       "  'output_cost_per_token': 3.7e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat'},\n",
       " 'azure_ai/Meta-Llama-3.1-8B-Instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 6.1e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice'},\n",
       " 'azure_ai/Meta-Llama-3.1-70B-Instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 2.68e-06,\n",
       "  'output_cost_per_token': 3.54e-06,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice'},\n",
       " 'azure_ai/Meta-Llama-3.1-405B-Instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 5.33e-06,\n",
       "  'output_cost_per_token': 1.6e-05,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice'},\n",
       " 'azure_ai/cohere-rerank-v3-multilingual': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'max_query_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'input_cost_per_query': 0.002,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'rerank'},\n",
       " 'azure_ai/cohere-rerank-v3-english': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'max_query_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'input_cost_per_query': 0.002,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'rerank'},\n",
       " 'azure_ai/Cohere-embed-v3-english': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'output_vector_size': 1024,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice'},\n",
       " 'azure_ai/Cohere-embed-v3-multilingual': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'output_vector_size': 1024,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice'},\n",
       " 'babbage-002': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 4e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'davinci-002': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'gpt-3.5-turbo-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'gpt-3.5-turbo-instruct-0914': {'max_tokens': 4097,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4097,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'text-completion-openai',\n",
       "  'mode': 'completion'},\n",
       " 'claude-instant-1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.63e-06,\n",
       "  'output_cost_per_token': 5.51e-06,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat'},\n",
       " 'mistral/mistral-tiny': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-small': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'supports_function_calling': True,\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-small-latest': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'supports_function_calling': True,\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-medium': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.7e-06,\n",
       "  'output_cost_per_token': 8.1e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-medium-latest': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.7e-06,\n",
       "  'output_cost_per_token': 8.1e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-medium-2312': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.7e-06,\n",
       "  'output_cost_per_token': 8.1e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-large-latest': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 9e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-large-2402': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 4e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-large-2407': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 9e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/pixtral-12b-2409': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_vision': True},\n",
       " 'mistral/open-mistral-7b': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/open-mixtral-8x7b': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 7e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/open-mixtral-8x22b': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 64000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 6e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/codestral-latest': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/codestral-2405': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/open-mistral-nemo': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://mistral.ai/technology/',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/open-mistral-nemo-2407': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://mistral.ai/technology/',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/open-codestral-mamba': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://mistral.ai/technology/',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/codestral-mamba-latest': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://mistral.ai/technology/',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'mistral/mistral-embed': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'mistral',\n",
       "  'mode': 'embedding'},\n",
       " 'deepseek-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.4e-07,\n",
       "  'input_cost_per_token_cache_hit': 1.4e-08,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'deepseek',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'codestral/codestral-latest': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'codestral',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://docs.mistral.ai/capabilities/code_generation/',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'codestral/codestral-2405': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'codestral',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://docs.mistral.ai/capabilities/code_generation/',\n",
       "  'supports_assistant_prefill': True},\n",
       " 'text-completion-codestral/codestral-latest': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'text-completion-codestral',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://docs.mistral.ai/capabilities/code_generation/'},\n",
       " 'text-completion-codestral/codestral-2405': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'text-completion-codestral',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://docs.mistral.ai/capabilities/code_generation/'},\n",
       " 'deepseek-coder': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.4e-07,\n",
       "  'input_cost_per_token_cache_hit': 1.4e-08,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'deepseek',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'groq/llama2-70b-4096': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 8e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama3-8b-8192': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 8e-08,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama3-70b-8192': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5.9e-07,\n",
       "  'output_cost_per_token': 7.9e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama-3.1-8b-instant': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 8e-08,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama-3.1-70b-versatile': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5.9e-07,\n",
       "  'output_cost_per_token': 7.9e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama-3.1-405b-reasoning': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5.9e-07,\n",
       "  'output_cost_per_token': 7.9e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/mixtral-8x7b-32768': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 2.4e-07,\n",
       "  'output_cost_per_token': 2.4e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/gemma-7b-it': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 7e-08,\n",
       "  'output_cost_per_token': 7e-08,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/gemma2-9b-it': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama3-groq-70b-8192-tool-use-preview': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 8.9e-07,\n",
       "  'output_cost_per_token': 8.9e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'groq/llama3-groq-8b-8192-tool-use-preview': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.9e-07,\n",
       "  'output_cost_per_token': 1.9e-07,\n",
       "  'litellm_provider': 'groq',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'cerebras/llama3.1-8b': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'cerebras',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'cerebras/llama3.1-70b': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'cerebras',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'friendliai/mixtral-8x7b-instruct-v0-1': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 4e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'friendliai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'friendliai/meta-llama-3-8b-instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'friendliai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'friendliai/meta-llama-3-70b-instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 8e-07,\n",
       "  'output_cost_per_token': 8e-07,\n",
       "  'litellm_provider': 'friendliai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'claude-instant-1.2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.63e-07,\n",
       "  'output_cost_per_token': 5.51e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat'},\n",
       " 'claude-2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat'},\n",
       " 'claude-2.1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat'},\n",
       " 'claude-3-haiku-20240307': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'cache_creation_input_token_cost': 3e-07,\n",
       "  'cache_read_input_token_cost': 3e-08,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 264,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-haiku-latest': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'cache_creation_input_token_cost': 3e-07,\n",
       "  'cache_read_input_token_cost': 3e-08,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 264,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-opus-20240229': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'cache_creation_input_token_cost': 1.875e-05,\n",
       "  'cache_read_input_token_cost': 1.5e-06,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 395,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-opus-latest': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'cache_creation_input_token_cost': 1.875e-05,\n",
       "  'cache_read_input_token_cost': 1.5e-06,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 395,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-sonnet-20240229': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-5-sonnet-20240620': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'cache_creation_input_token_cost': 3.75e-06,\n",
       "  'cache_read_input_token_cost': 3e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-5-sonnet-20241022': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'cache_creation_input_token_cost': 3.75e-06,\n",
       "  'cache_read_input_token_cost': 3e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'claude-3-5-sonnet-latest': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'cache_creation_input_token_cost': 3.75e-06,\n",
       "  'cache_read_input_token_cost': 3e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'text-bison': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-bison@001': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-bison@002': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-bison32k': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-bison32k@002': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-unicorn': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 2.8e-05,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-unicorn@001': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 2.8e-05,\n",
       "  'litellm_provider': 'vertex_ai-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'chat-bison': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'chat-bison@001': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'chat-bison@002': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'chat-bison-32k': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'chat-bison-32k@002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-bison': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-bison@001': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-bison@002': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-bison32k': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-bison-32k@002': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-gecko@001': {'max_tokens': 64,\n",
       "  'max_input_tokens': 2048,\n",
       "  'max_output_tokens': 64,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-gecko@002': {'max_tokens': 64,\n",
       "  'max_input_tokens': 2048,\n",
       "  'max_output_tokens': 64,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-gecko': {'max_tokens': 64,\n",
       "  'max_input_tokens': 2048,\n",
       "  'max_output_tokens': 64,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'code-gecko-latest': {'max_tokens': 64,\n",
       "  'max_input_tokens': 2048,\n",
       "  'max_output_tokens': 64,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-text-models',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'codechat-bison@latest': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'codechat-bison': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'codechat-bison@001': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'codechat-bison@002': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 6144,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'codechat-bison-32k': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'codechat-bison-32k@002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'input_cost_per_character': 2.5e-07,\n",
       "  'output_cost_per_character': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-code-chat-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-pro': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32760,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'input_cost_per_video_per_second': 0.002,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'input_cost_per_character': 1.25e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_character': 3.75e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'},\n",
       " 'gemini-1.0-pro': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32760,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'input_cost_per_video_per_second': 0.002,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'input_cost_per_character': 1.25e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_character': 3.75e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models'},\n",
       " 'gemini-1.0-pro-001': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32760,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'input_cost_per_video_per_second': 0.002,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'input_cost_per_character': 1.25e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_character': 3.75e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.0-ultra': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'input_cost_per_video_per_second': 0.002,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'input_cost_per_character': 1.25e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_character': 3.75e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.0-ultra-001': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'input_cost_per_video_per_second': 0.002,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'input_cost_per_character': 1.25e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_character': 3.75e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.0-pro-002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32760,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'input_cost_per_video_per_second': 0.002,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'input_cost_per_character': 1.25e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_character': 3.75e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-pro': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.00032875,\n",
       "  'input_cost_per_audio_per_second': 3.125e-05,\n",
       "  'input_cost_per_video_per_second': 0.00032875,\n",
       "  'input_cost_per_token': 1.25e-06,\n",
       "  'input_cost_per_character': 3.125e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05,\n",
       "  'input_cost_per_token_above_128k_tokens': 2.5e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'output_cost_per_character': 1.25e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 1e-05,\n",
       "  'output_cost_per_character_above_128k_tokens': 2.5e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-pro-002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.00032875,\n",
       "  'input_cost_per_audio_per_second': 3.125e-05,\n",
       "  'input_cost_per_video_per_second': 0.00032875,\n",
       "  'input_cost_per_token': 1.25e-06,\n",
       "  'input_cost_per_character': 3.125e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05,\n",
       "  'input_cost_per_token_above_128k_tokens': 2.5e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'output_cost_per_character': 1.25e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 1e-05,\n",
       "  'output_cost_per_character_above_128k_tokens': 2.5e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro'},\n",
       " 'gemini-1.5-pro-001': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.00032875,\n",
       "  'input_cost_per_audio_per_second': 3.125e-05,\n",
       "  'input_cost_per_video_per_second': 0.00032875,\n",
       "  'input_cost_per_token': 1.25e-06,\n",
       "  'input_cost_per_character': 3.125e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05,\n",
       "  'input_cost_per_token_above_128k_tokens': 2.5e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'output_cost_per_character': 1.25e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 1e-05,\n",
       "  'output_cost_per_character_above_128k_tokens': 2.5e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-pro-preview-0514': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.00032875,\n",
       "  'input_cost_per_audio_per_second': 3.125e-05,\n",
       "  'input_cost_per_video_per_second': 0.00032875,\n",
       "  'input_cost_per_token': 7.8125e-08,\n",
       "  'input_cost_per_character': 3.125e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5625e-07,\n",
       "  'input_cost_per_character_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_token': 3.125e-07,\n",
       "  'output_cost_per_character': 1.25e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_character_above_128k_tokens': 2.5e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-pro-preview-0215': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.00032875,\n",
       "  'input_cost_per_audio_per_second': 3.125e-05,\n",
       "  'input_cost_per_video_per_second': 0.00032875,\n",
       "  'input_cost_per_token': 7.8125e-08,\n",
       "  'input_cost_per_character': 3.125e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5625e-07,\n",
       "  'input_cost_per_character_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_token': 3.125e-07,\n",
       "  'output_cost_per_character': 1.25e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_character_above_128k_tokens': 2.5e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-pro-preview-0409': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_image': 0.00032875,\n",
       "  'input_cost_per_audio_per_second': 3.125e-05,\n",
       "  'input_cost_per_video_per_second': 0.00032875,\n",
       "  'input_cost_per_token': 7.8125e-08,\n",
       "  'input_cost_per_character': 3.125e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 0.0006575,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 6.25e-05,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5625e-07,\n",
       "  'input_cost_per_character_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_token': 3.125e-07,\n",
       "  'output_cost_per_character': 1.25e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 6.25e-07,\n",
       "  'output_cost_per_character_above_128k_tokens': 2.5e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-flash': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_image': 2e-05,\n",
       "  'input_cost_per_video_per_second': 2e-05,\n",
       "  'input_cost_per_audio_per_second': 2e-06,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_character': 1.875e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 2.5e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 4e-06,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_character': 7.5e-08,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'output_cost_per_character_above_128k_tokens': 1.5e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-flash-exp-0827': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_image': 2e-05,\n",
       "  'input_cost_per_video_per_second': 2e-05,\n",
       "  'input_cost_per_audio_per_second': 2e-06,\n",
       "  'input_cost_per_token': 4.688e-09,\n",
       "  'input_cost_per_character': 1.875e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 2.5e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 4e-06,\n",
       "  'output_cost_per_token': 4.6875e-09,\n",
       "  'output_cost_per_character': 1.875e-08,\n",
       "  'output_cost_per_token_above_128k_tokens': 9.375e-09,\n",
       "  'output_cost_per_character_above_128k_tokens': 3.75e-08,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-flash-002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_image': 2e-05,\n",
       "  'input_cost_per_video_per_second': 2e-05,\n",
       "  'input_cost_per_audio_per_second': 2e-06,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_character': 1.875e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 2.5e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 4e-06,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_character': 7.5e-08,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'output_cost_per_character_above_128k_tokens': 1.5e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash'},\n",
       " 'gemini-1.5-flash-001': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_image': 2e-05,\n",
       "  'input_cost_per_video_per_second': 2e-05,\n",
       "  'input_cost_per_audio_per_second': 2e-06,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_character': 1.875e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 2.5e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 4e-06,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_character': 7.5e-08,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'output_cost_per_character_above_128k_tokens': 1.5e-07,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.5-flash-preview-0514': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_image': 2e-05,\n",
       "  'input_cost_per_video_per_second': 2e-05,\n",
       "  'input_cost_per_audio_per_second': 2e-06,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_character': 1.875e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1e-06,\n",
       "  'input_cost_per_character_above_128k_tokens': 2.5e-07,\n",
       "  'input_cost_per_image_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_video_per_second_above_128k_tokens': 4e-05,\n",
       "  'input_cost_per_audio_per_second_above_128k_tokens': 4e-06,\n",
       "  'output_cost_per_token': 4.6875e-09,\n",
       "  'output_cost_per_character': 1.875e-08,\n",
       "  'output_cost_per_token_above_128k_tokens': 9.375e-09,\n",
       "  'output_cost_per_character_above_128k_tokens': 3.75e-08,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-pro-experimental': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0,\n",
       "  'output_cost_per_token': 0,\n",
       "  'input_cost_per_character': 0,\n",
       "  'output_cost_per_character': 0,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': False,\n",
       "  'supports_tool_choice': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental'},\n",
       " 'gemini-flash-experimental': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0,\n",
       "  'output_cost_per_token': 0,\n",
       "  'input_cost_per_character': 0,\n",
       "  'output_cost_per_character': 0,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': False,\n",
       "  'supports_tool_choice': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental'},\n",
       " 'gemini-pro-vision': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 2048,\n",
       "  'max_images_per_prompt': 16,\n",
       "  'max_videos_per_prompt': 1,\n",
       "  'max_video_length': 2,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-vision-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.0-pro-vision': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 2048,\n",
       "  'max_images_per_prompt': 16,\n",
       "  'max_videos_per_prompt': 1,\n",
       "  'max_video_length': 2,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-vision-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini-1.0-pro-vision-001': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 2048,\n",
       "  'max_images_per_prompt': 16,\n",
       "  'max_videos_per_prompt': 1,\n",
       "  'max_video_length': 2,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'vertex_ai-vision-models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'medlm-medium': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_character': 5e-07,\n",
       "  'output_cost_per_character': 1e-06,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'medlm-large': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_character': 5e-06,\n",
       "  'output_cost_per_character': 1.5e-05,\n",
       "  'litellm_provider': 'vertex_ai-language-models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'vertex_ai/claude-3-sonnet@20240229': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'vertex_ai-anthropic_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'vertex_ai/claude-3-5-sonnet@20240620': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'vertex_ai-anthropic_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'vertex_ai/claude-3-5-sonnet-v2@20241022': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'vertex_ai-anthropic_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'vertex_ai/claude-3-haiku@20240307': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'litellm_provider': 'vertex_ai-anthropic_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'vertex_ai/claude-3-opus@20240229': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'litellm_provider': 'vertex_ai-anthropic_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'vertex_ai/meta/llama3-405b-instruct-maas': {'max_tokens': 32000,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 32000,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'vertex_ai-llama_models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'},\n",
       " 'vertex_ai/meta/llama3-70b-instruct-maas': {'max_tokens': 32000,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 32000,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'vertex_ai-llama_models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'},\n",
       " 'vertex_ai/meta/llama3-8b-instruct-maas': {'max_tokens': 32000,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 32000,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'vertex_ai-llama_models',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models'},\n",
       " 'vertex_ai/meta/llama-3.2-90b-vision-instruct-maas': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'vertex_ai-llama_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas'},\n",
       " 'vertex_ai/mistral-large@latest': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 9e-06,\n",
       "  'litellm_provider': 'vertex_ai-mistral_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'vertex_ai/mistral-large@2407': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 9e-06,\n",
       "  'litellm_provider': 'vertex_ai-mistral_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'vertex_ai/mistral-nemo@latest': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'vertex_ai-mistral_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'vertex_ai/jamba-1.5-mini@001': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'vertex_ai-ai21_models',\n",
       "  'mode': 'chat'},\n",
       " 'vertex_ai/jamba-1.5-large@001': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 8e-06,\n",
       "  'litellm_provider': 'vertex_ai-ai21_models',\n",
       "  'mode': 'chat'},\n",
       " 'vertex_ai/jamba-1.5': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'vertex_ai-ai21_models',\n",
       "  'mode': 'chat'},\n",
       " 'vertex_ai/jamba-1.5-mini': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'vertex_ai-ai21_models',\n",
       "  'mode': 'chat'},\n",
       " 'vertex_ai/jamba-1.5-large': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 8e-06,\n",
       "  'litellm_provider': 'vertex_ai-ai21_models',\n",
       "  'mode': 'chat'},\n",
       " 'vertex_ai/mistral-nemo@2407': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'vertex_ai-mistral_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'vertex_ai/codestral@latest': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'vertex_ai-mistral_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'vertex_ai/codestral@2405': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'vertex_ai-mistral_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'vertex_ai/imagegeneration@006': {'cost_per_image': 0.02,\n",
       "  'litellm_provider': 'vertex_ai-image-models',\n",
       "  'mode': 'image_generation',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'},\n",
       " 'vertex_ai/imagen-3.0-generate-001': {'cost_per_image': 0.04,\n",
       "  'litellm_provider': 'vertex_ai-image-models',\n",
       "  'mode': 'image_generation',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'},\n",
       " 'vertex_ai/imagen-3.0-fast-generate-001': {'cost_per_image': 0.02,\n",
       "  'litellm_provider': 'vertex_ai-image-models',\n",
       "  'mode': 'image_generation',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'},\n",
       " 'text-embedding-004': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models'},\n",
       " 'text-multilingual-embedding-002': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 2048,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models'},\n",
       " 'textembedding-gecko': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'textembedding-gecko-multilingual': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'textembedding-gecko-multilingual@001': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'textembedding-gecko@001': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'textembedding-gecko@003': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'text-embedding-preview-0409': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'input_cost_per_token_batch_requests': 5e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/pricing'},\n",
       " 'text-multilingual-embedding-preview-0409': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'output_vector_size': 768,\n",
       "  'input_cost_per_token': 6.25e-09,\n",
       "  'output_cost_per_token': 0,\n",
       "  'litellm_provider': 'vertex_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'palm/chat-bison': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'palm',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'palm/chat-bison-001': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'palm',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'palm/text-bison': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'palm',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'palm/text-bison-001': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'palm',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'palm/text-bison-safety-off': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'palm',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'palm/text-bison-safety-recitation-off': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 1024,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 1.25e-07,\n",
       "  'litellm_provider': 'palm',\n",
       "  'mode': 'completion',\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini/gemini-1.5-flash-002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_prompt_caching': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-flash-001': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_prompt_caching': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-flash': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-flash-latest': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 7.5e-08,\n",
       "  'input_cost_per_token_above_128k_tokens': 1.5e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token_above_128k_tokens': 6e-07,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-flash-8b-exp-0924': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 0,\n",
       "  'input_cost_per_token_above_128k_tokens': 0,\n",
       "  'output_cost_per_token': 0,\n",
       "  'output_cost_per_token_above_128k_tokens': 0,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-flash-exp-0827': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 0,\n",
       "  'input_cost_per_token_above_128k_tokens': 0,\n",
       "  'output_cost_per_token': 0,\n",
       "  'output_cost_per_token_above_128k_tokens': 0,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-flash-8b-exp-0827': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'max_images_per_prompt': 3000,\n",
       "  'max_videos_per_prompt': 10,\n",
       "  'max_video_length': 1,\n",
       "  'max_audio_length_hours': 8.4,\n",
       "  'max_audio_per_prompt': 1,\n",
       "  'max_pdf_size_mb': 30,\n",
       "  'input_cost_per_token': 0,\n",
       "  'input_cost_per_token_above_128k_tokens': 0,\n",
       "  'output_cost_per_token': 0,\n",
       "  'output_cost_per_token_above_128k_tokens': 0,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-pro': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 32760,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-07,\n",
       "  'output_cost_per_token': 1.05e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-06,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini/gemini-1.5-pro': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-06,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-06,\n",
       "  'output_cost_per_token': 1.05e-05,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-05,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-pro-002': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-06,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-06,\n",
       "  'output_cost_per_token': 1.05e-05,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-05,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_prompt_caching': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-pro-001': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-06,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-06,\n",
       "  'output_cost_per_token': 1.05e-05,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-05,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_prompt_caching': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-pro-exp-0801': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-06,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-06,\n",
       "  'output_cost_per_token': 1.05e-05,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-05,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-pro-exp-0827': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 2097152,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0,\n",
       "  'input_cost_per_token_above_128k_tokens': 0,\n",
       "  'output_cost_per_token': 0,\n",
       "  'output_cost_per_token_above_128k_tokens': 0,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-1.5-pro-latest': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1048576,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-06,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-06,\n",
       "  'output_cost_per_token': 1.05e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-05,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True,\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_tool_choice': True,\n",
       "  'supports_response_schema': True,\n",
       "  'source': 'https://ai.google.dev/pricing'},\n",
       " 'gemini/gemini-pro-vision': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 30720,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'input_cost_per_token_above_128k_tokens': 7e-07,\n",
       "  'output_cost_per_token': 1.05e-06,\n",
       "  'output_cost_per_token_above_128k_tokens': 2.1e-06,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini/gemini-gemma-2-27b-it': {'max_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'output_cost_per_token': 1.05e-06,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'gemini/gemini-gemma-2-9b-it': {'max_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'output_cost_per_token': 1.05e-06,\n",
       "  'litellm_provider': 'gemini',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models'},\n",
       " 'command-r': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'cohere_chat',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'command-r-08-2024': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'cohere_chat',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'command-light': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'cohere_chat',\n",
       "  'mode': 'chat'},\n",
       " 'command-r-plus': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'litellm_provider': 'cohere_chat',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'command-r-plus-08-2024': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'litellm_provider': 'cohere_chat',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'command-nightly': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'completion'},\n",
       " 'command': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'completion'},\n",
       " 'rerank-english-v3.0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'max_query_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'input_cost_per_query': 0.002,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'rerank'},\n",
       " 'rerank-multilingual-v3.0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'max_query_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'input_cost_per_query': 0.002,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'rerank'},\n",
       " 'rerank-english-v2.0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'max_query_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'input_cost_per_query': 0.002,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'rerank'},\n",
       " 'rerank-multilingual-v2.0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'max_query_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'input_cost_per_query': 0.002,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'rerank'},\n",
       " 'embed-english-v3.0': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 1024,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'input_cost_per_image': 0.0001,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'embedding',\n",
       "  'supports_image_input': True},\n",
       " 'embed-english-light-v3.0': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 1024,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'embedding'},\n",
       " 'embed-multilingual-v3.0': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 1024,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'embedding'},\n",
       " 'embed-english-v2.0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'embedding'},\n",
       " 'embed-english-light-v2.0': {'max_tokens': 1024,\n",
       "  'max_input_tokens': 1024,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'embedding'},\n",
       " 'embed-multilingual-v2.0': {'max_tokens': 768,\n",
       "  'max_input_tokens': 768,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'cohere',\n",
       "  'mode': 'embedding'},\n",
       " 'replicate/meta/llama-2-13b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-2-13b-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-2-70b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6.5e-07,\n",
       "  'output_cost_per_token': 2.75e-06,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-2-70b-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6.5e-07,\n",
       "  'output_cost_per_token': 2.75e-06,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-2-7b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-2-7b-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-3-70b': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 6.5e-07,\n",
       "  'output_cost_per_token': 2.75e-06,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-3-70b-instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 6.5e-07,\n",
       "  'output_cost_per_token': 2.75e-06,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-3-8b': {'max_tokens': 8086,\n",
       "  'max_input_tokens': 8086,\n",
       "  'max_output_tokens': 8086,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/meta/llama-3-8b-instruct': {'max_tokens': 8086,\n",
       "  'max_input_tokens': 8086,\n",
       "  'max_output_tokens': 8086,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/mistralai/mistral-7b-v0.1': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/mistralai/mistral-7b-instruct-v0.2': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-08,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'replicate/mistralai/mixtral-8x7b-instruct-v0.1': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'replicate',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/deepseek/deepseek-coder': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.4e-07,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/microsoft/wizardlm-2-8x22b:nitro': {'max_tokens': 65536,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/google/gemini-pro-1.5': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 1000000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 2.5e-06,\n",
       "  'output_cost_per_token': 7.5e-06,\n",
       "  'input_cost_per_image': 0.00265,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/mistralai/mixtral-8x22b-instruct': {'max_tokens': 65536,\n",
       "  'input_cost_per_token': 6.5e-07,\n",
       "  'output_cost_per_token': 6.5e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/cohere/command-r-plus': {'max_tokens': 128000,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/databricks/dbrx-instruct': {'max_tokens': 32768,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/anthropic/claude-3-haiku': {'max_tokens': 200000,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'input_cost_per_image': 0.0004,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/anthropic/claude-3-haiku-20240307': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 264},\n",
       " 'anthropic/claude-3-5-sonnet-20241022': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'cache_creation_input_token_cost': 3.75e-06,\n",
       "  'cache_read_input_token_cost': 3e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'anthropic/claude-3-5-sonnet-latest': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'cache_creation_input_token_cost': 3.75e-06,\n",
       "  'cache_read_input_token_cost': 3e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'openrouter/anthropic/claude-3.5-sonnet': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'openrouter/anthropic/claude-3.5-sonnet:beta': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 159},\n",
       " 'openrouter/anthropic/claude-3-sonnet': {'max_tokens': 200000,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'input_cost_per_image': 0.0048,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/mistralai/mistral-large': {'max_tokens': 32000,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/cognitivecomputations/dolphin-mixtral-8x7b': {'max_tokens': 32769,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/google/gemini-pro-vision': {'max_tokens': 45875,\n",
       "  'input_cost_per_token': 1.25e-07,\n",
       "  'output_cost_per_token': 3.75e-07,\n",
       "  'input_cost_per_image': 0.0025,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/fireworks/firellava-13b': {'max_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/llama-3-8b-instruct:free': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/llama-3-8b-instruct:extended': {'max_tokens': 16384,\n",
       "  'input_cost_per_token': 2.25e-07,\n",
       "  'output_cost_per_token': 2.25e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/llama-3-70b-instruct:nitro': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/llama-3-70b-instruct': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 5.9e-07,\n",
       "  'output_cost_per_token': 7.9e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/openai/o1-mini': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False},\n",
       " 'openrouter/openai/o1-mini-2024-09-12': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.2e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False},\n",
       " 'openrouter/openai/o1-preview': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False},\n",
       " 'openrouter/openai/o1-preview-2024-09-12': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': False},\n",
       " 'openrouter/openai/gpt-4o': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/openai/gpt-4o-2024-05-13': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/openai/gpt-4-vision-preview': {'max_tokens': 130000,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 3e-05,\n",
       "  'input_cost_per_image': 0.01445,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'openrouter/openai/gpt-3.5-turbo': {'max_tokens': 4095,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/openai/gpt-3.5-turbo-16k': {'max_tokens': 16383,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 4e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/openai/gpt-4': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 6e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/anthropic/claude-instant-v1': {'max_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.63e-06,\n",
       "  'output_cost_per_token': 5.51e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/anthropic/claude-2': {'max_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.102e-05,\n",
       "  'output_cost_per_token': 3.268e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/anthropic/claude-3-opus': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'tool_use_system_prompt_tokens': 395},\n",
       " 'openrouter/google/palm-2-chat-bison': {'max_tokens': 25804,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/google/palm-2-codechat-bison': {'max_tokens': 20070,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/llama-2-13b-chat': {'max_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/llama-2-70b-chat': {'max_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/meta-llama/codellama-34b-instruct': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/nousresearch/nous-hermes-llama2-13b': {'max_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/mancer/weaver': {'max_tokens': 8000,\n",
       "  'input_cost_per_token': 5.625e-06,\n",
       "  'output_cost_per_token': 5.625e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/gryphe/mythomax-l2-13b': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 1.875e-06,\n",
       "  'output_cost_per_token': 1.875e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/jondurbin/airoboros-l2-70b-2.1': {'max_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3875e-05,\n",
       "  'output_cost_per_token': 1.3875e-05,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/undi95/remm-slerp-l2-13b': {'max_tokens': 6144,\n",
       "  'input_cost_per_token': 1.875e-06,\n",
       "  'output_cost_per_token': 1.875e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/pygmalionai/mythalion-13b': {'max_tokens': 4096,\n",
       "  'input_cost_per_token': 1.875e-06,\n",
       "  'output_cost_per_token': 1.875e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/mistralai/mistral-7b-instruct': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 1.3e-07,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'openrouter/mistralai/mistral-7b-instruct:free': {'max_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat'},\n",
       " 'j2-ultra': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'completion'},\n",
       " 'jamba-1.5-mini@001': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'chat'},\n",
       " 'jamba-1.5-large@001': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 8e-06,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'chat'},\n",
       " 'jamba-1.5': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'chat'},\n",
       " 'jamba-1.5-mini': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'chat'},\n",
       " 'jamba-1.5-large': {'max_tokens': 256000,\n",
       "  'max_input_tokens': 256000,\n",
       "  'max_output_tokens': 256000,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 8e-06,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'chat'},\n",
       " 'j2-mid': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-05,\n",
       "  'output_cost_per_token': 1e-05,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'completion'},\n",
       " 'j2-light': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'ai21',\n",
       "  'mode': 'completion'},\n",
       " 'dolphin': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'nlp_cloud',\n",
       "  'mode': 'completion'},\n",
       " 'chatdolphin': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'nlp_cloud',\n",
       "  'mode': 'chat'},\n",
       " 'luminous-base': {'max_tokens': 2048,\n",
       "  'input_cost_per_token': 3e-05,\n",
       "  'output_cost_per_token': 3.3e-05,\n",
       "  'litellm_provider': 'aleph_alpha',\n",
       "  'mode': 'completion'},\n",
       " 'luminous-base-control': {'max_tokens': 2048,\n",
       "  'input_cost_per_token': 3.75e-05,\n",
       "  'output_cost_per_token': 4.125e-05,\n",
       "  'litellm_provider': 'aleph_alpha',\n",
       "  'mode': 'chat'},\n",
       " 'luminous-extended': {'max_tokens': 2048,\n",
       "  'input_cost_per_token': 4.5e-05,\n",
       "  'output_cost_per_token': 4.95e-05,\n",
       "  'litellm_provider': 'aleph_alpha',\n",
       "  'mode': 'completion'},\n",
       " 'luminous-extended-control': {'max_tokens': 2048,\n",
       "  'input_cost_per_token': 5.625e-05,\n",
       "  'output_cost_per_token': 6.1875e-05,\n",
       "  'litellm_provider': 'aleph_alpha',\n",
       "  'mode': 'chat'},\n",
       " 'luminous-supreme': {'max_tokens': 2048,\n",
       "  'input_cost_per_token': 0.000175,\n",
       "  'output_cost_per_token': 0.0001925,\n",
       "  'litellm_provider': 'aleph_alpha',\n",
       "  'mode': 'completion'},\n",
       " 'luminous-supreme-control': {'max_tokens': 2048,\n",
       "  'input_cost_per_token': 0.00021875,\n",
       "  'output_cost_per_token': 0.000240625,\n",
       "  'litellm_provider': 'aleph_alpha',\n",
       "  'mode': 'chat'},\n",
       " 'ai21.j2-mid-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.25e-05,\n",
       "  'output_cost_per_token': 1.25e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'ai21.j2-ultra-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.88e-05,\n",
       "  'output_cost_per_token': 1.88e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'ai21.jamba-instruct-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 70000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 7e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_system_messages': True},\n",
       " 'amazon.titan-text-lite-v1': {'max_tokens': 4000,\n",
       "  'max_input_tokens': 42000,\n",
       "  'max_output_tokens': 4000,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 4e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'amazon.titan-text-express-v1': {'max_tokens': 8000,\n",
       "  'max_input_tokens': 42000,\n",
       "  'max_output_tokens': 8000,\n",
       "  'input_cost_per_token': 1.3e-06,\n",
       "  'output_cost_per_token': 1.7e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'amazon.titan-text-premier-v1:0': {'max_tokens': 32000,\n",
       "  'max_input_tokens': 42000,\n",
       "  'max_output_tokens': 32000,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'amazon.titan-embed-text-v1': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'output_vector_size': 1536,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'embedding'},\n",
       " 'amazon.titan-embed-text-v2:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'output_vector_size': 1024,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'embedding'},\n",
       " 'mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 4.5e-07,\n",
       "  'output_cost_per_token': 7e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'mistral.mistral-large-2402-v1:0': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'mistral.mistral-large-2407-v1:0': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 9e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'mistral.mistral-small-2402-v1:0': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 4.5e-07,\n",
       "  'output_cost_per_token': 7e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 4.5e-07,\n",
       "  'output_cost_per_token': 7e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 5.9e-07,\n",
       "  'output_cost_per_token': 9.1e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2.6e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'bedrock/eu-west-3/mistral.mistral-large-2402-v1:0': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.04e-05,\n",
       "  'output_cost_per_token': 3.12e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'anthropic.claude-3-5-sonnet-latest-v2:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'us.anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'us.anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'us.anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'us.anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'us.anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'eu.anthropic.claude-3-sonnet-20240229-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'eu.anthropic.claude-3-5-sonnet-20240620-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'eu.anthropic.claude-3-5-sonnet-20241022-v2:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'eu.anthropic.claude-3-haiku-20240307-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 1.25e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'eu.anthropic.claude-3-opus-20240229-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-05,\n",
       "  'output_cost_per_token': 7.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0455,\n",
       "  'output_cost_per_second': 0.0455,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.02527,\n",
       "  'output_cost_per_second': 0.02527,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0415,\n",
       "  'output_cost_per_second': 0.0415,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.02305,\n",
       "  'output_cost_per_second': 0.02305,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0175,\n",
       "  'output_cost_per_second': 0.0175,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00972,\n",
       "  'output_cost_per_second': 0.00972,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0175,\n",
       "  'output_cost_per_second': 0.0175,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00972,\n",
       "  'output_cost_per_second': 0.00972,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0455,\n",
       "  'output_cost_per_second': 0.0455,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.02527,\n",
       "  'output_cost_per_second': 0.02527,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0415,\n",
       "  'output_cost_per_second': 0.0415,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.02305,\n",
       "  'output_cost_per_second': 0.02305,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0175,\n",
       "  'output_cost_per_second': 0.0175,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00972,\n",
       "  'output_cost_per_second': 0.00972,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0175,\n",
       "  'output_cost_per_second': 0.0175,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v2': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00972,\n",
       "  'output_cost_per_second': 0.00972,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0455,\n",
       "  'output_cost_per_second': 0.0455,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.02527,\n",
       "  'output_cost_per_second': 0.02527,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-06,\n",
       "  'output_cost_per_token': 2.4e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0415,\n",
       "  'output_cost_per_second': 0.0415,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.02305,\n",
       "  'output_cost_per_second': 0.02305,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0175,\n",
       "  'output_cost_per_second': 0.0175,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00972,\n",
       "  'output_cost_per_second': 0.00972,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.0175,\n",
       "  'output_cost_per_second': 0.0175,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00972,\n",
       "  'output_cost_per_second': 0.00972,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.63e-06,\n",
       "  'output_cost_per_token': 5.51e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-07,\n",
       "  'output_cost_per_token': 2.4e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.011,\n",
       "  'output_cost_per_second': 0.011,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00611,\n",
       "  'output_cost_per_second': 0.00611,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.011,\n",
       "  'output_cost_per_second': 0.011,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.00611,\n",
       "  'output_cost_per_second': 0.00611,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-2/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 8e-07,\n",
       "  'output_cost_per_token': 2.4e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.23e-06,\n",
       "  'output_cost_per_token': 7.55e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.01475,\n",
       "  'output_cost_per_second': 0.01475,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.008194,\n",
       "  'output_cost_per_second': 0.008194,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.48e-06,\n",
       "  'output_cost_per_token': 8.38e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.01635,\n",
       "  'output_cost_per_second': 0.01635,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 100000,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_second': 0.009083,\n",
       "  'output_cost_per_second': 0.009083,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'cohere.command-text-v14': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/*/1-month-commitment/cohere.command-text-v14': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_second': 0.011,\n",
       "  'output_cost_per_second': 0.011,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/*/6-month-commitment/cohere.command-text-v14': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_second': 0.0066027,\n",
       "  'output_cost_per_second': 0.0066027,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'cohere.command-light-text-v14': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/*/1-month-commitment/cohere.command-light-text-v14': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_second': 0.001902,\n",
       "  'output_cost_per_second': 0.001902,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/*/6-month-commitment/cohere.command-light-text-v14': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_second': 0.0011416,\n",
       "  'output_cost_per_second': 0.0011416,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'cohere.command-r-plus-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'cohere.command-r-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'cohere.embed-english-v3': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'embedding'},\n",
       " 'cohere.embed-multilingual-v3': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'embedding'},\n",
       " 'meta.llama2-13b-chat-v1': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7.5e-07,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'meta.llama2-70b-chat-v1': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.95e-06,\n",
       "  'output_cost_per_token': 2.56e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.6e-07,\n",
       "  'output_cost_per_token': 7.2e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'output_cost_per_token': 6.9e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.2e-07,\n",
       "  'output_cost_per_token': 6.5e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.9e-07,\n",
       "  'output_cost_per_token': 7.8e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 1.01e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 2.65e-06,\n",
       "  'output_cost_per_token': 3.5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-east-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 2.65e-06,\n",
       "  'output_cost_per_token': 3.5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/us-west-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 2.65e-06,\n",
       "  'output_cost_per_token': 3.5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.18e-06,\n",
       "  'output_cost_per_token': 4.2e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.05e-06,\n",
       "  'output_cost_per_token': 4.03e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 2.86e-06,\n",
       "  'output_cost_per_token': 3.78e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 3.45e-06,\n",
       "  'output_cost_per_token': 4.55e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 4.45e-06,\n",
       "  'output_cost_per_token': 5.88e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat'},\n",
       " 'meta.llama3-1-8b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 2.2e-07,\n",
       "  'output_cost_per_token': 2.2e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'meta.llama3-1-70b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 9.9e-07,\n",
       "  'output_cost_per_token': 9.9e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'meta.llama3-1-405b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5.32e-06,\n",
       "  'output_cost_per_token': 1.6e-05,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'us.meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'eu.meta.llama3-2-1b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 1.3e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'us.meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'eu.meta.llama3-2-3b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.9e-07,\n",
       "  'output_cost_per_token': 1.9e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'meta.llama3-2-11b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'output_cost_per_token': 3.5e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'us.meta.llama3-2-11b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'output_cost_per_token': 3.5e-07,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'meta.llama3-2-90b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " 'us.meta.llama3-2-90b-instruct-v1:0': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 2e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_tool_choice': False},\n",
       " '512-x-512/50-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.018,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'},\n",
       " '512-x-512/max-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.036,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'},\n",
       " 'max-x-max/50-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.036,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'},\n",
       " 'max-x-max/max-steps/stability.stable-diffusion-xl-v0': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.072,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'},\n",
       " '1024-x-1024/50-steps/stability.stable-diffusion-xl-v1': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.04,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'},\n",
       " '1024-x-1024/max-steps/stability.stable-diffusion-xl-v1': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.08,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'},\n",
       " 'sagemaker/meta-textgeneration-llama-2-7b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'sagemaker',\n",
       "  'mode': 'completion'},\n",
       " 'sagemaker/meta-textgeneration-llama-2-7b-f': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'sagemaker',\n",
       "  'mode': 'chat'},\n",
       " 'sagemaker/meta-textgeneration-llama-2-13b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'sagemaker',\n",
       "  'mode': 'completion'},\n",
       " 'sagemaker/meta-textgeneration-llama-2-13b-f': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'sagemaker',\n",
       "  'mode': 'chat'},\n",
       " 'sagemaker/meta-textgeneration-llama-2-70b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'sagemaker',\n",
       "  'mode': 'completion'},\n",
       " 'sagemaker/meta-textgeneration-llama-2-70b-b-f': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'sagemaker',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-up-to-4b': {'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-4.1b-8b': {'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-8.1b-21b': {'max_tokens': 1000,\n",
       "  'input_cost_per_token': 3e-07,\n",
       "  'output_cost_per_token': 3e-07,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-21.1b-41b': {'input_cost_per_token': 8e-07,\n",
       "  'output_cost_per_token': 8e-07,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-41.1b-80b': {'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-81.1b-110b': {'input_cost_per_token': 1.8e-06,\n",
       "  'output_cost_per_token': 1.8e-06,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'chat'},\n",
       " 'together-ai-embedding-up-to-150m': {'input_cost_per_token': 8e-09,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'embedding'},\n",
       " 'together-ai-embedding-151m-to-350m': {'input_cost_per_token': 1.6e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'mode': 'embedding'},\n",
       " 'together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1': {'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'together_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'mode': 'chat'},\n",
       " 'together_ai/mistralai/Mistral-7B-Instruct-v0.1': {'litellm_provider': 'together_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'mode': 'chat'},\n",
       " 'together_ai/togethercomputer/CodeLlama-34b-Instruct': {'litellm_provider': 'together_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'mode': 'chat'},\n",
       " 'ollama/codegemma': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion'},\n",
       " 'ollama/codegeex4': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': False},\n",
       " 'ollama/deepseek-coder-v2-instruct': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'ollama/deepseek-coder-v2-base': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion',\n",
       "  'supports_function_calling': True},\n",
       " 'ollama/deepseek-coder-v2-lite-instruct': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'ollama/deepseek-coder-v2-lite-base': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion',\n",
       "  'supports_function_calling': True},\n",
       " 'ollama/internlm2_5-20b-chat': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'ollama/llama2': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama2:7b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama2:13b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama2:70b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama2-uncensored': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion'},\n",
       " 'ollama/llama3': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama3:8b': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama3:70b': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/llama3.1': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'ollama/mistral-large-instruct-2407': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 65536,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/mistral': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion'},\n",
       " 'ollama/mistral-7B-Instruct-v0.1': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/mistral-7B-Instruct-v0.2': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/mixtral-8x7B-Instruct-v0.1': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/mixtral-8x22B-Instruct-v0.1': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 65536,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'chat'},\n",
       " 'ollama/codellama': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion'},\n",
       " 'ollama/orca-mini': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion'},\n",
       " 'ollama/vicuna': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 2048,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'ollama',\n",
       "  'mode': 'completion'},\n",
       " 'deepinfra/lizpreciatior/lzlv_70b_fp16_hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/Gryphe/MythoMax-L2-13b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.2e-07,\n",
       "  'output_cost_per_token': 2.2e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/mistralai/Mistral-7B-Instruct-v0.1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 1.3e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/meta-llama/Llama-2-70b-chat-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.7e-07,\n",
       "  'output_cost_per_token': 2.7e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/codellama/CodeLlama-34b-Instruct-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/deepinfra/mixtral': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 32000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.7e-07,\n",
       "  'output_cost_per_token': 2.7e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'completion'},\n",
       " 'deepinfra/Phind/Phind-CodeLlama-34B-v2': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2.7e-07,\n",
       "  'output_cost_per_token': 2.7e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/deepinfra/airoboros-70b': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/01-ai/Yi-34B-Chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/01-ai/Yi-6B-200K': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 1.3e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'completion'},\n",
       " 'deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/meta-llama/Llama-2-13b-chat-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.2e-07,\n",
       "  'output_cost_per_token': 2.2e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/amazon/MistralLite': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 8191,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/meta-llama/Llama-2-7b-chat-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 1.3e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/meta-llama/Meta-Llama-3-8B-Instruct': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 8e-08,\n",
       "  'output_cost_per_token': 8e-08,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/meta-llama/Meta-Llama-3-70B-Instruct': {'max_tokens': 8191,\n",
       "  'max_input_tokens': 8191,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5.9e-07,\n",
       "  'output_cost_per_token': 7.9e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'deepinfra/01-ai/Yi-34B-200K': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'completion'},\n",
       " 'deepinfra/openchat/openchat_3.5': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 1.3e-07,\n",
       "  'litellm_provider': 'deepinfra',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/codellama-34b-instruct': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 3.5e-07,\n",
       "  'output_cost_per_token': 1.4e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/codellama-70b-instruct': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 2.8e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-70b-instruct': {'max_tokens': 131072,\n",
       "  'max_input_tokens': 131072,\n",
       "  'max_output_tokens': 131072,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-8b-instruct': {'max_tokens': 131072,\n",
       "  'max_input_tokens': 131072,\n",
       "  'max_output_tokens': 131072,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-sonar-huge-128k-online': {'max_tokens': 127072,\n",
       "  'max_input_tokens': 127072,\n",
       "  'max_output_tokens': 127072,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-sonar-large-128k-online': {'max_tokens': 127072,\n",
       "  'max_input_tokens': 127072,\n",
       "  'max_output_tokens': 127072,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-sonar-large-128k-chat': {'max_tokens': 131072,\n",
       "  'max_input_tokens': 131072,\n",
       "  'max_output_tokens': 131072,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-sonar-small-128k-chat': {'max_tokens': 131072,\n",
       "  'max_input_tokens': 131072,\n",
       "  'max_output_tokens': 131072,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-3.1-sonar-small-128k-online': {'max_tokens': 127072,\n",
       "  'max_input_tokens': 127072,\n",
       "  'max_output_tokens': 127072,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/pplx-7b-chat': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 7e-08,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/pplx-70b-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 2.8e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/pplx-7b-online': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'input_cost_per_request': 0.005,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/pplx-70b-online': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 2.8e-06,\n",
       "  'input_cost_per_request': 0.005,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/llama-2-70b-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-07,\n",
       "  'output_cost_per_token': 2.8e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/mistral-7b-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-08,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/mixtral-8x7b-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 7e-08,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/sonar-small-chat': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 7e-08,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/sonar-small-online': {'max_tokens': 12000,\n",
       "  'max_input_tokens': 12000,\n",
       "  'max_output_tokens': 12000,\n",
       "  'input_cost_per_token': 0,\n",
       "  'output_cost_per_token': 2.8e-07,\n",
       "  'input_cost_per_request': 0.005,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/sonar-medium-chat': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 6e-07,\n",
       "  'output_cost_per_token': 1.8e-06,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'perplexity/sonar-medium-online': {'max_tokens': 12000,\n",
       "  'max_input_tokens': 12000,\n",
       "  'max_output_tokens': 12000,\n",
       "  'input_cost_per_token': 0,\n",
       "  'output_cost_per_token': 1.8e-06,\n",
       "  'input_cost_per_request': 0.005,\n",
       "  'litellm_provider': 'perplexity',\n",
       "  'mode': 'chat'},\n",
       " 'fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 1e-07,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'accounts/fireworks/models/llama-v3p2-90b-vision-instruct': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/firefunction-v2': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 65536,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 1.2e-06,\n",
       "  'output_cost_per_token': 1.2e-06,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/yi-large': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 3e-06,\n",
       "  'output_cost_per_token': 3e-06,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 65536,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.2e-06,\n",
       "  'output_cost_per_token': 1.2e-06,\n",
       "  'litellm_provider': 'fireworks_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/nomic-ai/nomic-embed-text-v1.5': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'input_cost_per_token': 8e-09,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/nomic-ai/nomic-embed-text-v1': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'input_cost_per_token': 8e-09,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/WhereIsAI/UAE-Large-V1': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'input_cost_per_token': 1.6e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/thenlper/gte-large': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'input_cost_per_token': 1.6e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks_ai/thenlper/gte-base': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'input_cost_per_token': 8e-09,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://fireworks.ai/pricing'},\n",
       " 'fireworks-ai-up-to-16b': {'input_cost_per_token': 2e-07,\n",
       "  'output_cost_per_token': 2e-07,\n",
       "  'litellm_provider': 'fireworks_ai'},\n",
       " 'fireworks-ai-16.1b-to-80b': {'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'fireworks_ai'},\n",
       " 'fireworks-ai-moe-up-to-56b': {'input_cost_per_token': 5e-07,\n",
       "  'output_cost_per_token': 5e-07,\n",
       "  'litellm_provider': 'fireworks_ai'},\n",
       " 'fireworks-ai-56b-to-176b': {'input_cost_per_token': 1.2e-06,\n",
       "  'output_cost_per_token': 1.2e-06,\n",
       "  'litellm_provider': 'fireworks_ai'},\n",
       " 'fireworks-ai-default': {'input_cost_per_token': 0.0,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai'},\n",
       " 'fireworks-ai-embedding-up-to-150m': {'input_cost_per_token': 8e-09,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models'},\n",
       " 'fireworks-ai-embedding-150m-to-350m': {'input_cost_per_token': 1.6e-08,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'fireworks_ai-embedding-models'},\n",
       " 'anyscale/mistralai/Mistral-7B-Instruct-v0.1': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1'},\n",
       " 'anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1'},\n",
       " 'anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1': {'max_tokens': 65536,\n",
       "  'max_input_tokens': 65536,\n",
       "  'max_output_tokens': 65536,\n",
       "  'input_cost_per_token': 9e-07,\n",
       "  'output_cost_per_token': 9e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1'},\n",
       " 'anyscale/HuggingFaceH4/zephyr-7b-beta': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 16384,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat'},\n",
       " 'anyscale/google/gemma-7b-it': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it'},\n",
       " 'anyscale/meta-llama/Llama-2-7b-chat-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat'},\n",
       " 'anyscale/meta-llama/Llama-2-13b-chat-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2.5e-07,\n",
       "  'output_cost_per_token': 2.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat'},\n",
       " 'anyscale/meta-llama/Llama-2-70b-chat-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat'},\n",
       " 'anyscale/codellama/CodeLlama-34b-Instruct-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat'},\n",
       " 'anyscale/codellama/CodeLlama-70b-Instruct-hf': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf'},\n",
       " 'anyscale/meta-llama/Meta-Llama-3-8B-Instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 1.5e-07,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct'},\n",
       " 'anyscale/meta-llama/Meta-Llama-3-70B-Instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 1e-06,\n",
       "  'litellm_provider': 'anyscale',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct'},\n",
       " 'cloudflare/@cf/meta/llama-2-7b-chat-fp16': {'max_tokens': 3072,\n",
       "  'max_input_tokens': 3072,\n",
       "  'max_output_tokens': 3072,\n",
       "  'input_cost_per_token': 1.923e-06,\n",
       "  'output_cost_per_token': 1.923e-06,\n",
       "  'litellm_provider': 'cloudflare',\n",
       "  'mode': 'chat'},\n",
       " 'cloudflare/@cf/meta/llama-2-7b-chat-int8': {'max_tokens': 2048,\n",
       "  'max_input_tokens': 2048,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 1.923e-06,\n",
       "  'output_cost_per_token': 1.923e-06,\n",
       "  'litellm_provider': 'cloudflare',\n",
       "  'mode': 'chat'},\n",
       " 'cloudflare/@cf/mistral/mistral-7b-instruct-v0.1': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1.923e-06,\n",
       "  'output_cost_per_token': 1.923e-06,\n",
       "  'litellm_provider': 'cloudflare',\n",
       "  'mode': 'chat'},\n",
       " 'cloudflare/@hf/thebloke/codellama-7b-instruct-awq': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.923e-06,\n",
       "  'output_cost_per_token': 1.923e-06,\n",
       "  'litellm_provider': 'cloudflare',\n",
       "  'mode': 'chat'},\n",
       " 'voyage/voyage-01': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-lite-01': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-large-2': {'max_tokens': 16000,\n",
       "  'max_input_tokens': 16000,\n",
       "  'input_cost_per_token': 1.2e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-law-2': {'max_tokens': 16000,\n",
       "  'max_input_tokens': 16000,\n",
       "  'input_cost_per_token': 1.2e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-code-2': {'max_tokens': 16000,\n",
       "  'max_input_tokens': 16000,\n",
       "  'input_cost_per_token': 1.2e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-2': {'max_tokens': 4000,\n",
       "  'max_input_tokens': 4000,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-lite-02-instruct': {'max_tokens': 4000,\n",
       "  'max_input_tokens': 4000,\n",
       "  'input_cost_per_token': 1e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'voyage/voyage-finance-2': {'max_tokens': 4000,\n",
       "  'max_input_tokens': 4000,\n",
       "  'input_cost_per_token': 1.2e-07,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'voyage',\n",
       "  'mode': 'embedding'},\n",
       " 'databricks/databricks-meta-llama-3-1-405b-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'input_dbu_cost_per_token': 7.1429e-05,\n",
       "  'output_cost_per_token': 1.500002e-05,\n",
       "  'output_db_cost_per_token': 0.000214286,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-meta-llama-3-1-70b-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 1.00002e-06,\n",
       "  'input_dbu_cost_per_token': 1.4286e-05,\n",
       "  'output_cost_per_token': 2.99999e-06,\n",
       "  'output_dbu_cost_per_token': 4.2857e-05,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-dbrx-instruct': {'max_tokens': 32768,\n",
       "  'max_input_tokens': 32768,\n",
       "  'max_output_tokens': 32768,\n",
       "  'input_cost_per_token': 7.4998e-07,\n",
       "  'input_dbu_cost_per_token': 1.0714e-05,\n",
       "  'output_cost_per_token': 2.24901e-06,\n",
       "  'output_dbu_cost_per_token': 3.2143e-05,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-meta-llama-3-70b-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 128000,\n",
       "  'input_cost_per_token': 1.00002e-06,\n",
       "  'input_dbu_cost_per_token': 1.4286e-05,\n",
       "  'output_cost_per_token': 2.99999e-06,\n",
       "  'output_dbu_cost_per_token': 4.2857e-05,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-llama-2-70b-chat': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5.0001e-07,\n",
       "  'input_dbu_cost_per_token': 7.143e-06,\n",
       "  'output_cost_per_token': 1.5e-06,\n",
       "  'output_dbu_cost_per_token': 2.1429e-05,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-mixtral-8x7b-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 5.0001e-07,\n",
       "  'input_dbu_cost_per_token': 7.143e-06,\n",
       "  'output_cost_per_token': 9.9902e-07,\n",
       "  'output_dbu_cost_per_token': 1.4286e-05,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-mpt-30b-instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 9.9902e-07,\n",
       "  'input_dbu_cost_per_token': 1.4286e-05,\n",
       "  'output_cost_per_token': 9.9902e-07,\n",
       "  'output_dbu_cost_per_token': 1.4286e-05,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-mpt-7b-instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 5.0001e-07,\n",
       "  'input_dbu_cost_per_token': 7.143e-06,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'output_dbu_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-bge-large-en': {'max_tokens': 512,\n",
       "  'max_input_tokens': 512,\n",
       "  'output_vector_size': 1024,\n",
       "  'input_cost_per_token': 1.0003e-07,\n",
       "  'input_dbu_cost_per_token': 1.429e-06,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'output_dbu_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'databricks/databricks-gte-large-en': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'output_vector_size': 1024,\n",
       "  'input_cost_per_token': 1.2999e-07,\n",
       "  'input_dbu_cost_per_token': 1.857e-06,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'output_dbu_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'databricks',\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://www.databricks.com/product/pricing/foundation-model-serving',\n",
       "  'metadata': {'notes': \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}},\n",
       " 'azure/gpt-4o-mini-2024-07-18': {'max_tokens': 16384,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 16384,\n",
       "  'input_cost_per_token': 1.65e-07,\n",
       "  'output_cost_per_token': 6.6e-07,\n",
       "  'cache_read_input_token_cost': 7.5e-08,\n",
       "  'litellm_provider': 'azure',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_parallel_function_calling': True,\n",
       "  'supports_response_schema': True,\n",
       "  'supports_vision': True,\n",
       "  'supports_prompt_caching': True},\n",
       " 'amazon.titan-embed-image-v1': {'max_tokens': 128,\n",
       "  'max_input_tokens': 128,\n",
       "  'output_vector_size': 1024,\n",
       "  'input_cost_per_token': 8e-07,\n",
       "  'input_cost_per_image': 6e-05,\n",
       "  'output_cost_per_token': 0.0,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'supports_image_input': True,\n",
       "  'mode': 'embedding',\n",
       "  'source': 'https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1'},\n",
       " 'azure_ai/mistral-large-2407': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 2e-06,\n",
       "  'output_cost_per_token': 6e-06,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview'},\n",
       " 'azure_ai/ministral-3b': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 4e-08,\n",
       "  'output_cost_per_token': 4e-08,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview'},\n",
       " 'azure_ai/Llama-3.2-11B-Vision-Instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 3.7e-07,\n",
       "  'output_cost_per_token': 3.7e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview'},\n",
       " 'azure_ai/Llama-3.2-90B-Vision-Instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 2048,\n",
       "  'input_cost_per_token': 2.04e-06,\n",
       "  'output_cost_per_token': 2.04e-06,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True,\n",
       "  'mode': 'chat',\n",
       "  'source': 'https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview'},\n",
       " 'azure_ai/Phi-3.5-mini-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 5.2e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3.5-vision-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 5.2e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': True,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3.5-MoE-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.6e-07,\n",
       "  'output_cost_per_token': 6.4e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3-mini-4k-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 5.2e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3-mini-128k-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.3e-07,\n",
       "  'output_cost_per_token': 5.2e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3-small-8k-instruct': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 8192,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3-small-128k-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.5e-07,\n",
       "  'output_cost_per_token': 6e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3-medium-4k-instruct': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 4096,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.7e-07,\n",
       "  'output_cost_per_token': 6.8e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'azure_ai/Phi-3-medium-128k-instruct': {'max_tokens': 128000,\n",
       "  'max_input_tokens': 128000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1.7e-07,\n",
       "  'output_cost_per_token': 6.8e-07,\n",
       "  'litellm_provider': 'azure_ai',\n",
       "  'mode': 'chat',\n",
       "  'supports_vision': False,\n",
       "  'source': 'https://azure.microsoft.com/en-us/pricing/details/phi-3/'},\n",
       " 'xai/grok-beta': {'max_tokens': 131072,\n",
       "  'max_input_tokens': 131072,\n",
       "  'max_output_tokens': 131072,\n",
       "  'input_cost_per_token': 5e-06,\n",
       "  'output_cost_per_token': 1.5e-05,\n",
       "  'litellm_provider': 'xai',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_vision': True},\n",
       " 'claude-3-5-haiku-20241022': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'cache_creation_input_token_cost': 1.25e-06,\n",
       "  'cache_read_input_token_cost': 1e-07,\n",
       "  'litellm_provider': 'anthropic',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'tool_use_system_prompt_tokens': 264,\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_prompt_caching': True,\n",
       "  'supports_pdf_input': True},\n",
       " 'vertex_ai/claude-3-5-haiku@20241022': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'vertex_ai-anthropic_models',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'supports_assistant_prefill': True},\n",
       " 'openrouter/anthropic/claude-3-5-haiku': {'max_tokens': 200000,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'openrouter/anthropic/claude-3-5-haiku-20241022': {'max_tokens': 8192,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 8192,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'openrouter',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True,\n",
       "  'tool_use_system_prompt_tokens': 264},\n",
       " 'anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_function_calling': True},\n",
       " 'us.anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_assistant_prefill': True,\n",
       "  'supports_function_calling': True},\n",
       " 'eu.anthropic.claude-3-5-haiku-20241022-v1:0': {'max_tokens': 4096,\n",
       "  'max_input_tokens': 200000,\n",
       "  'max_output_tokens': 4096,\n",
       "  'input_cost_per_token': 1e-06,\n",
       "  'output_cost_per_token': 5e-06,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'chat',\n",
       "  'supports_function_calling': True},\n",
       " 'stability.sd3-large-v1:0': {'max_tokens': 77,\n",
       "  'max_input_tokens': 77,\n",
       "  'output_cost_per_image': 0.08,\n",
       "  'litellm_provider': 'bedrock',\n",
       "  'mode': 'image_generation'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "def gpt_chat_completion(client, message, model=\"gpt-4o\"):\n",
    "    return client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message,\n",
    "        }\n",
    "    ],\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "rep = gpt_chat_completion(client, \"Hello! How are you?\")\n",
    "print(rep.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Test Set \n",
    "\n",
    "### Prompts \n",
    "\n",
    "- [ ] One entity quality vs. another entity quality \n",
    "- [ ] One column quality vs. another column quality \n",
    "- [ ] One schema quality vs. another schema quality \n",
    "\n",
    "### Demonstrations \n",
    "\n",
    "- [ ] A high quality entity (description)\n",
    "- [ ] A high quality column (description)\n",
    "- [ ] A high quality schema (description)\n",
    "\n",
    "### Quality Categories\n",
    "\n",
    "- [ ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tests/assets/entity_comparison_assets.json\", \"r\") as f:\n",
    "    entity_comparison_assets = json.load(f)\n",
    "\n",
    "gold_entity_comparison = \"\".join(entity_comparison_assets[\"gold\"][\"prompt\"])\n",
    "four_entity_comparison = \"\".join(entity_comparison_assets[\"four\"][\"prompt\"])\n",
    "three_entity_comparison = \"\".join(entity_comparison_assets[\"three\"][\"prompt\"])\n",
    "two_entity_comparison = \"\".join(entity_comparison_assets[\"two\"][\"prompt\"])\n",
    "one_entity_comparison = \"\".join(entity_comparison_assets[\"one\"][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting output: 3 \n",
      "\n",
      "{'reasoning': \"To evaluate the documentation provided, I will compare it against the GOLD documentation and the criteria provided. The task requires determining whether the evaluated documentation matches or exceeds the quality of the GOLD documentation, based on criteria of correctness, clarity, and descriptiveness.\\n\\nFirst, we need to examine the documentation submitted for evaluation:\\n\\n- The 'id' field contains a clear and concise description, matching the GOLD example.\\n- Similarly, the 'marketplace' field is well-described, stating which marketplace the snapshot belongs to, consistent with the GOLD documentation.\\n- The 'blockNumber' and 'timestamp' fields are described accurately, specifying where and when the snapshot is taken, aligning with the GOLD standard.\\n- The 'collectionCount', 'cumulativeTradeVolumeETH', 'marketplaceRevenueETH', 'creatorRevenueETH', 'totalRevenueETH', 'tradeCount', 'cumulativeUniqueTraders', 'dailyActiveTraders', 'dailyTradedCollectionCount', and 'dailyTradedItemCount' fields all provide descriptions matching the GOLD documentation. Each description specifies exactly what the field represents in the context of the marketplace daily snapshot, and uses precise language consistent with the GOLD example.\\n\\nSince every field in the evaluation submission directly matches the GOLD documentation in terms of phrasing, detail, and clarity, all descriptions are considered 'Almost Perfect' as per the second level of the correctness criterion. The documentation provided does not exceed the GOLD standard because it uses the same language and does not provide additional detail beyond what is considered 'Almost Perfect'.\\n\\nTherefore, the evaluation documentation is rated as 3 as it matches but does not exceed the GOLD documentation in any way.\", 'correctness': 3}\n",
      "\n",
      " Expecting output: 4 \n",
      "\n",
      "{'reasoning': \"To evaluate the quality of the provided EVALUATION DOCUMENTATION, we will compare it against the GOLD DOCUMENTATION and the provided criteria for correctness.\\n\\n1. **id**: The EVALUATION DOCUMENTATION provides a detailed description of the ID structure, which includes the contract address and the number of days since Unix epoch time. This is more informative than the GOLD DOCUMENTATION's description, which only includes the ID structure in curly braces without any explanation.\\n\\n2. **marketplace**: The EVALUATION DOCUMENTATION states that it is 'a reference to the marketplace entity that this snapshot belongs to,' which is slightly more detailed than the GOLD DOCUMENTATION, which simply states 'The marketplace that this snapshot belongs to.' The evaluation description reduces ambiguity by specifying that it is a reference.\\n\\n3. **blockNumber**: The EVALUATION DOCUMENTATION describes the block number in detail by tying it to the transaction related to the snapshot and the corresponding network. This is marginally more informative than the GOLD DOCUMENTATION, which merely states 'Block number where the snapshot is taken.'\\n\\n4. **timestamp**: The description of the timestamp in the EVALUATION DOCUMENTATION is slightly more informative as it mentions it is 'associated with the block' and ties it to the snapshot transaction, as opposed to the GOLD DOCUMENTATION, which just mentions the block timestamp.\\n\\n5. **collectionCount**: Both the EVALUATION and GOLD DOCUMENTATION describe the number of collections listed with slight variation; however, the EVALUATION description specifies 'on the OpenSea marketplace,' which could be seen as more informative if relevant.\\n\\n6. **cumulativeTradeVolumeETH**: The EVALUATION DOCUMENTATION provides a more detailed explanation by specifying the volume is 'formatted as a decimal,' which is not included in the GOLD DOCUMENTATION.\\n\\n7. **marketplaceRevenueETH**: Both descriptions are similar, but the EVALUATION DOCUMENTATION adds 'that goes to the marketplace protocol,' which provides a clearer picture of the revenue source.\\n\\n8. **creatorRevenueETH**: The EVALUATION DOCUMENTATION specifies the revenue is in 'Ether (formatted as a decimal),' offering slightly more clarity than the GOLD version.\\n\\n9. **totalRevenueETH**: The description provided in the EVALUATION DOCUMENTATION goes into more detail by listing the components of the total revenue explicitly, which is clearer compared to the succinct explanation in the GOLD DOCUMENTATION.\\n\\n10. **tradeCount**: Both documentations provide similar descriptions; however, the EVALUATION DOCUMENTATION mentions the 'marketplace protocol,' which may provide additional context.\\n\\n11. **cumulativeUniqueTraders**: The EVALUATION DOCUMENTATION further specifies that this count is based on 'unique addresses that have traded on the protocol,' which adds clarity not present in the GOLD DOCUMENTATION.\\n\\n12. **dailyActiveTraders**: EVALUATION DOCUMENTATION includes 'based upon a count of user addresses,' which enhances the understanding of the metric.\\n\\n13. **dailyTradedCollectionCount** and **dailyTradedItemCount**: The EVALUATION DOCUMENTATION adds context by specifying 'on a given day at the time of the snapshot,' which the GOLD DOCUMENTATION lacks.\\n\\nOverall, the EVALUATION DOCUMENTATION consistently provides more context and details than the GOLD DOCUMENTATION. It either matches or exceeds the level of clarity and correctness of the GOLD DOCUMENTATION, often providing additional explanatory information. \\n\\nConsidering these observations, the EVALUATION DOCUMENTATION meets the criteria for a perfect column description and should be rated as '4: Perfect'.\", 'correctness': 4}\n",
      "\n",
      " Expecting output: 3 \n",
      "\n",
      "{'reasoning': \"To evaluate the quality of the documentation, we must assess whether the provided documentation (EVALUATION DOCUMENTATION) matches, falls below, or exceeds the GOLD DOCUMENTATION based on the specified criteria. \\n\\n1. **Correctness**: We start by comparing each individual field description in both the EVALUATION DOCUMENTATION and the GOLD DOCUMENTATION.\\n   - The descriptions for all fields in the EVALUATION DOCUMENTATION are identical to those in the GOLD DOCUMENTATION: both provide clear, unambiguous descriptions for each column.\\n   - Each field description properly specifies what the field represents, often including context (e.g., 'The marketplace that this snapshot belongs to.').\\n   - The descriptions use complete sentences with proper grammar, capitalization, and punctuation.\\n\\n2. **Comparison**: Since the EVALUATION DOCUMENTATION perfectly matches the GOLD DOCUMENTATION without missing any information or providing misleading data, it falls into the 'Almost Perfect' category, as it matches the GOLD documentation but does not exceed it.\\n\\nBased on this reasoning, the correctness rating should be 3, as the EVALUATION DOCUMENTATION matches the GOLD DOCUMENTATION.\", 'correctness': 3}\n",
      "\n",
      " Expecting output: 2 \n",
      "\n",
      "{'reasoning': \"The task is to evaluate the quality of the provided evaluation documentation against the gold documentation based on the criteria of correctness. Each column description from the evaluation documentation should be compared with its counterpart in the gold documentation to determine if they meet the description and format as outlined by the evaluation criterion. Let's analyze them step-by-step: \\n\\n1. 'id': The evaluation describes it as '{ Contract address }-{# days since epoch time}'. The gold documentation refines this to '{ Contract address }-{# of days since Unix epoch time}'. The difference here is the lack of clarity on 'Unix epoch', reducing specificity and correctness in the evaluation documentation.\\n\\n2. 'marketplace': Evaluation states 'The marketplace', whereas the gold version adds 'that this snapshot belongs to', clarifying the association. \\n\\n3. 'blockNumber': Evaluation states 'Block number of snapshot', whereas gold is more specific with 'where the snapshot is taken'. This adds more context on what 'block number' refers to.\\n\\n4. 'timestamp': Evaluation states 'Block timestamp of snapshot', gold adds clarity with 'when the snapshot is taken'.\\n\\n5. 'collectionCount': Evaluation states 'collections count on marketplace', gold specifies 'Number of collections listed on the marketplace', being clearer and more specific.\\n\\n6. 'cumulativeTradeVolumeETH': In both descriptions, the completeness and clarity are quite similar.\\n\\n7. 'marketplaceRevenueETH': Evaluation describes it as 'protocol fee', but gold clarifies context with 'Revenue that goes to the marketplace protocol, aka protocol fee'.\\n\\n8. 'creatorRevenueETH': Similar to prior, evaluation calls it 'royalty fee', but gold adds context by saying 'Revenue that goes to creator, aka royalty fee'.\\n\\n9. 'totalRevenueETH': Evaluation states 'marketplaceRevenueETH and creatorRevenueETH', not exhaustive enough as gold states 'Sum of marketplaceRevenueETH and creatorRevenueETH'.\\n\\n10. 'tradeCount': Evaluation states 'trade count of collections', whereas gold specifies 'Trade count of the all collections on the marketplace'.\\n\\n11-14: Cumulative descriptions for 'cumulativeUniqueTraders', 'dailyActiveTraders', 'dailyTradedCollectionCount', 'dailyTradedItemCount' are concise in both versions.\\n\\nIn summary, the evaluation documentation often misses the additional context provided in the gold documentation, leading to potentially ambiguous interpretations. Therefore, the evaluation documentation does not match the gold documentation and can be rated as 'Somewhat Correct'. \\n\", 'correctness': 2}\n",
      "\n",
      " Expecting output: 1 \n",
      "\n",
      "{'reasoning': \"To evaluate the quality of documentation, I will compare each column description in the evaluation documentation to the gold documentation. \\n\\n1. The 'id' description is missing in the evaluation documentation, whereas the gold documentation provides a detailed description about the structure combining 'Contract address' and '# of days since Unix epoch time'.\\n\\n2. The 'marketplace' description is present but vaguely described in the evaluation documentation as just the marketplace name. The gold documentation explicitly states, 'The marketplace that this snapshot belongs to'.\\n\\n3. For 'blockNumber', the gold documentation gives a precise definition, stating it is the 'Block number where the snapshot is taken'. The evaluation documentation provides no description.\\n\\n4. Similarly, 'timestamp' lacks any description in the evaluation documentation, but the gold documentation clearly states it as the 'Block timestamp when the snapshot is taken'.\\n\\n5. 'collectionCount' is marked as 'collections on marketplace' in evaluation documentation, whereas the gold provides 'Number of collections listed on the marketplace', which is more detailed and clear.\\n\\n6. 'cumulativeTradeVolumeETH' in the evaluation documentation is only labeled 'trade volume', missing the clarity 'Cumulative trade volume (in ETH)' in the gold standard.\\n\\n7. The 'marketplaceRevenueETH' is labeled 'creator fee' in the evaluation documentation, but in the gold documentation, it's clearly described as 'Revenue that goes to the marketplace protocol, aka protocol fee', indicating a disconnect in understanding.\\n\\n8. The 'creatorRevenueETH' is labeled 'marketplace fee' in the evaluation documentation, showing confusion. The gold description labels it correctly as 'Revenue that goes to creator, aka royalty fee'.\\n\\n9. 'totalRevenueETH' description is absent in the evaluation documentation, whereas the gold describes it as the 'Sum of marketplaceRevenueETH and creatorRevenueETH'.\\n\\n10. For 'tradeCount', the evaluation description is 'trade count of traders', which lacks clarity. The gold describes it as 'Trade count of the all collections on the marketplace'.\\n\\n11. 'cumulativeUniqueTraders', 'dailyActiveTraders', 'dailyTradedCollectionCount', and 'dailyTradedItemCount' have descriptions in the evaluation documentation but lack the precision and details provided in the gold documentation.\\n\\nOverall, the evaluation documentation lacks consistency, detail, and precision, resulting in misunderstandings and ambiguity. Many descriptions in the evaluation documentation either miss crucial information, contain misleading information (items 7 and 8), or lack information entirely.\", 'correctness': 1}\n"
     ]
    }
   ],
   "source": [
    "# Function to reload the template\n",
    "def reload_template(template_path=\"../assets/prompts\", template_name=\"entity_comparison_prompt.txt\"):\n",
    "    env = Environment(loader=FileSystemLoader(template_path))\n",
    "    env.cache.clear()\n",
    "    entity_comparison_prompt_template = env.get_template(template_name)\n",
    "    return entity_comparison_prompt_template\n",
    "\n",
    "def parse_response(response): \n",
    "    response = response.choices[0].message.content\n",
    "    response = response.strip('```json').strip('```').strip()\n",
    "    response = json.loads(response)\n",
    "    return response\n",
    "\n",
    "example_prompt = reload_template()\n",
    "example_prompt_filled = example_prompt.render({\"entity_pred\": \"<example prediction goes here>\", \"entity_gold\": \"<example gold goes here>\"})\n",
    "\n",
    "entity_comparison_prompt_template = reload_template()\n",
    "gold_output = entity_comparison_prompt_template.render({\"entity_pred\": {gold_entity_comparison}, \"entity_gold\": {gold_entity_comparison}})\n",
    "four_output = entity_comparison_prompt_template.render({\"entity_pred\": {four_entity_comparison}, \"entity_gold\": {gold_entity_comparison}})\n",
    "three_output = entity_comparison_prompt_template.render({\"entity_pred\": {three_entity_comparison}, \"entity_gold\": {gold_entity_comparison}})\n",
    "two_output = entity_comparison_prompt_template.render({\"entity_pred\": {two_entity_comparison}, \"entity_gold\": {gold_entity_comparison}})\n",
    "one_output = entity_comparison_prompt_template.render({\"entity_pred\": {one_entity_comparison}, \"entity_gold\": {gold_entity_comparison}})\n",
    "\n",
    "print(\"Expecting output: 3 \\n\")\n",
    "gold_comparison = parse_response(gpt_chat_completion(client, gold_output))\n",
    "print(gold_comparison)\n",
    "\n",
    "print(\"\\n Expecting output: 4 \\n\")\n",
    "four_comparison = parse_response(gpt_chat_completion(client, four_output))\n",
    "print(four_comparison)\n",
    "\n",
    "print(\"\\n Expecting output: 3 \\n\")\n",
    "three_comparison = parse_response(gpt_chat_completion(client, three_output))\n",
    "print(three_comparison)\n",
    "\n",
    "print(\"\\n Expecting output: 2 \\n\")\n",
    "two_comparison = parse_response(gpt_chat_completion(client, two_output))\n",
    "print(two_comparison)\n",
    "\n",
    "print(\"\\n Expecting output: 1 \\n\")\n",
    "one_comparison = parse_response(gpt_chat_completion(client, one_output))\n",
    "print(one_comparison)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_comparison_prompt_template = reload_template(\n",
    "    template_path=\"../assets/prompts\",\n",
    "    template_name=\"entity_comparison_revision.txt\",\n",
    ")\n",
    "\n",
    "entity_comparison_prompt_modification = entity_comparison_prompt_template.render(\n",
    "    {\n",
    "        \"original_prompt\": {example_prompt_filled}, \n",
    "\n",
    "        \"four_result_correct\": {\"True\" if four_comparison[\"correctness\"] == 4 else \"False\"},\n",
    "        \"four_result\": {four_comparison[\"reasoning\"]},\n",
    "        \n",
    "        \"three_result_correct\": {\"True\" if three_comparison[\"correctness\"] == 3 else \"False\"},\n",
    "        \"three_result\": {three_comparison[\"reasoning\"]},\n",
    "        \n",
    "        \"two_result_correct\": {\"True\" if two_comparison[\"correctness\"] == 2 else \"False\"},\n",
    "        \"two_result\": {two_comparison[\"reasoning\"]},\n",
    "        \n",
    "        \"one_result_correct\": {\"True\" if one_comparison[\"correctness\"] == 1 else \"False\"},\n",
    "        \"one_result\": {one_comparison[\"reasoning\"]},\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt_revision = gpt_chat_completion(client, entity_comparison_prompt_modification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../assets/prompts/entity_comparison_prompt_revised.txt\"\n",
    "\n",
    "prompt_revision = parse_response(prompt_revision)\n",
    "revised_prompt = prompt_revision[\"modified_prompt\"]\n",
    "\n",
    "# Replace the placeholder with Jinja syntax\n",
    "revised_prompt = revised_prompt.replace(r\"{entity_pred}\", r\"{{ entity_pred }}\")\n",
    "revised_prompt = revised_prompt.replace(r\"{entity_gold}\", r\"{{ entity_gold }}\")\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(revised_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gold\": {\n",
      "        \"version\": \"1.0.0\",\n",
      "        \"prompt\": [\n",
      "            \"type Collection @entity @regularPolling { \\n\",\n",
      "            \"  \\\" Contract address. \\\" \\n\",\n",
      "            \"  id: ID! \\n\",\n",
      "            \"\\n\",\n",
      "            \"  \\\" Collection name, mirrored from the smart contract. Leave null if not available. \\\" \\n\",\n",
      "            \"  name: String \\n\",\n",
      "            \"} \\n\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def format_schema_to_json(schema_text):\n",
    "    \"\"\"\n",
    "    Convert GraphQL-like schema text into a specific JSON format.\n",
    "    \n",
    "    Args:\n",
    "        schema_text (str): The input schema text\n",
    "        \n",
    "    Returns:\n",
    "        dict: Formatted JSON object\n",
    "    \"\"\"\n",
    "    # Split the input text into lines and clean them\n",
    "    lines = schema_text.strip().split('\\n')\n",
    "    \n",
    "    # Initialize the formatted lines list\n",
    "    formatted_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Clean the line and add proper escaping\n",
    "        cleaned_line = line.replace('\"', '\\\"').rstrip()\n",
    "        \n",
    "        # Skip empty lines that don't add value\n",
    "        if not cleaned_line:\n",
    "            formatted_lines.append(\"\\n\")\n",
    "            continue\n",
    "            \n",
    "        # Add the line with proper formatting\n",
    "        formatted_lines.append(cleaned_line + \" \\n\")\n",
    "    \n",
    "    # Create the JSON structure\n",
    "    json_output = {\n",
    "        \"gold\": {\n",
    "            \"version\": \"1.0.0\",\n",
    "            \"prompt\": formatted_lines\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return json_output\n",
    "\n",
    "# Example usage function to demonstrate the formatter\n",
    "def example_usage(schema_text):\n",
    "    \"\"\"\n",
    "    Demonstrate the usage of the schema formatter with pretty printing\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    # Format the schema\n",
    "    formatted_json = format_schema_to_json(schema_text)\n",
    "    \n",
    "    # Pretty print the result\n",
    "    print(json.dumps(formatted_json, indent=4))\n",
    "\n",
    "# Test with a sample input\n",
    "sample_schema = '''\n",
    "type Collection @entity @regularPolling {\n",
    "  \" Contract address. \"\n",
    "  id: ID!\n",
    "\n",
    "  \" Collection name, mirrored from the smart contract. Leave null if not available. \"\n",
    "  name: String\n",
    "}\n",
    "'''\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "example_usage(sample_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdoc import Parser \n",
    "from graphql import build_schema, parse, build_ast_schema, validate_schema, print_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = Parser(\n",
    "    schema_directory_path=\"../assets/schemas/opensea\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_text_example = print_ast(par.parse_schema_from_file(\"opensea_original_schema.graphql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gold': {'version': '1.0.0',\n",
       "  'prompt': ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '} \\n']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par.format_text_schema_to_json(ast_text_example)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"test_schema_output.json\", \"w\") as f:\n",
    "    json_output_ex = format_schema_to_json(ast_text_example)\n",
    "    json.dump(json_output_ex, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gold': {'version': '1.0.0', 'prompt': ['enum Network { \\n', '  ARBITRUM_ONE \\n', '  ARWEAVE_MAINNET \\n', '  AURORA \\n', '  AVALANCHE \\n', '  BOBA \\n', '  BSC \\n', '  CELO \\n', '  COSMOS \\n', '  CRONOS \\n', '  MAINNET \\n', '  FANTOM \\n', '  FUSE \\n', '  HARMONY \\n', '  JUNO \\n', '  MOONBEAM \\n', '  MOONRIVER \\n', '  NEAR_MAINNET \\n', '  OPTIMISM \\n', '  OSMOSIS \\n', '  MATIC \\n', '  XDAI \\n', '} \\n', '\\n', 'enum NftStandard { \\n', '  ERC721 \\n', '  ERC1155 \\n', '  UNKNOWN \\n', '} \\n', '\\n', 'enum SaleStrategy { \\n', '  \" Strategy that executes an order at a fixed price that can be taken either by a bid or an ask. \" \\n', '  STANDARD_SALE \\n', '  \" Strategy that executes an order at a fixed price that can be matched by any tokenId for the collection. \" \\n', '  ANY_ITEM_FROM_COLLECTION \\n', '  \" Strategy that executes an order at a fixed price that can be matched by any tokenId in a set of tokenIds. \" \\n', '  ANY_ITEM_FROM_SET \\n', '  \" Strategy to launch a Dutch Auction for a token where the price decreases linearly until a specified timestamp and end price defined by the seller. \" \\n', '  DUTCH_AUCTION \\n', '  \" Strategy to set up an order that can only be executed by a specific address. \" \\n', '  PRIVATE_SALE \\n', '} \\n', '\\n', 'type Marketplace @entity @regularPolling { \\n', '  \" Smart contract address of the protocol\\'s main contract (Factory, Registry, etc) \" \\n', '  id: ID! \\n', '  \" Name of the NFT marketplace, for example LooksRare \" \\n', '  name: String! \\n', '  \" Slug of the NFT marketplace, for example looksrare \" \\n', '  slug: String! \\n', '  \" The blockchain network this subgraph is indexing on. \" \\n', '  network: Network! \\n', '  \" Version of the subgraph schema, in SemVer format (e.g. 1.0.0) \" \\n', '  schemaVersion: String! \\n', '  \" Version of the subgraph implementation, in SemVer format (e.g. 1.0.0) \" \\n', '  subgraphVersion: String! \\n', '  \" Version of the methodology used to compute metrics, loosely based on SemVer format (e.g. 1.0.0) \" \\n', '  methodologyVersion: String! \\n', '  \" Number of collections listed on the marketplace. \" \\n', '  collectionCount: Int! \\n', '  \" Trade count of the all collections on the marketplace. \" \\n', '  tradeCount: Int! \\n', '  \" Cumulative trade volume (in ETH) \" \\n', '  cumulativeTradeVolumeETH: BigDecimal! \\n', '  \" Revenue that goes to the marketplace protocol, aka protocol fee. \" \\n', '  marketplaceRevenueETH: BigDecimal! \\n', '  \" Revenue that goes to creator, aka royalty fee. \" \\n', '  creatorRevenueETH: BigDecimal! \\n', '  \" Sum of marketplaceRevenueETH and creatorRevenueETH. \" \\n', '  totalRevenueETH: BigDecimal! \\n', '  \" Cumulative unique traders \" \\n', '  cumulativeUniqueTraders: Int! \\n', '} \\n', '\\n', 'type Collection @entity @regularPolling { \\n', '  \" Contract address. \" \\n', '  id: ID! \\n', '  \" Collection name, mirrored from the smart contract. Leave null if not available. \" \\n', '  name: String \\n', '  \" Collection symbol, mirrored from the smart contract. Leave null if not available. \" \\n', '  symbol: String \\n', '  \" Total supply of the collection, mirrored from the smart contract. \" \\n', '  totalSupply: BigInt \\n', '  \" NFT Standard the collection uses. \" \\n', '  nftStandard: NftStandard! \\n', '  \" Royalty fee rate in percentage. E.g. 2.5% should be 2.5 \" \\n', '  royaltyFee: BigDecimal! \\n', '  \" Cumulative trade volume (in ETH) \" \\n', '  cumulativeTradeVolumeETH: BigDecimal! \\n', '  \" Revenue that goes to the marketplace protocol, aka protocol fee. \" \\n', '  marketplaceRevenueETH: BigDecimal! \\n', '  \" Revenue that goes to creator, aka royalty fee. \" \\n', '  creatorRevenueETH: BigDecimal! \\n', '  \" Sum of marketplaceRevenue and creatorRevenue. \" \\n', '  totalRevenueETH: BigDecimal! \\n', '  \" Trade count of the collection on the marketplace. \" \\n', '  tradeCount: Int! \\n', '  \" Buyer count. \" \\n', '  buyerCount: Int! \\n', '  \" Seller count. \" \\n', '  sellerCount: Int! \\n', '  \" Trades of the collection. \" \\n', '  trades: [Trade!]! @derivedFrom(field: \"collection\") \\n', '} \\n', '\\n', '\" Trades exist such as a combination of taker/order and bid/ask. \" \\n', 'type Trade @entity @transaction { \\n', '  \" { Transaction hash }-{ Log index }-{ (optional) ID within bundle } \" \\n', '  id: ID! \\n', '  \" Event transaction hash. \" \\n', '  transactionHash: String! \\n', '  \" Event log index. \" \\n', '  logIndex: Int \\n', '  \" Block timestamp where the trade is executed. \" \\n', '  timestamp: BigInt! \\n', '  \" Block number where the trade is executed. \" \\n', '  blockNumber: BigInt! \\n', '  \" Whether the trade is in a bundle. \" \\n', '  isBundle: Boolean! \\n', '  \" Collection involved \" \\n', '  collection: Collection! \\n', '  \" Token ID of the traded NFT. \" \\n', '  tokenId: BigInt! \\n', '  \" The amount of token to transfer. It is set at 1 except for ERC1155 batch. \" \\n', '  amount: BigInt! \\n', '  \" Price (in ETH). If only 1 tokenId is involved, then the price is determined by the token only. If the trade is incurred by a batch purchasing (available in x2y2), then the price is the average price in the batch. \" \\n', '  priceETH: BigDecimal! \\n', '  \" Stretegy that the trade is executed. \" \\n', '  strategy: SaleStrategy! \\n', '  \" Buyer account address \" \\n', '  buyer: String! \\n', '  \" Seller account address \" \\n', '  seller: String! \\n', '} \\n', '\\n', 'type MarketplaceDailySnapshot @entity @dailySnapshot { \\n', '  \" { Contract address }-{# of days since Unix epoch time} \" \\n', '  id: ID! \\n', '  \" The marketplace that this snapshot belongs to. \" \\n', '  marketplace: Marketplace! \\n', '  \" Block number where the snapshot is taken. \" \\n', '  blockNumber: BigInt! \\n', '  \" Block timestamp when the snapshot is taken. \" \\n', '  timestamp: BigInt! \\n', '  \" Number of collections listed on the marketplace. \" \\n', '  collectionCount: Int! \\n', '  \" Cumulative trade volume (in ETH) \" \\n', '  cumulativeTradeVolumeETH: BigDecimal! \\n', '  \" Revenue that goes to the marketplace protocol, aka protocol fee. \" \\n', '  marketplaceRevenueETH: BigDecimal! \\n', '  \" Revenue that goes to creator, aka royalty fee. \" \\n', '  creatorRevenueETH: BigDecimal! \\n', '  \" Sum of marketplaceRevenueETH and creatorRevenueETH. \" \\n', '  totalRevenueETH: BigDecimal! \\n', '  \" Trade count of the all collections on the marketplace. \" \\n', '  tradeCount: Int! \\n', '  \" Cumulative unique traders \" \\n', '  cumulativeUniqueTraders: Int! \\n', '  \" Daily active traders \" \\n', '  dailyActiveTraders: Int! \\n', '  \" Number of traded collections of the day \" \\n', '  dailyTradedCollectionCount: Int! \\n', '  \" Number of traded items of the day \" \\n', '  dailyTradedItemCount: Int! \\n', '} \\n', '\\n', 'type CollectionDailySnapshot @entity @dailySnapshot { \\n', '  \" { Contract address }-{# of days since epoch unix time } \" \\n', '  id: ID! \\n', '  \" The collection that this snapshot belongs to. \" \\n', '  collection: Collection! \\n', '  \" Block number where the snapshot is taken. \" \\n', '  blockNumber: BigInt! \\n', '  \" Block timestamp when the snapshot is taken. \" \\n', '  timestamp: BigInt! \\n', '  \" Royalty fee rate in percentage. E.g. 2.5% should be 2.5 \" \\n', '  royaltyFee: BigDecimal! \\n', '  \" Minimum sale price of the day (in ETH) \" \\n', '  dailyMinSalePrice: BigDecimal! \\n', '  \" Maximum sale price of the day (in ETH) \" \\n', '  dailyMaxSalePrice: BigDecimal! \\n', '  \" Cumulative trade volume (in ETH) \" \\n', '  cumulativeTradeVolumeETH: BigDecimal! \\n', '  \" Daily trade volume (in ETH) \" \\n', '  dailyTradeVolumeETH: BigDecimal! \\n', '  \" Revenue that goes to the marketplace protocol, aka protocol fee. \" \\n', '  marketplaceRevenueETH: BigDecimal! \\n', '  \" Revenue that goes to creator, aka royalty fee. \" \\n', '  creatorRevenueETH: BigDecimal! \\n', '  \" Sum of marketplaceRevenue and creatorRevenue. \" \\n', '  totalRevenueETH: BigDecimal! \\n', '  \" Trade count of the collection on the marketplace. \" \\n', '  tradeCount: Int! \\n', '  \" Number of traded items of the day \" \\n', '  dailyTradedItemCount: Int! \\n', '} \\n', '\\n', '\" A helper utility entity that works as a set for deduplication purpose. \" \\n', 'type _Item @entity { \\n', '  id: ID! \\n', '} \\n']}}\n"
     ]
    }
   ],
   "source": [
    "print(json_output_ex)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph Metadata Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.thegraph.com/ipfs/api/v0/cat?arg=QmcQY5m381fPQUS6cEFY4VFZadtarYXNfRbEWJ7G7gbq7T\n",
    "# https://gateway.thegraph.com/api/[api-key]/subgraphs/id/DZz4kDTdmzWLWsV373w2bSmoar3umKKH9y82SUKr5qmp\n",
    "\n",
    "\"\"\"graphql\n",
    "{\n",
    "  subgraph(id:\"DZz4kDTdmzWLWsV373w2bSmoar3umKKH9y82SUKr5qmp\") {\n",
    "    id\n",
    "    metadata {\n",
    "      codeRepository\n",
    "    }\n",
    "    currentVersion {\n",
    "      subgraphDeployment {\n",
    "        ipfsHash\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/l2x6pccx1qdbhd_r0px4crjm0000gp/T/ipykernel_59538/3513027921.py:10: ResourceWarning: unclosed <ssl.SSLSocket fd=81, family=2, type=1, proto=0, laddr=('192.168.1.205', 62095), raddr=('104.18.40.31', 443)>\n",
      "  sg = Subgrounds()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "INFO:httpx:HTTP Request: POST https://gateway.thegraph.com/api/e4b7117cf42e1a57b7d54f3bdd0df9ea/subgraphs/id/DZz4kDTdmzWLWsV373w2bSmoar3umKKH9y82SUKr5qmp \"HTTP/2 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from subgrounds.pagination import ShallowStrategy\n",
    "from subgrounds import Subgrounds\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GRAPH_API_KEY=os.getenv(\"GRAPH_API_KEY\")\n",
    "subgraph_url = f\"https://gateway.thegraph.com/api/{GRAPH_API_KEY}/subgraphs/id/DZz4kDTdmzWLWsV373w2bSmoar3umKKH9y82SUKr5qmp\"\n",
    "\n",
    "sg = Subgrounds()\n",
    "network_subgraph = sg.load_subgraph(subgraph_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://gateway.thegraph.com/api/e4b7117cf42e1a57b7d54f3bdd0df9ea/subgraphs/id/DZz4kDTdmzWLWsV373w2bSmoar3umKKH9y82SUKr5qmp \"HTTP/2 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgraphs_metadata_codeRepository</th>\n",
       "      <th>subgraphs_currentVersion_subgraphDeployment_ipfsHash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/graphprotocol/graph-network...</td>\n",
       "      <td>QmUzRg2HHMpbgf6Q4VHKNDbtBEJnyp5JWCh2gUX9AV6jXv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subgraphs_metadata_codeRepository  \\\n",
       "0  https://github.com/graphprotocol/graph-network...   \n",
       "\n",
       "  subgraphs_currentVersion_subgraphDeployment_ipfsHash  \n",
       "0     QmUzRg2HHMpbgf6Q4VHKNDbtBEJnyp5JWCh2gUX9AV6jXv    "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph_metadata = network_subgraph.Query.subgraphs(\n",
    "    where=[\n",
    "        network_subgraph.Subgraph.id == \"DZz4kDTdmzWLWsV373w2bSmoar3umKKH9y82SUKr5qmp\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "sg.query_df([\n",
    "    # subgraph_metadata.id,\n",
    "    subgraph_metadata.metadata.codeRepository,\n",
    "    subgraph_metadata.currentVersion.subgraphDeployment.ipfsHash\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphdoc-x8ppHhEw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
